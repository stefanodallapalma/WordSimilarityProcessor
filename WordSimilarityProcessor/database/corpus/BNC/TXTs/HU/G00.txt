It is often said that you can discover a great deal about a person's character by the books on their shelves.
I suspect that the same is true for his profession and the objects on their desk; calculator, notepad, diary and telephone book for example.
Spot these next to the computer on someone's desk and you immediately know they have never heard the phrase ‘Desktop Accessories’.
Most of today's business computers are based on the IBM PC design and, sadly, this is only capable of performing one task at a time.
Regardless of what the manufacturers of integrated software may tell us it can still be a time consuming process to off-load the document from the wordprocessor and pull in the data base and its files to look up a simple telephone number.
Fortunately the means do exist for a PC to suspend the operation of one program and run another and it is the exploitation of this facility that has produced a veritable rash of Desktop Accessory software.
Often called Memory Resident or Background software, because it hides away in memory, the program can be accessed at any time regardless of whatever foreground software is running.
These programs provide facilities ranging from the essential to the virtually useless depending on your point of view.
The first to enjoy any degree of commercial success was SideKick which is primarily aimed at the technical user rather than the businessman.
How many executives need to look up ASCII codes or work out problems in Hexadecimal and Octal?
Rather more flexible, but copy protected—SideKick is available both un-protected and protected, is Spotlight which would suit the executive with Rolodex type files for names and addresses, a proper calculator and so on.
While the facilities that this kind of software can offer are attractive they can have some drawbacks.
The majority of memory resident offerings are well house trained but some software doesn't seem to like having its operations suspended without due notice.
The main problems seem to come when the foreground application program has control over the keyboard or is using large chunks of memory to mimic the screen.
Generally you'll find that the publisher of a Desktop Accessory will show a list of ‘proven to work’ software, so unless you can see your particular application be cautious.
Remember too, memory resident programs take up memory.
Running a large application on a PC is fine but steal between 32K and 128K for your desktop accessory and your spreadsheet model may no longer fit.
The third, and most troublesome, problem is the interaction of various accessories.
Some have to be loaded first, others last and just a few, Ready! is an example, couldn't care less.
But all of them are constantly watching the keyboard for their particular call up command and it is possible that one command may affect more than one accessory—with predictable, and disastrous, results!
The final point, on the purely technical side, is that accessories which offer automatic dialling of telephone numbers via a Hayes-compatible modem won't necessarily work in the UK.
The latest versions of SideKick offer the choice of tone (useless unless you have a touch-tone system) or pulse (which works fine) but Spotlight, despite claiming to be a UK version resisted all my efforts.
Look for the ability to modify the ‘lead-in’ and lead-out' codes, if you can change them there's a good chance that you'll be able to get the dialler working.
All of these comments and caveats will have set you pondering on the myriad uses to which you can put the data base, the diary, the notepad and the calculator.
In just a few moments you can see how much easier your working life could become.
Blunt pencils and empty pens become a thing of the past.
No more scrabbling for notepads or realising that you've left your diary on your secretary's desk.
You will, in short, become a desktop junkie.
But, be warned!
The reality of life is somewhat different.
Would you really, and think carefully about this, trust all your personal information; diary, telephone list and so on to the memory of that recalcitrant computer on your office desk?
In the first place you've got to type all those numbers, names and so on into the thing before it becomes of any real use.
And then you must keep it all up to date.
No longer is it any use making a note in your diary at home about the meal you'll be enjoying at a friend's on Wednesday night.
You must also remember to put the information into the computer's diary and set the alarm function or, come 6.00pm you could still be working and have lost another acquaintance to the great god Mammon!
In all seriousness though, desktop accessories can be an absolute delight.
Always having a calculator to hand (isn't that what you bought a computer for?) and an instantly accessible notepad are probably the two essential elements.
Also extremely useful is a pathway back into the operating system so you can copy a file onto a floppy for your colleague without having to unload everything.
Diaries, calendars, ASCII code tables and the rest can, and do, have their uses but analysis of the amount they really get used shows that they probably still belong on the desk rather than in the computer.
If all computers had a modem, and only around 15% do, which the software could communicate with then on-screen dialling would be a viable proposition and the office telephone list might join the notebook and calculator.
Until then much of the usefulness of these accessories lies in their exploitation of an underused resource rather than a dramatic step forward.
The Reviews
SideKick
To call up SideKick use Ctrl-Alt or hold down both Shift keys.
These options can be tailored to suit if you find they aren't easily remembered or clash with some other option.
SideKick's telephone dialer is designed to work with a Hayes-compatible modem and can be set to operate in either tone or pulse mode.
As the latter is the only one that works for the majority of UK phones you need to select it when you Install the program.
Spotlight
The Phone book accessory now has a telephone dialer installed but, despite being labelled ‘UK Edition’ it proved beyond our capabilities to get it to dial anything.
All the lead-in codes were set up for USA-style dialling; local, long distance and so on, and whilst these could be changed the lead-out character was set to be a semi-colon.
Our Hayes-compatible modem, a Miracle Technology WS3000, needs a Return code so whilst the information was sent to the modem it was never given the go ahead to dial.
Summary
Despite its recent upgrades to include support for the IBM AT, fast colour monitors and the ability to set the default colours of each accessory window Spotlight lags behind SideKick on friendliness and ease of use.
In addition it takes up a lot more room than its rival although, even in copy protected form, it can be installed on a Winchester without needing a key disk.
The One-Key Series
The One-Key series offers an unusual approach to the concept of Desktop Accessory programs.
Rather than have one large program that offers the sort of facilities we've described for SideKick and Spotlight you can choose one, or more, of the range and build you own set.
The four offered are Calculator, Memo Pad, DOS Plus and Timekeeper.
The Calculator accessory takes 20K of RAM and offers a full-blown printing calculator simulation.
The regular functions are present together with a change sign facility, a currency mode, dollars of course, and ten independent memories.
These can be displayed, cleared or have the four basic operations performed on them allowing eleven different sums to be carried out simultaneously.
As well as showing the progress with a tally roll on the screen the calculator can also copy its operations directly to your computer's printer.
The final result can also be carried back into whatever program you were running before you used the calculator and is printed at the current cursor position.
Theoretically the most useful of the set is DOS Plus which offers a path back into the operating system from any application program.
Here you can copy files, list files in other directories and even format a floppy disk.
The utility takes 22K and crashed our test system on several occasions.
Why is not immediately obvious but sufficiently worrying to put a black mark against the program.
We tested all the Desktop Accessories on a naked system with no other memory resident programs installed.
The foreground software used; Smart, Cardbox and Multiplan have all been found to work fine with memory resident software over many months of use.
By far the smallest of the utilities is Timekeeper which needs just 13K.
Basically it's small because it doesn't do very much!
Up to five alarm calls per day can be set and there's a perpetual calendar as well.
Probably the only useful thing that the program offers is the ability to carry back the date, time or combination of the two into your foreground application.
On several occasions though the program also brought back a quantity of junk graphics suggesting that its overlay technique wasn't foolproof.
Topping the heap at 36K is Memo Pad which gives you a scratchpad facility.
Simple text editing can be performed and files loaded and saved to and from other directories but it lacks the power of SideKick's notepad, in fact it's even more basic than Spotlight's offering.
No directory information is provided so if you can't remember the file or path name you could get a bit stuck.
Overall the Calculator accessory is the only one that comes close to being worth its price, the others are either too basic or liable to crash to be considered seriously.
They also take up an extraordinary amount of memory, the four together gobble up 91K which is more than double that required by SideKick and a quarter as much again as Spotlight.
Perhaps the clearest indication of the quality of the One Key series is given by the documentation.
While both SideKick and Spotlight have well produced manuals to back up their on-screen help functions One Key has an instruction sheet the size of a folded postcard.
When installing the software information is given but this approach is more expected of public domain or ‘free’ software, not a commercial product.
Desktop Publishing
Hardly an issue of a computer magazine goes by without some mention, editorial or advertisement, of desktop publishing.
Just what this wondrous new jargon phrase means is a considerable mystery to many yet to others it is the best thing to happen on a micro.
Unfortunately, like much jargon, the term has arisen partly from people who needed a term to express what they were actually doing and partly from suppliers seeking a new vehicle to act as a stimulant for their products.
Desktop publishing, as it was originally conceived, was the action of using computer hardware and software to bypass all the tedious, mechanical stages of typing, correcting, editing, assembling and, finally, producing printed material.
There have been electronic publishing systems for many years but these were, and generally still are, expensive in the extreme.
Apple's Macintosh coupled with the new generation of page printers made the process possible at a cost within the reach of tens of thousands of individuals rather than a few hundreds.
The device we call a page printer, by the way, is more usually referred to as a laser printer, much more exciting.
But, as page printers don't all use laser technology we'll stick with the proper term for the duration of this article.
The reason that the Macintosh, hardly a favourite among the business community, has been so successful in its guise as a publishing system is due to the fact that it was the first to provide a common user interface for all its software.
This means that the user generally finds it easier to use and data from one program can be easily transferred to another, a feat requiring skill and patience on machines like the PC.
Add to this the fact that Apple were the first and, until very recently the only, supplier to offer a complete system their success is no great surprise at all.
That dominance is now being challenged as PC manufacturers slowly come to terms with the potential market for desktop publishing.
There are basically four elements required before a system can even begin to be considered as a desktop publishing tool.
Primarily the computer has to have a graphics capability, preferably monochrome and as high a resolution as possible.
Secondly the operating environment must allow simple and effective data transfer between programs, this is standard on an Apple Macintosh but on the PC one needs software such as GEM or Windows to achieve it.
In the third instance the most vital piece of equipment required is a page printer, ideally one with a page description language built in but that's not completely essential as we'll see later.
Finally, software that can run under the environment manager and allow the results of programs such as word processors and graphics packages to be merged to produce results on the page printer.
This last point is where much of the confusion currently reigns.
In addition to the software we have become used to; word processors, data bases, spreadsheets and so on, we now have two additional categories.
The most misused of these is page makeup or page layout software while the second is just described as desktop publishing software.
In the first instance the potential buyer must look to see if the program offers the following capabilities.
Does it have a WYSIWYG mode or, to put it into English, does the user see on the screen exactly what he'll get on the page?
Can it read text files from a word processor and pictures from a graphics package?
Does it allow graphics to be scaled up or down to fit?
Can the text and graphics be moved around once they have been placed on the page?
If the answer is no to even one of the above then the product is not truly providing a replacement for the layout artist, that's the human who normally does page makeup.
Much of the product around today does not meet the above four requirements.
But, for many people all that will ever be needed is a program which provides word processing with the capability to get decent quality print out of a page printer.
There is apparently much to choose from and some, but by no means all, fit the requirements.
The key to almost all the page makeup software problems is to discover whether the program supports a page description language.
This wonderful term is actually self explanatory.
The program describes, in step by step terms, the process of constructing a page and passes these instructions to the page printer which recreates the image.
If it does then the product, in conjunction with a page printer that speaks the same language, will be almost infinitely more powerful than one that doesn't.
There are currently two page description languages that are getting all the attention; PostScript, the language adopted by Apple and many other hardware and software companies, and DDL, recently taken up by Hewlett Packard.
Page description languages are currently a hot topic with much being written about the relative strengths and weaknesses of the various offerings.
In reality, just as the user couldn't care less what language a piece of software was written in, it doesn't matter which one is used by the desktop publishing program.
The only important consideration is whether the product is widely supported by both hardware and software producers so giving a choice rather than a single option.
Until that day arrives they remain a useful way of detecting the desktop publishing bore!
The best place to start with desktop publishing, as with most new phenomena, is at the beginning.
If all that is needed from the computer system is a means of generating high quality text output then settle for a word processing package that can talk to a page printer.
There are several; Wordcraft, Microsoft Word, WordPerfect and more to come.
All can converse quite happily with one or more of the common page printers with or without the help of a page description language.
Should the requirement be for text with the occasional graphic such as a bar chart or line drawing thrown in then many of those just mentioned will look after this as well.
It is only when one moves into the realms of complicated, multi-column pages which have several different sizes and styles of print with perhaps some photographs as well that the user really needs to worry about page makeup software.
Once again there are many names to choose from but it is at this point that the design of the Amstrad PC starts to interfere.
Because of the restrictions placed on adding high resolution display cards or monitors much of the product on sale or announced for PCs will not operate.
Limiting oneself to just the products that run on the standard graphics card, be it colour or monochrome, reduces the options to a mere handful.
Two programs which are virtually guaranteed to work are Fontasy and Fleet Street Editor which is the same as Clickart Personal Publisher to all intents and purposes.
While the latter is much more of a page makeup program than Fontasy they both produce roughly the same results at the end of the day.
A product well worth noting that definitely isn't a page makeup package in the terms described here but which does a better job when it comes to producing newsletter pages and so on is Newswriter.
This should also work perfectly happily on a 1512 system as it make no special demands on graphics presentation.
Desktop publishing, as far as the user is concerned, is really the action of producing documents that look as though they have been professionally designed and produced by traditional methods.
The software used to produce the end results is, by and large, fairly irrelevant.
The important thing is to establish just what the end result is to be and then find the right software.
Attacking the problem from the other end can be expensive, time consuming and involve the use of skills which the artistically untrained user is unlikely to have.
Unless someone can crack the problem of how to incorporate higher quality displays and graphics cards in an Amstrad PC it is unlikely that the machine will figure largely at the page makeup end of the market.
In most cases the processing power required is that of an AT type machine with a Hercules or EGA graphics card so until Amstrad come out with the next generation machine this aspect of desktop publishing will have to wait.
There is, however, nothing to stop the PC1512 being used where either text on it own or simple text and graphics from programs like Gem Draw are involved.
There is also a strong argument for using several of the machines as word processors or graphics generators and passing the data on to a larger central system for final assembly.
Indeed, in a publishing environment where there may be a need for perhaps a dozen word processors but just one page makeup system this approach has strong financial advantages.
When it comes to using the right tools for the job it is also important to realise that the final output from a desktop publishing system is not always the end product.
If only a single copy is needed then it is logical to produce it on the page printer.
It may still be economical to print ten or more but when hundreds or even thousands of copies are required a whole new technology takes over.
The quality of output from a page printer is more than adequate for an instant print shop to use as the master for a bulk run either through a copier or proper printing.
Several additional features can now be added like colour or photographs and the product starts to take on a more professional look.
In the extreme case it is possible to use the same file that created the page on a page printer and use it to generate true phototypeset quality results.
Equipment of this kind is not something a single individual could afford but the services are available from a growing number of bureaux.
Desktop publishing is fun.
It allows a user who has, until now, produced typewritten or word processed text to achieve results that are barely distinguishable from those achieved by professional publishers.
Books, magazines, newsletters, hand bills and a veritable host of other printed material can be designed, created and printed without the need for any outside help at all.
The aesthetic quality of the results will depend heavily on the artistic ability of the user but even these skills can be developed in time
Macintosh DTP Feature
It is perhaps ironic that the product which has seen the complete transformation in Apple Computer's financial status is neither a computer nor a piece of software.
It is the LaserWriter, a Canon-derived page printer equipped with a complex processing system licensed from Adobe.
In many respects, it isn't even their product!
As to why a peripheral, albeit a very smart one, should prove to be the saviour of a company we need to look at some history.
In the beginning was electronic publishing and Apple was not there.
Three, four years ago the seeds of what we know today as desktop publishing were being sown by companies like Xerox, Interleaf, Sun and Apollo.
Large, powerful computer systems based on minicomputer architectures but built using microprocessors, were beginning to offer the sort of graphical interface and high resolution screen that we take for granted today.
Based on research done at Xerox's Palo Alto Research Centre or, PARC as it is widely known, the Apple Lisa was the first commercial micro to take these concepts to the mass market.
Around the same time the first desktop publishing programs, although they weren't called that, were beginning to emerge on Unix-based engines like the Sun and Apollo.
The first personal computer program which met the standards expected of today's products actually ran on the IBM PC and was called DO-IT, but that's another story.
For the Apple Macintosh, however, the future, at this time, looked pretty bleak.
Corporate America had decided the IBM was the machine to follow and the Macintosh, whatever its advantages, simply didn't fit into this scheme.
Apple had to find something that only their computer could do.
That something became desktop publishing.
The component parts needed to make a desktop publishing system on any computer are as follows.
To start with, software running on the computer must be properly integrated and Apple had designed that into the Macintosh from day one.
Secondly there must be an efficient method of getting the information displayed on the screen onto the paper and the PostScript page description language met that requirement to a tee.
Apple themselves had already cracked the communications problem with the AppleTalk network.
Thirdly was the need for a high quality printer and the Canon page printing engine met this requirement exactly.
Combine the three and all that's missing is the software.
From day one Macintosh applications have been WYSIWYG, it's an integral part of the machine's concept.
Getting the information onto the printer meant that a page description language became essential if Apple were to avoid the problems faced by manufacturers who were just treating the Canon engine as a high quality dot matrix printer.
PostScript couldn't be built into the Macintosh, it was too late for that, so the interpreter had to go into the printer, now called the LaserWriter.
That boosted its price substantially but it could do things that no other printer was capable of so the added value made it well worth it.
All that's missing is the software to drive it all, and that wasn't long in coming.
Of the three original page makeup programs; PageMaker, MacPublisher and Ready, Set, Go! only the first survives in its original form.
That Aldus got the first version so nearly right is a considerable tribute to their talents.
MacPublisher's first incarnation was, to be polite, dreadful and version II fared little better despite a brief spell of fame as Letraset's LetraPage.
Ready, Set, Go! went through version 2 like a rocket and emerged late last year as version 3.
This is a superb product, better than PageMaker 1.2 and, on paper at least, better than the long awaited upgrade, PageMaker 2.0.
However, its marketing has recently been taken over by Letraset and we await to see the outcome.
Future page makeup programs that also have yet to see the light of day include SPUD, now called Scoop, which looked truly amazing when we saw a preview last year, and MacPage which is an Israeli program primarily designed for broadsheet and newspaper production.
Word processing on the Macintosh has always bordered on the realm of page makeup and recent announcements here only serve that view.
The latest version of Microsoft Word incorporates a host of features designed to allow newsletters and simple text and line work to be produced from within a familiar word processing environment.
The British created MacAuthor was there well ahead of it and now enjoys some considerable success among the serious writing fraternity.
Indeed, it is the only word processor on the Mac that we would use were it not for the fact that no other software speaks its format.
A recent arrival is WriteNow, marketed by T/Maker of Clickart fame but developed by Steve Job's new company.
By all reports this appears to be an amalgamation of the best of Word 3 and MacAuthor but, until our review copy arrives judgement is withheld.
The traditional method of setting type on computer-based systems is not WYSIWYG but code driven.
The other major difference between traditional typesetting software or emulations of such products and page makeup programs is the degree of control they provide.
Page makeup software may allow type to be set in 1 point increments and, perhaps, offer half-point line spacing.
Typesetting software would expect to offer at least half-point setting increments and tenth-point line spacing.
Features such as kerning, tracking, inter-letter and inter-word spacing control, ligatures and hung punctuation are all but unknown in page makeup yet no typographer would be without them.
The classic computer-based typesetting software is TeX.
This has recently been transported to the Macintosh under the name Textures and offers a level of control that exceed the capabilities of the LaserWriter by several orders of magnitude.
Indeed, to get the best out of it a phototypesetting system is an absolute must.
An interesting piece of software called JustText offers a more realistic alternative.
Probably the only piece of Macintosh software designed not to be WYSIWYG, although a preview version is now available, it allows real typesetting control to be exercised.
The codes are fairly learnable, although the skill to make the best of them comes slowly.
JustText is a misnomer really as it can handle graphics and rules quite easily.
It is one of only a few products that can run text round an irregular object, although there are restrictions to this.
It is interesting to note that JustText is used by Adobe to help produce its regular Colophon newsletter, a production that makes full use of the PostScript language and is an object lesson in what can be achieved, given the computer power.
Because everything that appears on the Macintosh screen is treated as a graphic, even the text is handled this way, life is remarkably easy for the desktop publisher.
Illustrations produced by any package can be transferred with consummate ease to another.
There are, however, limitations that the desktop publisher needs to be aware of.
Accurate scaling is difficult for bitmapped graphics, especially scaling up, so it is often better to use a object-based drawing program like MacDraw or MacDraft.
It is likely that both these will be supplanted by Cricket Draw.
This is brilliantly easy to use, incorporates loads of special effects such as distortion, graduated tones and can even generate raw PostScript if required.
Another contender for the crown is Superpaint which combines the best of 300dpi bitmapped graphics with an object drawing program.
Although the Macintosh is an excellent vehicle for creating graphics not everyone is a budding Picasso.
Scanners, or digitisers, are the answer for the majority of us who struggle to draw a straight line, let alone a circle.
Given that the image already exists on paper, a scanner can capture it as a bitmap which can then be manipulated by a suitable graphics package.
The word suitable is important here, it is vital to match the capabilities of the software to the resolution of the scanner.
Photographs, on the other hand, are not so simple.
To capture the detail requires a scanner that can interpret grey scales, the more the better.
Somewhat surprisingly one of the cheapest scanners, the Thunderscan, can outperform most of the expensive flatbed machines in this respect.
Another growing use for scanners is as optical character readers.
Custom made OCR devices have traditionally cost many tens of thousands, with the exception of the ill-fated Omni-Reader.
One recent introduction, the DEST PC Scan, has broken this mould by providing very reasonable OCR for around £3,000.
The PC Scan uses a SCSI interface to communicate with the PC and so its adaption to the Macintosh is a foregone conclusion.
TextPac, the software that controls this dedicated OCR device, has recently been joined by PublishPac.
This allows the device to be used for graphics scanning as well.
Microtek, a well-known manufacturer of low-cost flatbed scanners, has recently introduced software that allows it to act as an OCR scanner as well.
However, its performance is likely to be less reliable than that of the DEST system simply because the PC Scan was designed to perform OCR while the Microtek has merely been adapted.
One brand new product that seems to have scored a huge hit at the recent MacWorld show is Adobe's Illustrator.
Imagine scanning an image as a bitmap and then converting that to PostScript.
This is what Illustrator achieves and then it allows you to modify the results.
The benefits are enormous, working in raw PostScript means that anything can be scaled by any amount and all the original information is retained.
It should work like a dream with halftones because, given that the grey scales are captured PostSCript can work on them with its internal routines to perform some stunning effects.
JustText, by the way, includes a Thunderscan to PostScript routine that's worth the price of the product alone.
Page printers are developing too.
We already have a second generation of RIP from Adobe which speeds the interpretation by up to four times.
The first commercial use of the new product is in Agfa's 406dpi printer.
Increased dot resolution is an area of great interest, it's highly likely that Apple will move to the 406dpi standard before the end of the year.
The apparent increase from 300 to 400 is 30% but what we actually need to measure is the increase in dots per square inch and this increases by 84%.
The results speak for themselves.
Increased page printer speeds are coming slowly, the norm is now 10–15ppm rather than eight, but prices rise accordingly.
Agfa's P400PS runs at 18 original pages per minute but you pay £18,500 or so for the privilege.
Interesting facts culled from a meeting with the leading lights of both Aldus and Adobe at last year's Appleworld show indicate that the main problem with PostScript on the Macintosh is the QuickDraw to PostScript conversion process and has nothing at all to do with the LaserWriter or PostScript.
The problem is aggravated by the AppleTalk management software and, we hope, the new Macintosh E and Macintosh II operating systems will solve them both.
The new RIP can build a page of text in RAM, given that the font tables are computed, in around threequarters of a second…
Stories currently in circulation talk of the search for a printer mechanism that can run at 90 pages per minute!
One thing's for certain, the Apple desktop publishing machine is going to keep moving forward.
A recent Dataquest survey showed that even after the IBM world had taken 60% of the overall market Apple retains the largets single share, 27%.
A substantial achievement for a company that might have ended up dead less than two years ago
If you believed everything you've ever read about desktop publishing it's quite possible that you think anyone who can use a computer can turn out professional looking material with consummate ease.
And, I'm sad to say, you'd be completely wrong.
Desktop publishing is unlike any other kind of software ever set loose on the market.
Like most creative processes it requires certain skills and an overall understanding of simple design principles before even partially decent results are achieved.
This contrasts strongly with the simplicity of word processing, data base or even spreadsheet software.
Here, letters, words and figures can be entered at will and the underlying structure of the software takes care of the details.
The nearest group of software products are the various art packages but even here it is easy to distinguish between good and bad.
The whole problem was compounded by the fact that the first successful desktop publishing system was based on the Macintosh; a computer designed to be easy to use and, therefore, give the feeling of rapid achievement.
It is only now, after some 18 months, that people are beginning to realise that owning and using a desktop publishing system doesn't instantly make one a great designer.
What this article will try to outline are the basic essentials of that design process, so helping new (and not so new) users avoid some of the more gross errors.
For it is sadly true that misuse of a desktop publishing system can actually reduce the impact of your material rather than enhance it.
In the first instance it is important to establish whether or not you actually need ‘desktop publishing’ as portrayed by the advertisers.
If your material consists of pure text; a book or report, for example, then it is quite likely that you'll be better off with a high-powered word processor such as Word 3, MacAuthor or even a typesetting system like JustText, TeXtures or Page One.
However, as the real appeal of DTP is in its ability to manipulate pages it's likely that we are looking for a page makeup product such as PageMaker or its many rivals.
These products excel where text and graphics are to be mixed on a single page.
The single most important element of a page is its overall design, regardless of, but strongly influenced by, its content.
The device which holds the design together is the grid and this is what gets designed first.
An A4 page is too wide to have a single column of text; the human eye gets bored very quickly, so adopt a two- or even three-column layout from the start.
Four columns can be used but later when the ground-rules are better understood.
There should be a decent gap between the columns and it is often useful to place a vertical line in the middle of this gap, so physically preventing the eye straying from one to the other.
Text doesn't need to be justified, a lot of research indicates that ragged columns are ‘friendlier’ and easier to read.
Space is often more important than type so don't pack the lines too closely together.
Most desktop publishing packages offer an automatic leading setting as a default and this should be generally over-ridden.
Large amounts of text can be set in 10pt type on 11pt leading (leading is the amount od space between the lines) and this provides a nice balance for most situations.
Leave blank lines between paragraphs and make frequent use of headings to hold the reader's interest.
Set the body text, that's the main volume of text, in a serif typeface, that's one with those little ticks at the ends of the letters like Times, Palatino, Bookman, etc, and the headings in a sans serif face such as Helvetica, Avant Garde, etc.
The variation between the two creates interest and, anyway, serif faces are easier to read in large quantities.
Once you've made the choice, though, stick to it throughout the publication, don't chop and change from one style to another.
Stick to just two typefaces throughout the publication; one for the text, the other for headings and so on.
Use no more than three sizes; one for the body text, a larger size for major headings (headings within the text should be bold but not necessarily bigger) and a smaller size for page headings, page numbers, captions and so on.
Leave large margins at the top and bottom of pages, preferably separated by some device such as a rule to draw the eye into the page.
Don't be afraid of white space, use it to break up the page and provide more interest.
Use illustrations and photographs but don't overdo it.
A picture may be worth a thousand words but you'll still need some text to explain what the pictures are about!
Some words of warning on the subject of pictures are in order at this point.
Just because you can buy a scanner which will capture photographs and drawings doesn't mean that it is necessarily the best way.
At 300dpi the quality achieved with photographs can generally be described as poor to awful.
Storing a single Bphoto can also absorb an awful lot of memory, megabytes in some cases.
Simple drawings and illustrations are generally OK but avoid enlarging or reducing them wherever possible.
Scanners capture images as a pattern of dots, changing the proportions can instantly turn an acceptable image into a complete mess!
Better in many cases to stick the photographs in at the printing stage and have them done by traditional methods.
Above all, it is worth talking to the people who produce your documents by traditional methods.
They may talk an alien language of picas and points, separations and screens but they have accumulated the knowledge of several centuries.
It is unreasonable to expect a piece of software to turn you and your computer into their equal in a matter of weeks or even months.
Don't be too proud to have a designer come and help design the basic pages you need.
Most desktop publishing systems have the advantage of a degree of flexibility that most printers and designers simply cannot believe.
Remember, though, that this often means that you'll make bigger and better mistakes in even shorter time.
Henry Budgett, one of the country's leading exponents of desktop publishing since the technology first emerged in 1984, looks at the growing gap between desktop and professional publishing.
It can, he argues, often be reduced by the application of a little thought before you start work on your latest creation.
Desktop publishing is, despite all the hype and glossy advertising, not yet all things to all men.
Even some five years into the technology there are still areas in which it simply cannot compete with the more traditional methods of print production and publishing, the most often quoted being that of output quality.
There is no doubt that the quality of text produced by a 300 dot per inch page printer is of a lower quality than that from a phototypesetter—anyone who claims otherwise probably needs spectacles quite urgently.
However, there is a large and growing market which is more than happy to accept 300dpi resolution; it's an appropriate technology for their needs.
That market is the business sector who require better presented documents but without the hassles of having them professionally, is traditionally, created.
It is often the case that documents created in the business environment are considered inferior in terms of design, typography and overall appearance.
Strangely, when compared against the material they replace, word processor generated pages, they are usually substantially better!
Unfortunately, because they were generated by desktop publishing they tend to be compared against ‘professionally’ created material.
Good design isn't everything
There are three distinct areas in which the quality of the final document can be affected by the equipment rather than by the design; the input devices, the software and, obviously, the output device.
This article will tackle each in turn and make suggestions as to how the problems can be relieved or eliminated depending on the user's needs.
The single most abused area is that of the typography.
Getting this right, however, is only part of the solution to the problem.
Indeed, good design is worth an entire article on its own.
Graphics and other illustrative material has its part to play as well and this is an area which receives little attention.
Not so very long ago paint programs were used as a demonstration of the capabilities of a computers system.
They are easy to use and often appear to produce quite good results.
Sadly, the sort of quality that can be achieved from such bit mapped graphics is rather less than the advertisements might lead you to believe, especially when it comes to enlarging or reducing them and printing them out at high resolution.
If you must use a painting program then it is essential to use one that works at the resolution of the output device.
This at least allows you to make the best of poor job; a package which only works at the screen resolution could be a fifth the quality, or worse.
The golden rule is to use a drawing program which builds its image from instructions rather than individual dots.
These images can be re-scaled at will and always print out at the resolution of the printer rather than the computer's display.
Capturing the image
Photographs, however, are not such an easy matter.
It would be easy to dismiss scanned photographs as simply worthless and suggest that you just leave a gap in the page and let your printer look after the problem for you.
If, however, you just want to produce single sheets with the image already in place that's not going to be a practical solution.
So, what are the alternatives?
The first thing to watch for is that the scanner be matched as closely as possible to the target printer.
Secondly, the more grey scales the scanner can resolve the better as we are going to be trading these against resolution for the best compromise.
Finally, the scanner should not mess about with the image through fixed dither patterns or their various equivalents, we need to let the software do this.
The magic word to look for is TIFF or Tagged Image File Format which is an industry standard for scanned images.
If you do have a scanner which performs grey-scaling by using dither patterns it is important to run tests to check which pattern is the most suitable for the particular picture, there is often a considerable difference in quality which is due to the scanner's response to the original photography.
Always try to scan a photograph as near to the size you want it rather than use software to re-scale it, optically reducing scanners are a great help here.
The next best compromise is a scanner which allows you to pre-scan an image and then select the part you want and its size.
All these methods are ways to reduce the amount of data captured, don't forget than a 5″ by 4″ blackwhite photo scanned with 64 levels of grey will take a theoretical 1.35M of storage.
Manipulating this much information puts a considerable strain on the processor's memory and gives you a storage problem to boot!
Software as a tool
The next area in which you have control over the final quality is that of the software you choose.
The software for each desktop publishing task should be the package that suits the task, rather than the one you happened to use yesterday.
Although the ultimate resolution rests with the output device it is essential that the software can at least provide control over it.
Business communications are unlikely to need precision typography but the ability to have fractional point sizes and leading values is pretty much essential.
Even the best display systems currently available are pushing the limits to reach 150 dots per inch, half the resolution of a page printer and less than a tenth that of a typesetter.
WYSIWYG software is matched to these resolutions, if it's impossible to display a half point change in type on the screen then WYSIWYG isn't!
Code driven systems don't have these restrictions and, put simply, that's why the professional typesetting systems stick with it.
So, if you are going to typeset a fine art book or produce high quality galleys for an advertisement then it's possible that a WYSIWYG package will not suffice.
Don't write off desktop publishing for doing any of the above, though.
You will get perfectly acceptable results from a WYSIWYG package so long as you work within the constraints the software imposes but this now becomes a design problem rather than a technological one.
If you are going to be integrating photographs into your documents then it is obviously fairly essential to make sure that the software can look after the TIFF file format (or any other that you may be working with).
It's also useful to have scaling and cropping facilities just in case the picture does need slight adjustments made to it.
If these turn out to be major then it's often better to re-scan the picture for the new dimensions than to mess about with the first version.
The software also needs to support the various drawing and, if you're desperate, paint packages.
Currently the ‘ideal’ portable graphics standard is the Encapsulated PostScript file format, often called EPS, which is well supported across the whole spectrum of both desktop publishing and electronic publishing software.
Getting some output
It is also fairly essential to ensure that your desktop publishing package has a route through to high quality output devices such as typesetting systems.
And, even more essential, that the typefaces you are using within the package are available on those systems.
Whilst most packages do now support PostScript there now versions of PostScript other than that created by Adobe!
It is essential to make sure that your version is the same as that of your typesetting bureau and that you are both using the same fonts, ideally from the same vendor.
The final stage of the desktop publishing process is the output and this is where all the quality aspects begin to come to rest.
If we consider the page printers first then the dominant printer control software is PCL, Hewlett Packard's Printer Command Language.
This is found in the LaserJet and its imitators and with over 2,000,000 units in the market it totally dominates.
But, because it's a command language and not a page description language the facilities it possesses are adequate rather than sophisticated.
Hewlett Packard have a working agreement with Compugraphic which has already led to that company's typesetters being able to understand PCL and HP's printers being able to accept Compugraphic's fonts—they also provide PostScript as an option.
You may think that all 300dpi page printers would produce the same quality of image but this turns out not to be the case.
To begin with the quality of the font designs can have a substantial effect; not all versions of Times look as good as they ought to.
Secondly, there are two methods of building up the image within the printer.
The method used by the original Canon laser engine is called ‘write black’ because it charges up those areas of the drum that are going to become black when printed.
The opposite method, that of discharging all the parts of the drum that are going to stay white, is used by Ricoh, Hitachi among others.
Of the two methods it is generally agreed that ‘write black’ is much better at fine lines and accurate reproduction of small typeface sizes while ‘write white’is best for large areas of solid black.
The engine type itself; laser, LED, LCD shutter or ion deposition, can also cause variances in the quality.
Laser engines undoubtedly rule at this moment in time but the LED looks like becoming a strong contender with devices like the NEC SilentWriter—it's also inherently more reliable.
LCD shutters have finally cracked the quality problem and models are available from Qume, Sharp and Taxan.
Ion deposition has never laid claim to be a quality method but for high volume work it's the way to go as it is a virtually indestructible technology.
Once you move beyond 300dpi the game starts to change.
To start with, unless the system is based on an outline font system such as PostScript, there are virtually no fonts available.
All the 300dpi libraries for HP printers and the like would look exactly the same because they are designed as bitmaps.
The 300dpi world will probably start to move to 400dpi fairly shortly but the vendors first need to make the move to using outline fonts rather than bitmaps.
Still within the page printer world, but at higher resolution, is AM Varityper's VT-600.
This is the nearest thing to typesetting yet released and it speaks PostScript so for desktop publishers looking for the quality but without typesetting it could be the answer.
The system is designed for fairly low volumes so it is more suited to an art studio than in-plant work but many companies already use it instead of a phototypesetter for much of their origination.
It still can't handle halftones but for text it is more than adequate.
With all the page printers, 300, 400 or 600dpi, the ability to produce good text and line artwork is assured, so long as the resolution meets your needs.
For photographs, however, we are still outside striking distance for quality.
Even with 64 levels of grey scanned at 300dpi and printed at 600dpi the reproduction, when printed, will be of worse quality than a newspaper photograph.
If that suits your needs, and only trial and error will prove this, then you can do it all ‘in-house’.
But, for the next step, we need to move to typesetting.
In today's market this almost inevitably means using PostScript to drive a Linotronic 100 or 300 system and, equally inevitably, relying on a bureau to do it for you as the systems cost £25,000 and up.
There are alternatives though.
If you have been using a code driven system then it's likely that you can drive alternative systems directly; GO Graphics' Deskset talks to Compugraphic systems, for example.
Some typesetter manufacturers have also produced work-rounds; Chelgraph can drive their IBX directly from GEM or Windows, for example.
The search for quality can be summed up in with a few ‘Golden Rules’.
Graphics:
1
Use drawing packages not paint packages wherever possible.
2
Avoid scanning photographs if at all possible but if you must then use a scanner that has at least 64 levels of grey and is capable of outputting TIFF format files.
3
Try to scan artwork as near to the size you want to use it in order to avoid taking up large amounts of memory and having to re-size with the desktop publishing software.
Software:
1
Ensure that the package has adequate control of typography for the work you wish to do.
2
Don't be afraid of using a code-driven package if this provides the fine control you need.
3
Make certain that the fonts used by the software exactly match those of the output device.
4
Avoid buying a system that won't communicate with a higher resolution output device such as a typesetter if you think you may need better quality.
Printers:
1
Write black laser printers should give the best quality at 300dpi compared with other page printing systems.
2
Fonts created from outline masters should be better quality than those built up as bitmaps.
3
Even at 600dpi the reproduction of photographs is inferior to newspaper quality.
4
Typesetters can be accessed by routes other than PostScript but it is essential to match fonts exactly.
5
Choose your bureau with care, not all have a background in typography or design.
6
Speak to your printer before committing to any one route as there may be alternatives such as setting from word processor disk.
If the past two years of desktop publishing has had an impact on the traditional typesetting market it must surely be reflected in the number of PostScript bureau that have sprung up around the country.
It wouldn't be fair to suggest that most users of desktop publishing systems were unhappy with the quality of their page printer's output—more that they have realised that they can improve the quality still further by going to a bureau.
During the recent explosion in numbers, a year ago there were only a handful—now there are dozens, it has become apparent that there are three distinct breeds of bureau.
The first, as typified by The Graphics Factory, is a design house that has seized on the possibilities offered by microcomputers to improve throughput and increase flexibility.
This sort of bureau is most happy when it is handling the complete job from design through to the final artwork and, in some cases, will even do the printing as well.
Our second bureau is based on or around a traditional typesetting service where they have seen customers moving to in-house production using desktop publishing and want to continue to service the high quality end of the market.
Companies of this type are, in my opinion, real bureau in that they simply process the material you supply and don't seek to interfere with the design.
They are also generally happier with a wider range of jobs, both in size and complexity because they have often cracked most of the problems already.
The third category of bureau is that which has no obvious base in either the design or typesetting market.
It is usually staffed by Macintosh enthusiasts who think that they are onto a good thing and often appear to enjoy a remarkably short life span…
Easy ways to detect this kind of outfit are to ask for popular, but not standard, typefaces or to suggest that the material will be coming on IBM format disk.
The scornful response to the latter and silence about the former soon gives the game away.
Don't let me fool you into thinking that all the third category bureau are bad, some develop into excellent typesetting houses with none of the pre-conceptions of the old brigade, it's just the majority who are dodgy.
In fairness there is a fourth category of bureau, those who don't have a typesetter at all.
In the main these are service houses who will contract out the typesetting (and generally printing) work to one of the established bureau.
There is absolutely nothing wrong with this at all, for many of the smaller companies it's the only sensible way to go.
However, there are a number of these bureau who insist on advertising the fact that they have a typesetter when they don't.
Sub-contracting works fine most of the time but if you want something done urgently and the typesetter is broken or tied up on a job for its owner then guess who's work is going to have to wait.
In order to evaluate the level of service that we could expect from a bureau we concocted a dummy page for a newsletter and sent it on disk to six carefully selected bureau.
To begin with, we weren't looking to trick anyone—the job was perfectly straightforward—and we wanted to get a good geographic spread to avoid any bias towards the London area which has the lion's share of the current bureau.
We supplied on disk a single PageMaker 2.0a page stored in PageMaker format, its PostScript output file complete with the Aldus Prep information and files for each of the three graphics incorporated on the page; Illustrator Encapsulated PostScript, PICT and MacPaint.
In the accompanying letter we requested that the sample be run out on their typesetter in order to satisfy a client that they were competent to handle a monthly four page newsletter for our mythical client on a 48-hour turn-round basis.
We also enclosed details of the particular System and Finder installed on our Macintosh together with a LaserWriter Plus sample and an approximate timing for the page to print on that device.
Pricing for the job was requested by a specified date and we asked that the disk be returned.
We mailed the six packages recorded delivery on the 14th of January and sat down to wait.
The results of the exercise are recorded below in the order they returned.
First past the post was the Cotswold Press whose sample was back on the doormat on the 16th.
The sample was accurately imaged on a Linotron 300 and the accompanying letter quoted £6 per page plus postage and packing for a monthly four page job of this type.
Cotswold quote a same-day turn-round for work received by 9.00am using Special Delivery post for the return journey although they will happily Red Star if required.
Enclose in the bundle was our sample, the disk and two sheets detailing the fonts, software and services offered.
Three bureau tied for second place by delivering on the 19th; P's &Q's, The Setting Studio and The Last Word.
P's's supplied a typeset bromide and quoted £20 ex delivery for the job.
Our sample and the disk were returned but no additional information was supplied.
The Setting Studio delivered two copies of the typesetting—no apparent difference between them—and returned the disk.
Their quotation was £12 for two pages, we had asked for a quote based on four, and although the letter promised a price and font list it was not enclosed.
While all the other samples were clean edged both of those from The Setting Studio were torn off larger pieces of bromide.
If we had actually wanted to use them we would have had to do some tidying as the area of the bromide was somewhat less than A4.
The Last Word, a recently formed bureau using refugees from other establishments delivered its offering mounted on board, the only bureau to do so.
It also enclosed a version on film which was absolutely covered in fingermarks.
While we hadn't asked for a film sample it's worth knowing that all bureau should be able to offer this service—it can save time and money at the printing end.
However, that was all they delivered—no quote, no disk, nothing.
In fact, the envelope the film sample came in carried a completely different company name and it was only our knowledge of the market that allowed us to recognise the source.
In fifth place was Stephenson Moore who delivered on the 21st.
Enclosed was the typeset sample, they were the only bureau to quote the actual resolution used (2,540 on a Linotronic 300) and returned both our laser sample and the disk.
Quotation was £24 for the four pages based on our 48-hour requirement, no indication was given of delivery charges.
Coming last, the package arrived on the 22nd, was Fingerprint.
They were the only company to contact us by phone, purely as a courtesy call, and their package took the longest in the post—four days.
However, it was the most complete.
As well as the sample, our laser proof and the disk there was a full price list, conditions of service, a very full font list, hardware and software support list, typesetting services offered, a background to the company and a page of hints and tips including a warning about the dreaded Helvetica Narrow (Cotswold also included this) and the fact that they can now set it.
They even remembered to tell us how long our page took to image on the Linotronic, two minutes.
The price of all this additional information is not shown in the quote, £6 per page.
Given the geographic spread of the ‘contestants’ it was not surprising that the packages arrived back at varying times but outlying areas such as Newcastle, Liverpool and Bristol were not obviously handicapped.
Our two top scorers; Costwold and Fingerprint, are both bureau from the second category and have a strong typesetting background.
They also know how to provide what the customer wants, even if Costwold's presentation was slightly less ‘professional’ that Fingerprint's.
The only bureau to ‘fail’ our test was The Last Word—we can only assume that someone simply had a brainstorm and left all the important bits out.
However, in a commercial sense, they won't be getting the job.
Both Stephenson Moore and P's's would undoubtedly do a perfectly adequate job for us, no qualms there, and we know The Setting Studios reputation indicates that they can do better—it's just worrying to have things left out of envelopes…
We should stress that all the six bureau were hand picked, there's another 30 or so that we could have used and which would have quite probably delivered similar results.
There are also a few that we simply wouldn't have bothered with, either from past experience or through reputation (or lack of it).
So, how do you go about choosing a bureau?
First of all, try them.
None of the six we tested included an invoice for the sample, nor have any, at the time of writing, sent one on later so it's pretty safe to assume that the trial was free.
Don't restrict yourself to local services, the postal service is better outside London and most will offer Special Delivery or Red Star if you need it.
Second, remember to provide details of the font you want, the System you use, software version number and, if possible, a laser proof.
This will enable the bureau to spot any problems before it starts and, hopefully, sort them out with you.
Fingerprint actually request that you supply a copy of your System, screen fonts and Aldus Prep to try to reduce the difficulties.
Third, avoid bitmapped graphics generally and scanned halftones in particular.
They can take ages to print and most bureau will charge accordingly.
You should also remember to put copies of the graphics files, especially EPS ones, on the disk with your pages.
We would always suggest that you supply a copy of the PageMaker document so the bureau can output it via the software if the PostScript file won't perform.
Finally, be prepared to pay a little bit more to get the service that you want rather than that which seems most convenient.
None of the charges quoted was outrageous, £5–6 per page is pretty much the norm but beware of minimum charges, and as the job we tested them on was non-urgent we could afford to be a little more flexible.
For really urgent stuff it's worth paying for reliability.
There are now, according to the official Linotype list, some 120 bureaux dotted throughout the United Kingdom equipped with PostScript imagesetters.
These organisations are ready and willing to accept your work and reproduce it to a significantly higher quality that you can achieve with a page printer such as Apple's LaserWriter or even AM Varityper's VT 600.
Notionally, each of the bureau should be able to provide an identical service but, as we know from our own experiences and those of our clients, this turns out not to be the case.
The reasons for the variations are many but there are probably some underlying trends that make it easier to pick the right bureau for the job.
In a survey carried out earlier this year for DTP Desktop Publishing magazine, a sister title to MacUser, something over half of the bureau had their roots in traditional typesetting while around a quarter came from the printing side of the business.
Both of these will obviously know their picas from their points but do not necessarily have any experience with the Macintosh (or any other computer system, come to that).
The remainder of the bureau questioned, around 20%, either had no traditional typesetting or printing background at all or came from the computer services sector.
If all you want is a simple page of text run out in one of the standard LaserWriter fonts then any of the bureau should be able to manage that without any difficulty at all—if they can't then they probably won't last long in the business.
The fun comes when you want to produce real publications with mixed text and graphics, multiple fonts and even the possibility of scanned photographs or colour separations.
Here the men get well and truly separated from the cowboys.
Possibly the biggest single problem area at the moment is that of fonts.
Not all bureau have all the fonts and while most have a good range from the Adobe/Linotype collection few seem to cater for the other vendors such as Monotype, Compugraphic, etc, etc.
Obviously, if your document uses Monotype's Times New Roman then there's no earthly point in sending it to a bureau that hasn't got the face.
(Incidentally, most bureau will buy in typefaces for clients so long as either the client pays for it or there is going to be sufficient volume of work to justify it.)
However, even if the bureau has the typeface it may well not appear on the output due to the vagaries of Apple's font numbering system.
If you are using special fonts do check with the bureau first, they may provide you with a copy of their screen font to install on your system as a way of ensuring that what you send them matches what they send you back.
(As a legal aside, it appears that screen fonts are not so vigorously copyrighted—or at least protected—as the printer fonts.
Copy the screen fonts freely but copy the printer fonts and you may well face some unpleasant consequences.)
Once over the fonts hurdle you will doubtless be pleased to find that there are other potential stumbling blocks placed in your way.
First, and most common, is that of version differences.
Some program upgrades do truly behave in the same way as their predecessors but this is the exception rather than the rule!
Just because you output the document to a LaserWriter Plus from XYZ Publisher version 1.2 does not mean that the bureau will get the same result from version 1.35 talking to a Linotronic 100.
Quite apart from the program differences there are changes in the way the output is handled for a higher resolution device and there may be significant changes in the versions of PostScript being used.
Always check that the bureau is running the same version of software as you are — and that applies to the System and Finder as well.
Most of the better bureau do keep libraries of older versions of the programs and will make sure that they use the correct one—but they can only do this if you ask.
If all is running smoothly at this point you have two further pitfalls awaiting you.
The first is the classic bitmap graphic output when you expected a beautifully drawn diagram.
I am, of course, assuming that you all avoid paint programs like the plague when it comes to professional desktop publishing!
The normal reason for this is that, although you saw the graphic on the page and it printed correctly on the LaserWriter you copied the publication onto a disk and sent that to the bureau.
This is a common problem with PageMaker—though not exclusive to that program—and is caused by the program losing its link to the graphics file when it comes to printing from the copy.
As a result, the only thing that it can print is the 72dpi screen image and hence the resulting mess of your document.
The answer is to make sure that all graphics are sent to the bureau with the publication so that the links can be restored.
It is worth, at this point, stressing the absolute need to enclose a LaserWriter proof of your document showing the graphics files used and their names as well as indicating all the fonts.
Although bureau primarily exist to simply output your files direct to bromide or film most of them will make sure that the output is what you were expecting before they send it back.
Unless they have a proof copy there is no way that they can spot any of the above problems.
The second problem that graphics can bring is when you have been active with that 256 greyscale scanner which seemed like such a good idea.
Quite apart from introducing the problem of just how you get the document to the bureau in the first place (we know of people who have extra hard disks for just this purpose) the time it takes to run such a document through an imagesetter can be significant in the extreme.
In the USA most bureau charge by the amount of time that the document takes with a fixed cost for bromide or film—usually by the foot.
Over here the practice has yet to catch on but do expect your bureau to charge you more if there are large scanned images.
You should also, of course, warn the poor chap first so he can run your job overnight rather than have it tie the system up during the day.
So, what are the basic rules about choosing a bureau—bearing in mind the potential problems?
First, shop around.
Do not be afraid to ask a selection of bureau to quote for a job, even to output a sample page.
This will allow you to gauge their response time and, most important, to see what sort of job they produce.
Make the test pages an accurate reflection of the sort of work that you will be sending and take the time to explain what they contain, where the files come from and always include a laser printed proof.
Once you have chosen your bureau make sure that they know everything about your system and the way that documents will be presented.
It is quite likely that they will make suggestions or ask that the work is prepared according to a set of guidelines that they provide.
This is as much for your benefit as theirs so it does pay to listen—otherwise they may well turn round and say ‘we told you so’ when it all comes out in Courier.
Do make sure that every job that gets sent out for setting has a full specification and requirements sheet with it.
This should state the pages that are required, the number of copies, whether there are crop marks needed or colour separations, etc, etc.
Most of the bureau don't supply order forms—most of their work comes in on spec—and so it is very much up to the customer to specify what is required.
And, of course, who it is for and where it is to be sent back to—facts which often seem to be forgotten.
In the majority of cases all will go smoothly—although sometimes the Macintosh seems to conspire to create problems all its own on long jobs—and the caveats listed above will not apply.
Murphy's Law, naturally, decrees that only the important, urgent or totally trivial jobs will get into difficulties and it is here that the bureau can really play its part.
If they know everything about a job then they may well be able to fix the problems for you.
If you have failed to brief them properly then they have little option but to either put it on hold or send it back as it came out and let you sort it out.
On these occasions you will often be glad that you didn't choose your bureau simply on the basis of either price of convenience…
Desktop publishing systems offer business the chance to reduce their dependence on external agencies such as design houses, PR companies and advertising agencies.
They certainly don't, at today's level of sophistication, eliminate that dependence.
Nor, as is often believed, do they remove the need for traditional print technology.
The ink on paper process is still essential if you intend to produce quantities rather than single copies.
Just as the introduction of word processing made it easier for people to produce and maintain large documents, so desktop publishing makes it easier for those same people to produce professional looking publications.
However, where word processing is simply a more efficient form of typing and requires no great understanding of design or layout, desktop publishing demands that these things be understood.
Ignoring that difference could be one of the worst mistakes you make.
In a world where, far from becoming ‘paperless’, our output of printed material is doubling every three years it is hardly surprising that any attempt to increase our efficient use of paper is rapidly accepted.
Just three years ago desktop publishing was virtually unheard of, today we are as familiar with it as with the spreadsheet, the word processor or the data base.
Sadly, we are not yet as familiar with its correct or appropriate use.
The publishing process is not a single act, as is word processing, but a long and complex undertaking.
Certainly, it includes elements with which we are all familiar but there are aspects which need a completely different approach from conventional office automation.
That is not to say that someone who is using word processing or a similar application will not be able to make the best of a desktop publishing package but rather to point out that new skills will need to be learned, new concepts understood.
It is essential to realise at the outset that desktop publishing software is totally unlike any other software product category.
To begin with, by itself it doesn't produce anything.
It most closely resembles an infinite supply of blank sheets of paper onto which items may be positioned in order to create a page or a document.
This may contain text or graphics or both.
The shape, style and content of these items can be altered at will as can their position but without ever reaching for scissors or glue.
Desktop publishing acts as an integrator of the output from other office automation packages.
The user creates the pages by manipulating this information so as to make it pleasing to the eye, informative, amusing, or whatever effect is required.
The need to understand design is often heavily stressed during conversations or articles about desktop publishing.
A rather more realistic approach would be to point out that there are certain conventions which have been imposed by traditional working methods.
The freedom gained by using electronic means to create the page has already changed those working methods and is, itself, leading to new conventions.
For the desktop publishing tyro, however, there are some sensible guidelines which can be observed in order to prevent too terrifying an experience during the initial phase.
Like all good guidelines these are simple and, generally, common sense.
Once the initial novelty has worn off they will often no longer be needed, you'll understand the concepts better and be able to make your own judgements.
Desktop publishing is one of the most seductive executive toys that can currently be found on any computer system.
The sheer freedom to play around with typefaces, styles and sizes—a process impossible with conventional word processing or typesetting—tends to mean that users will try all the possible combinations.
Whilst this may be ‘wrong’ according to the traditional school it costs nothing apart from time and quickly reveals both what does and doesn't work in terms of presentation.
The most fundamental realization that needs to be made is that desktop publishing uses ‘real’ typefaces which are proportionally spaced and not the monospaced characters of the word processing world.
Because of this you will need to develop the idea of working within a grid.
The grid is really a set of guides which help you to produce a consistent document and in traditional printing would consist of sheets of heavy paper pre-printed with a pattern of blue lines.
(Blue doesn't reproduce when photographed for printing) Within this framework the typeset text would be stuck down and photographs and illustrations added as required.
The whole sheet would then be photographed at actual size and the resulting image used to make a plate.
This latter stage; the photography and plate making, still forms a part of desktop publishing where large numbers of copies are required.
Designing a grid for the pages you wish to produce is really a matter of commonsense.
With the A4 page so firmly entrenched the number of options is rather restricted; one column of text is too wide to read comfortably, four columns are too narrow for anything other than magazines or newsletters.
The choice, therefore, rests with two or three.
Other elements of the grid, spaces for photographs and illustrations, page numbers and other items that will appear on each page can also be added at this stage.
Creating grids with desktop publishing software is a matter of moments with most of the good packages and, once created, they can be used over and over again without ever needing to be re-drawn.
Choosing the typeface and style to produce the document in is the next biggest hurdle.
Because of the freedom most users find when they move from the word processing market into desktop publishing many early documents resemble Victorian handbills in design.
There seems to be an almost universal delight in trying out all the fonts on one page!
Once again, it is only the traditional approach which says that this is actually wrong.
Usually the choice of typeface and style is simple to make; pick one that looks good to your eye.
However, once you have chosen a typeface, Bookman for example, stick to it.
A good rule of thumb is to restrict your early use of type to one or two typefaces in the document in no more than three sizes.
With a word processor you might get bold and underlined with, perhaps, italic.
Apart from the variations in pitch the other typographic controls available are limited in the extreme.
Now you have entered the world of desktop publishing there are many more controls to consider and many more traps for the unwary.
In general terms it is best, but not essential, to choose one typeface for the main text and a different one for headings.
Traditionally, and with good reason, large amounts of text are set in a serifed face (that's one with the little tick marks at the ends of the letters) and headings are set in a typeface that doesn't have them; a sans serif face.
The two other main decisions that have to be made at the design stage are the sizes of type and the style in which it is set.
The size of the type and the amount of spacing between lines, the leading, are very much more controllable within desktop publishing than word processing.
Type sizes are measured in points; one point is roughly  of an inch, and can normally be controlled in at least one point increments.
Just as with word processing type can be set flush with the left-hand margin, centred or justified.
In this latter case it is important to realise that we should expect to get true hyphenated justification or Has it is commonly known.
Words can be split either according to a set of pre-defined rules or from a table of correct hyphenations but in both cases ensure that English English is being used rather than American.
Most packages now support a full range of European language hyphenation rules making life substantially easier for those working in the international market.
Part of the decision as to whether to justify text or not should rest on the type of product that is being produced.
The human eye and brain are much happier reading short to medium length unjustified lines although books are conventionally justified.
Once again, however, it costs nothing to try an idea out on the screen.
It is often assumed that the world of desktop publishing begins and, for some people, ends with the Apple Macintosh.
While it is undeniable that that system has had a dramatic effect of the development of the market it is incorrect to assume that it is the only one which is influencing it.
In fact, there were electronic publishing systems around long before the Macintosh ever appeared and the first ‘desktop publishing’ package, at least in the terms we understand today, was DO-IT by Studio Software which ran on the PC.
So, why has the PC taken so long to get to grips with the market and how is it faring today, some two years after the phrase ‘desktop publishing’ was coined.
The simple reason that the PC took so long to catch up is a direct result of its design.
The PC was conceived, primarily, as a text and number processing system and was not equipped with anything approaching a decent graphics capability.
While third party developments such as the Hercules graphics cards helped relieve this situation they complicated the life of the software developers who had to provide drivers for each and every variation.
The Macintosh, on the other hand, was a closed system and, by design, forced software developers to work through a single, common set of drivers.
And, being designed to treat everything as graphics, it was readily adaptable to applications such as desktop publishing.
Indeed, Apple designed both the screen resolution and its internal software routines to match typographic standards so the task was made even easier.
However, the PC standard has moved away from original CGA toward EGA, VGA and even higher resolutions, so easing the display problem, while operating system vendors such as Microsoft and Digital Research have delivered environments closely matching that of the Macintosh.
The significance of these environments is more than just their friendly appearance to the user and their use of graphics rather than text standards.
Their major contribution is the provision of a set of standard routines to drive the various devices such as high resolution monitors, page printers and so on.
This, in turn, relieves the software houses of the problem of having to write and test numerous device drivers.
In theory, therefore, just as with the Macintosh, a single piece of PC software can now operate in any hardware configuration the user desires.
The practicality, needless to say, is not quite so simple!
With the environments came a new piece of jargon; WYSIWYG.
Now accepted in common parlance, it stands for What You See Is What You Get, the implication being that the image you see on the screen will be exactly that which you get on the page.
This, sadly, is also only partially true as the resolution of even the very best screen available today is around 150 dots per inch while, as we will see, the current generation of page printers produce 300, 400 or even 600 dots per inch.
What you get will, in fact, be very much better than what you see!
Taking place at the same time as the development of graphics capabilities was the introduction of printing devices that could reproduce the images created on the screen.
The traditional dot matrix printer is fine for hammering out drafts and even pseudo letter-quality documents but cannot hope to produce typographic quality text.
Books, newspapers, magazines, etc, are generally typeset with a resolution of 1,000 dots per inch or greater.
Dot matrix printers can, at best, manage 240 dots per inch and are both slow and noisy.
Their replacement, at least as far as desktop publishing is concerned, is the page printer.
Often called laser printers because many of them use a semiconductor laser to expose the image onto the drum, they are based on photocopier technology and produce an excellent substitute for traditionally typeset material, so long as the quality requirements are not paramount.
The main problem with page printers is in their control and developments here have been rapid indeed.
After many years languishing in the backwaters of Xerox's Palo Alto Research Centre the page description language has finally blossomed forth, although not, it must be said, from Xerox.
Current leader of the pack, but by no means the only one, is Adobe's PostScript.
A page description language is, essentially, a programming language that allows the elements of a page; type, graphics, rules, scanned photographs, etc, to be described mathematically and reproduced on a printer which is equipped with the appropriate device for understanding the language.
PostScript was first adopted by Apple and is now the preferred or primary page description language of virtually every major manufacturer from AST to Wang, including IBM.
Many, indeed the majority, of the page printers sold are not equipped with a PDL; Hewlett Packard's LaserJet, the biggest selling device in the market, does not support one other than as an optional extra.
If the user only wishes to produce text on the system and is prepared to restrict this to a few styles and sizes then such a device is perfectly adequate.
For graphics, at least simple bit-mapped or paint-type ones, all that is needed is extra memory; an A4 page of graphics requires at least 1M of memory.
What such a printer will not be able to handle are scalable fonts, that is the ability to choose a typeface and produce any size of type you require when you require it, nor will it be able to cope accurately with re-scaling object or draw-type graphics such as those produce by CAD or professional graphics applications.
As the hardware development gathered pace so has that of the software.
First away from the gate was Xerox with their acquired Ventura product.
This is an excellent product for producing long documents; books, manuals, reports, etc, where there is a rigid structure.
It works best when its style commands, called tags, are embedded in the original word processor text file and these are then fed directly through Ventura's style sheet.
The speed of document production is extremely impressive; I have assembled and printed a 280-page directory consisting of over 40 individual text files in little more than two hours from start to finish using this approach.
On the debit side it must be said that Ventura is not really suited for use on documents where the styles and formats change from page to page; newsletters and magazines, for example.
This is not to say that it cannot be used, merely that it is less than efficient.
It also suffers from a purely ‘mathematical’ approach to its typography although this issue will be corrected from Version 2.0, due to be released towards the end of this year.
Aldus' PageMaker, the doyen of the Macintosh desktop publishing world, took rather longer to migrate onto the PC that had been expected but is now very firmly established.
Almost the reverse of Ventura, it allows the user total control over the production of each page but still allows limited automation of the process with tags and templates.
However, it so closely matches the traditional methods of cut and paste used within publishing houses and art studios that it is extremely easy to both learn and use.
The two products are complementary rather than directly competitive and most serious users end up with both.
With these two products firmly established as the market leaders other products are having a tough time breaking through.
Among the contenders for the PC market are Lotus Manuscript, IMSI's PagePerfect and a number of low-cost products such as Digital Research's GEM Desktop Publisher and Software Publishing's pfs:First Publisher.
On the Macintosh the introduction of Interleaf, previously restricted to Unix workstations, and document processors like FullWrite have kept pace with the pure layout packages such as Ready, Set, Go! and Quark XPress.
With the introduction of these and other products the market is beginning to segment into a number of well-defined categories.
At the top end there are the programs that seek to reproduce the environment found within a traditional art studio; PageMaker, XPress and the now defunct Harvard Professional Publisher most closely fit this category, while products such as Ventura seek to provide the same typographic quality through a stylesheet and coded tags so appealing to the business user who needs an easily produced document which follows a common format.
It is in the area below these two groups that the real battles will almost certainly be fought as the word processor vendors look to enhance their products by adding typographic control and the ability to include pictures within text.
Products like GEM Desktop Publisher and pfs:First Publisher require new skills to be learned as they are a completely separate product which can be used to enhance the output from a word processor.
PagePerfect, on the other hand, takes the approach of offering an in-built word processor, it emulates Wordstar and Multimate, and adding complex document formatting capabilities onto these features.
It further relieves the learning process by using a highly visual interface which, once understood, can be replaced by a faster and more efficient coding system.
Within an office environment where there seldom seems to be time to learn new software this approach may find a considerable following.
There is, fortunately, only one really good way of deciding what software to buy for desktop publishing and that is to take the document you wish to create on the system along to the demonstrations.
Unless the system can be shown to reproduce it more efficiently than any existing system it is probably not worth considering.
There are many cases where varying documents are required and it is likely that no one single product will be able to do them all.
Because of the very nature of desktop publishing this should come as no surprise.
As I have pointed out already, desktop publishing software doesn't really do very much on its own, it requires the output from a number of other packages; word processors, graphics programs, data bases and spreadsheets, to produce the raw information which can then be manipulated into a final form.
The degree of control required, or the ease of use, will directly affect the suitability of the product.
It's rather like DIY in that one day you may need a power saw to cut up some timber, the next a hand saw for some precision work.
Both are valid tools for the job but only one is appropriate at any given time.
All the points raised so far are conceptual rather than practical and would apply to any publication method from hand-set lead type through to true electronic publishing.
Where desktop publishing begins to score, even over its close cousin corporate electronic publishing, CEPS as it is known, is in its ability to integrate with current personal computer systems.
Whilst Apple were undoubtedly the first to successfully market a desktop publishing system, it was Xerox who invented it, the business world tends to run on PC-type systems rather than Macintoshes.
Early PC-based software was both expensive and fairly awful; Studio Software, who produced the first desktop publishing program for the PC recently went to the wall as a direct result of being unable to keep up with the new leaders.
Any desktop publishing package worth considering should be able to read files from a wide range of word processors, data bases, spreadsheets and graphics packages in their native format.
That is to say that a word in bold in your word processor file should still be bold when it gets onto the page, even though it has changed from being monospaced typescript to a real typeface and may be in a different size altogether.
Similarly, graphics files should be able to retain their formats and display an accurate representation of their content either when viewed on the screen or printed on the page.
Using graphics in a publication produced by traditional means is straightforward.
Once the drawing has been created it is measured up and a reduced or enlarged version is stuck onto the page prior to being photographed for printing.
There is absolutely nothing to stop this method being used for desktop publishing and where the original only exists in printed form it may be the only viable method.
If, however, the lure of creating illustrations by electronic means is strong consider the following carefully.
Before choosing a painting or drawing package it is important to realise the fundamental difference between them.
A painting program creates images as a pattern of dots on the screen and the resolution of that screen determines the resolution at which that image may be printed, regardless of the resolution of the printing device.
An image drawn on, say, a Macintosh screen is stuck forever at 72dpi whether printed out on a matrix printer or an imagesetter.
A drawn image on the other hand consists of a series of co-ordinate points and instructions on how to joint them up.
Because these instructions are stored, and not the pattern of dots, it is possible to reproduce them on any system at whatever size is required.
Patterns of dots from a painting program tend to fall apart when enlarged or coagulate into muddy puddles if reduced.
For serious work, therefore, stick firmly to drawing or object oriented programs.
Photographs are widely used in publications but, despite the persuasive nature of scanner manufacturers, they cannot yet be successfully integrated into desktop publishing.
That doesn't mean that you cannot use photographs, merely that the traditional methods still produce better results than the electronic ones.
Scanners convert the image they are given into a pattern of dots, typically at a resolution of 300dpi.
If this is printed directly on a page printer at the same resolution the results seem reasonable but attempt to reproduce the image by photocopying or traditional printing and the lack of quality is all too apparent.
A 300dpi scanner can manage to scan in line artwork but, apart from using it as a guide, photographs are best left well alone.
The problem is two-fold.
Photographs consist of a continuously varying tone, hence the name contone in the printing world.
To reproduce them by traditional means has required a special camera which can reduce the photograph to the required size and, at the same time, convert it into a pattern of dots—a process called halftone screening.
What makes this pattern of dots different to those that can be produced by a scanner and page printer is that they vary in size.
A basic scanner can capture a dot as either being there or not, it is a binary device.
More sophisticated scanners can capture levels of grey as well, but they require significantly more memory.
An A4 page scanned at 300dpi needs just over a megabyte of storage, the same page scanned at 16 levels of grey would need 4 megabytes.
The base level for anything approaching quality reproduction would be 64 levels and this needs over 6.5 megabytes.
The problem doesn't end there.
The page printer is a binary device, it either prints a dot or it doesn't, and is, therefore, incapable of producing the dots of varying sizes.
The scanner manufacturers use lots of clever software to simulate halftones by a process called dithering.
This uses a varying pattern of dots to create the effect of varying intensities of grey but, at 300dpi, it is a pretty poor attempt.
To achieve newspaper quality reproduction, the lowest we tolerate in daily life, would require a 700dpi scanner and a 700dpi page printer.
Because photographs and line artwork processed through a scanner are captured as bitmaps all the earlier comments about painting programs apply equally when it comes to re-sizing them for inclusion within a page.
Two very significant products, Adobe Illustrator and Aldus FreeHand, looks set to change that for line artwork at least but it will be a year or two yet before scanned photographs become a reality.
Collecting all the raw material to create the final page or document is only the beginning of the desktop publishing process and is something that would have to have been done whatever system was being used.
It is at this point that things start to change and we can add the phrase page makeup to the vocabulary.
Given that you have already been through the design process and selected the details concerning the number of columns, typeface and so on, now is the time to load all the prepared information into your chosen publishing package.
The choice of which package to select is usually helped considerable by a number of factors.
First, and most important, is the type of product you wish to produce; is it a short document or a long one, does it include illustrations or photographs, what methods are currently used to produce it, and so on.
Secondly you must consider the environment within which the work is done; is it based on PCs or is there a free choice of machines, will data files come from one program or many and are they the same type are just some of the immediate questions here.
Finally you need to consider the people who are going to be using the product; are they writers, or designers, or managers.
There are fundamentally two different approaches to creating pages electronically.
The first method follows the conventional cut and paste concept with varying degrees of enhancement while the second removes much of the drudgery and lets the software handle the complicated stuff.
It is important to realise early on that the degree to which you can let the computer get on with producing your pages automatically corresponds exactly to the amount of control over those pages that you will be able to exert as a user.
In the good, old-fashioned days text was sent off to be typeset and came back in long strips called galleys.
Assuming they were free from spelling and other mistakes, a process which may have involved several attempts, these were cut up and stuck down onto a master layout sheet using wax or gum.
When an illustration or photograph was to be used the appropriate area was opened up and the relevant item stuck in.
If text needed to be re-set for any reason it was back to the typesetter again.
This process has been accepted and developed since the first typesetting systems which produced galleys were introduced—indeed an identical process was used with lead type but in an upside down and back to front sort of a way.
It is interesting to note, therefore, that the best-selling desktop publishing package on the market today, Aldus PageMaker, follows this process exactly.
Text from a word processor file is flowed onto the page as a galley of typeset material.
The typeface, size and style are set before the text is flowed, as are the margins but any or all of these can be altered at any stage.
This eliminates the traditional need to get things re-set—in PageMaker it's a trivial task although sometimes a little tedious.
PageMaker also keeps track of all the bits of the galley so if a section is moved or deleted all the other portions move in sympathy.
The benefits of this method are that it can be easily understood and it gives total control over every element at all times.
A variation on this theme is found in packages like Ready, Set, Go! and XPress.
Here the galley is flowed into frames or boxes that have been previously defined.
This can be much quicker, but although the control is there it is not quite so intuitive to use.
The other main contender is the stylesheet approach as used by Ventura.
Here tags are attached to sections of text which is then dropped into a template or pre-defined page layout.
The tags can have meaningful names like HEADING or BULLET which hide a very complex list of typographic controls.
These can determine the typeface, size, style, leading, kerning, line-breaks and so on completely automatically.
This makes Ventura ideal for publishing long, regular format documents like books or manuals where the main desire is to keep the style consistent.
The concept tends to fall down slightly when variations are required.
It is possible to start off with just one or two tags which control the main typographic elements but by the time page numbers, headers, footers, indexes, etc have been added the list can get unwieldy.
The ideal place to add these tags is at the stage the document is created, otherwise the process is rather laborious.
Given a pre-tagged document and a pre-designed template, however, Ventura can produce pages faster than anything else running on a micro.
The other side of the argument is that, as I commented earlier, giving the control over to the computer reduces the capability of the user to make changes and producing short documents with complex layouts is not a task for Ventura.
Regardless of which product you choose and, if you produce different sorts of document you may well end up with more than one, the important thing is to select the correct tool for the job.
In some cases this may even mean not using a page makeup package at all but rather a high-powered word processor like Lotus Manuscript, Word or WordPerfect 5.0.
It is vital to match the software to the task, not the other way around.
It is also important to realise that the majority of design decisions are simple ones.
Indeed, the best designs usually are very simple and elegant rather than cluttered or busy.
Remember, above all, that the purpose of the document is that is should convey information quickly and clearly.
It is amazing the number of supposedly professionally produced documents which are actually un-readable.
Stand back from your work and actually try to read it; are the headings clear?
Is the text sensibly laid out?
Is the reader lead through the text in the correct order?
These are just some of the simple questions which, if asked, can prevent novice desktop publishers, and even a few older hands, from making fundamental errors.
Just as the advent of the word processor allowed people to produce text more efficiently, so will the introduction of desktop publishing allow people to produce more documents.
But, just as with the word processor, the content and presentation of those documents do not necessarily reflect a similar improvement.
It is often the case that the quality of the documents produced by someone adopting desktop publishing goes down rather than up.
After all, with perhaps one typeface and one size from your word processor there was precious little opportunity to make much of a mess!
If desktop publishing is considered as a tool then it is important, as with any tool, to select both the correct one for the job and then use it in a sensible manner.
Most of the techniques are simple and, generally, based on common sense.
If you try to make life complicated for yourself by using the wrong tool or handling it in an inappropriate fashion then the result is solely your responsibility.
There is just time for some words of warning.
Desktop publishing is a probably the best executive toy ever invented.
Unless careful control is exercised over its introduction it can have unpleasant effects on things like corporate image, house styles and general productivity.
Memos and letters have a habit of being decorated with dozens of fonts or cute little pieces of artwork.
Some companies even report losing credibility for a brief period as their documents have been so badly presented.
It should be clear by now that this isn't the fault of desktop publishing, merely of the way in which it has been implemented.
If you have relied on the services of external designers to produce artwork it is foolish to imagine that internal staff with no training can achieve similar results.
It is similarly naive to believe that management who have relied on these external services will necessarily be able to control them when they are brought in-house
Designing and producing better pages
The design criteria for desktop publishing are simple enough if you follow the basic guidelines.
Henry Budgett explains.
The starting point for any document is the audience it is aimed at.
If you don't know who that audience is then you really do have a monumental task in front of you.
The design of any document should be influenced by its intended readership; a newsletter for, say, the legal market would have a very different ‘feel’ to a marketing brochure for the leisure sector.
The audience influences the style by indicating the seriousness, formality, or otherwise that the publication should adopt and the first area that this affects is the way the text is laid out on the page.
There are a number of options available to the publisher who is stuck, as most of us are, with the A4 page.
The word processor approach of a single column of text simply won't work when it comes to desktop publishing and proper typefaces.
A line of 60 characters printed on a typewriter looks OK but a 6″ line of type set at 10pt is virtually unreadable, simply because the eye gets bored and stops short of the end.
Two columns of text across an A4 page are fine, three is more versatile and four or five can be used but with care by the novice.
By far the most popular design for an A4 page, by usage if nothing else, is that of the three-column grid; that is to say a page divided into three equal text or graphic columns.
However, there's a lot more to consider than just the number of columns.
If the top and bottom of the page are left open the eye tends to wander away and not locate the beginning of the next column properly.
Ruling off the tops and bottoms of each page also allows the use of page numbers, headers, footers and various other devices to be used to keep the reader constantly informed as to what's going on.
Once again the nature of these devices and their complexity will be heavily influenced by the publication's audience.
Setting out the structure
So, to take a fairly typical example, let's begin to design a newsletter.
We know the audience we wish to reach; it's a technically literate readership who want information to be presented quickly and clearly so a simple, consistent layout and good visual signposts are paramount.
We'll chose a three-column grid because this is fast to work with while still allowing a good degree of flexibility.
The next choice is to select the typefaces to be used.
An enormous amount of rubbish is talked about type.
There are really only two important considerations as far as the desktop publisher is concerned; is it readable and does it look good.
You'll generally find that a serif face, that's one with the little ticks at the ends of the letters, is much easier to read in large quantities than a sans serif one.
Tradition rules, therefore, that you set the text in a serif face such as Times, Palatino, Bookman or Century Schoolbook while the headings are contrasted in a sans serif one such as Helvetica or Avant Garde.
We'll use Helvetica and Times, both because they work very well and most page printers come equipped with them (although often under false names like Swiss and Dutch).
It is only right to point out that there is nothing particularly ‘wrong’ in using a sans serif face for the text and a serif one for the headings, just that it needs a bit more care.
We'll use Times Roman (that's normal Times to you and me) in 10pt set justified across three columns.
The term justified means that the text lines up down both left and right margins, just like in a book.
Justified copy also has the effect of looking more authoritative than ragged setting—where the right-hand margin is allowed to float according to the amount that can be fitted onto the line.
We'll also indicate the beginning of each paragraph by indenting the first line, except where that paragraph is the first of a section.
Article headings will be set in Times 14pt Bold to give them a bit of impact while headings within the text, cross or subheads to give them their proper name, will be in 10pt Helvetica Bold.
Because Times is a fairly heavy face, that is, it looks very dark when there's a lot of it on the page, we'll lighten it a little by having more space between the lines so the leading or inter-line spacing will be set to 11pt.
This also makes our text much easier to align as everything will be set to the same leading.
Take any desktop published document and look across the page.
In most cases the text in the columns won't line up which indicates that the person who put it together didn't know about this little trick.
One point well worth noting is that you should restrict the usage of typefaces within a single document or publication to two or, at the most, three.
Type sizes should also be restricted with text, heading and caption sizes being easily distinguishable.
It is possible, given a degree of understanding, to break these rules without any detrimental effect but, for the beginner, keeping to these rules will prevent you creating anything really horrific.
We have a term for publications which break the rules; Victorian Handbills.
It's definitely worth writing down a style-sheet for each design you create as this allows a you to maintain a much more consistent style across your various publications; a house style in effect.
Adding an identity
Our basic newsletter format is complete but lacks any real identity so the next phase is to add the little touches which make it distinguishable from the crowd.
Starting with the title page of the publication we, not surprisingly, need a title.
Keeping things simple, generally the safest approach, means that we'll use a standard typeface but use it very big.
As we are trying to keep the whole publication as simple as possible this means that we'll use Times again but if your page printer isn't a PostScript device you may have to create the title in a graphics package and import it.
To indicate the page we're on there's a number centred across the bottom of the page below the rule while on normal pages we'll have a strap indicating the title and issue date on the outside edge of each page; recto and verso headings to use the official terminology.
And that's just about it for the basic framework of the publication.
Adding some images
Most documents could definitely do with some brightening up; the question is, what sort of illustrative material to use?
There are basically three types, at least so far as desktop publishers are concerned; Bit maps, photographs and object oriented graphics.
Bit mapped graphics : Certainly the most common, these derive their name from the fact that they are made up from individual dots or pixels, each of which represents one bit of computer memory.
Painting programs such as MacPaint, Windows Paint, PC Paintbrush, GEM Paint and a host more, all use this method although they all use different file formats to store the information—a problem in its own right.
While creating a bit mapped image is quick and easy it does have a number of significant disadvantages.
The major one is that image is fixed at the resolution of the device that created it; a picture drawn on a CGA screen stays at that resolution regardless.
Worse, however, is the fact that the image is also fixed in its proportions and, unless it has been created at precisely the size you wish to use it, it will distort when manipulated by the publishing package.
Bit mapped images are also generated by scanners.
There are several proprietary file formats around that scanners can use to store information but the one that has gained industry-wide support is TIFF or Tagged Image File Format.
Unlike the paint file formats used for binary (black and white) images, TIFF is capable of supporting grey scale information which makes it extremely relevant to the next image type we'll be looking at.
Photographs:are certainly the most popular form of illustration but, as yet, desktop publishing systems cannot handle them very well.
Images scanned and printed on a 300dpi system using 32 levels of grey look surprisingly good; better than you might expect at any rate.
The problem is reproducing the image in bulk; photocopying simply reduces it to a uniform blur, traditional litho printing is much the same.
Overall, it's best to leave the photographs out of the electronic side of things altogether and get them reproduced optically for you by your printer.
This reduces the amount of memory your file needs, speeds things up and gives a much better result at the end of the day than you could ever hope to achieve with a scanner.
Object oriented graphics : are the other type that can be created on a computer and here the packages have names like MacDraw, Windows Draw, GEM Draw and AutoCAD.
Instead of creating the image from patterns of dots the data is stored as a set of instructions with each element being an individual object.
A straight line, for example, would be defined by its start and end co-ordinates and the thickness of the line.
This means that the information is portable between systems of differing resolution and, more crucial for the desktop publisher, can be re-scaled as required.
If you are going to use computer generated artwork in your publications, be they business graphs, drawings or logos then ensure that they are created with a drawing package not a painting one.
The final benefit is that the files are much smaller than those of a corresponding bit map image.
There is a new and special class of object graphic and these are the ones created by a page description language such as PostScript.
Page description languages are often though of as being the means of outputting information but they can just as easily be used as a method of receiving it as well.
Adobe's Illustrator, and many others, can export their PostScript files to any package that can understand it, be it PC, Macintosh or workstation based.
This is true portability and is almost certainly the way the industry will go in the future.
Having decided what sort of images you want to incorporate into your publication, and ensured that they exist in a form that the publishing package can understand, the next problem is that of positioning them.
The golden rule here is one of balance.
I find it often helps to hold the page at arms length, of further if possible, and judge the overall image of the mixture of text and image.
It's rather like deciding where to hang a picture on a blank wall.
Professional designers will come out with all sorts of advice but as this is intended for normal people I'll suggest that you just go with what looks right to you.
Don't over illustrate is a rule that should be adhered to though.
It's also important to get the size of the image right.
Some photographs or illustrations may contain unwanted material and, if you don't need it there's nothing to stop you cutting it out; cropping in art terminology.
A cropped picture should have more impact than an uncropped one but beware of over-cropping, the eye needs room to move round the image if it is to absorb the information.
Don't underestimate the importance of captions either.
Although a picture may be worth a thousand words the reader still needs to know what the picture relates to.
It is also worth framing pictures with a box or rule, once again to help the reader focus his or her attention on the image.
This also helps the printers with the positioning if you are supplying the images as artwork rather than treating them electronically.
Used sensibly photographs and illustrations can enhance a publication and transform its readability.
Conversely, they can complicate the material and, worst of all, distract the reader from the text.
As with the basic advice for the textual part of a newsletter the message is keep it simple.
If it looks better with a picture, use one.
If it doesn't then don't.
Keep with that simple guide and you won't often go far wrong.
Digitisers
The pantograph is probably the simplest type of digitiser there is; and for home computer use it is completely adequate.
A pantograph consists of two hinged arms, the ‘elbow’ being free-moving while the ‘shoulder’is anchored to a fixed baseboard.
The shoulder and elbow joints are built around precision variable resistors and as each joint swivels so the variable resistor turns.
The value of the resistance is a measure of the angle that is formed between the two arms at the elbow and the arm and the baseboard at the shoulder.
This technique provides a constantly changing voltage which can be fed to the computer through a suitable analogue input.
The mathematics required to convert the two voltages back into angles and hence into an actual position on the baseboard are relatively complex but once the relationship has been established the system can be made self-calibrating.
If, for example, three known positions are input to the program before each session with the pantograph the software can compensate for any changes in the expected readings due to wear and tear or temperature.
Several commercial pantographs are available, mostly for the BBC Micro, and some are even offered in kit form for the adventurous to build for themselves.
One stage more advanced than the pantograph, although still lacking the sophistication of a magnetic or acoustic digitiser, is the pressure sensitive digitiser.
Often referred to as a ‘bit pad’(although that is the name of a specific device) it can take one of two forms.
The simpler of the two is based on a resistive sheet, often just heavy paper with a graphite coating.
If an AC voltage is passed across the sheet a stylus will be able to detect the potential at any point.
Using an electronic sampling method which is locked to the same frequency as the supply voltage it is possible to derive a direct relationship between the voltage detected and the position of the stylus on the sheet.
The second type of pressure sensitive digitiser uses two sheets of resistive material separated by a cellular membrane.
The pressure of the stylus causes the two conductive surfaces to make contact, a principle used in the Sinclair ZX81's keyboard.
The main problem faced by both of the pressure sensitive systems is that the weight of a hand pressing on another part of the surface can alter the resistive characteristics and so give false readings.
However, for normal purposes they are perfectly adequate and offer the best solution for the home or small business user who cannot afford the more professional systems.
One of the most powerful features of the current generation of home computers is their graphics.
With a few simple commands great sweeping designs appear and disappear, colours change and a new pattern emerges.
Unfortunately, for the really creative user, all this requires programming knowledge and can't be created on paper first and loaded in as a completed work.
Certainly the use of light pens can ease the editing and manipulation of an image once it's on the screen but they cannot be used to copy a picture from a sheet of paper.
Designers of cars, aeroplanes and microprocessors as well as interior decorators, landscape gardeners and fashion designers (to name but a few) can all benefit from the facilities that a computer graphics system can provide.
Once the design is safely stored in the computer's memory additions and alterations can be tried without wasting valuable raw materials or creating a product that simply isn't quite what the customer expected.
Yet all these potential users of computer systems are limited by the fact that the computer cannot recognise a shape drawn on a piece of paper.
What is needed is an input device which can translate the lines and curves of the drawing or design into the sort of information that a computer can display.
In the professional market graphics tablets have been around for almost as long as computers, low-cost alternatives for the home user have only recently started to become available.
High precision graphics tablets, also known as digitisers because they reduce analogue shapes to digital information, use a wide variety of techniques to produce the required information.
Among the most accurate are the magnetic and capacitive systems; a capacitive system can offer accuracies around  of an inch—sufficient for engineers and draughtsmen—while the magnetic method is potentially even better.
Both the magnetic and capacitive systems work on having a series of wire grids embedded in the baseboard of the tablet.
In the magnetic system the grids are used to detect the position of the stylus which, in this case, is a coil radiating a pulsed high frequency signal.
The signal detected by the grids is compared with a reference signal and provides a direct measure of the x, y position of the stylus.
The capacitive system works the other way around in that the stylus is used to detect a series of coded pulses fed into a two-layer grid.
As an alternative to these; both acoustic and optical tablets are available.
The acoustic system works by timing the passage of a known frequency through the metal of the baseboard.
This system is not as accurate as either of the grid systems.
What it does offer, however, is the possibility of digitising the third dimension with a signal passing through the object being digitised to give a measure of its thickness.
At the lower end of the scale are the pressure sensitive tablets which use conductive sheets separated by a cellular insulator.
A high frequency signal is fed into the two layers, the signals are normally either opposite in phase or at right angles to each other.
The signal detected by the stylus when it makes an electrical connection between the two sheets provides a measure of its position.
Typical problems encountered with this type of system include changes in the surface resistance due to damage or the pressure of a hand at another point on the surface.
However, given the limited resolution of home computer graphics the accuracy of this method is more than adequate for today's home computers.
The cheapest and simplest digitisers are the various pantographs.
Based around the old-fashioned drawing aid principle of jointed arms they use co-ordinate geometry to provide a direct measure of the position of the stylus.
Variable resistances mounted at the two joints provide a varying voltage to the computer which can be connected through an analogue port; a joystick socket may be enough, given suitable software.
The resolution of the pantograph is limited by the accuracy of both the variable resistances and the mechanical linkages; typically it is around 5%.
However, sophisticated pantographs based on optical measurement of the rotation of the joints can offer much better results although they still falls short of the best systems.
Optical tablets using infra red beams to detect the position of a stylus are not nearly as sensitive as the other systems but are quite adequate for allowing a finger to be used to select an item from a program menu.
In some applications the infra red sources and detectors are placed around the edge of the visual display unit, a cheaper method of providing an interactive screen than embedding touch pads into the glass.
The actual data produced by a graphics tablet or digitiser must be converted into information suitable for display on the screen and to this end most of the commercial products come with all the necessary software.
However, just entering the data isn't the end of the graphics tablets usefulness.
Once the information is stored in the computer the tablet can be used as an editing tool allowing colour to be added or changed and shapes to be modified.
The surface of the tablet can be programmed to act as a menu that selects standard options from the program so that the keyboard need only be used for selecting the main functions.
Touchmaster feature for THCAC The one feature most of today's best-selling home computers have in common is the facility to produce high quality graphics displays.
The snag for the user is that, in most cases, unless he or she has access to a piece of ready-written graphics software or can program the machine to create the required displays from scratch these features seldom get used to the full.
Even having a drawing or sketching program isn't the whole answer because, in many cases, the user will not want to draw something freehand but copy an existing image into the computer.
Several digitisers have appeared for specific computers such as the BBC Micro and ZX Spectrum but the Touchmaster graphics tablet claims to add a new dimension in that it will operate (with a suitable interface or cable) with almost all the current machines.
It is also being heavily promoted as a replacement for the keyboard in many areas of use although there is currently little software available to use with it.
In any case the use of a tablet will be restricted to selection between a number of options, menu selection or simple games controls for example, and the computer keyboard will still be needed for data entry—and loading the program in the first place.
Based on an A4 sized pressure sensitive membrane, a bigger version of the Koala-pad in effect (see pages 629–631), it comes in a neat grey case some 350mm by 330mm by 35mm.
The back of the case is raised slightly which tilts the tablet to form a convenient drawing surface.
All connections to the tablet are at the rear and it is here that one of the differences between Touchmaster and its rivals become obvious.
Power is supplied from a plug-in transformer, a single red LED shows that the power in on but no power switch is fitted.
To allow the tablet to be used with as many home computers as possible there are both parallel and serial interface sockets on the rear panel together with an unexplained socket for a ‘foot switch’.
Quite what this does isn't covered by the manual!
The general weakness of the information given in the manuals is something which Touchmaster would do well to correct.
The hardware manual covers the connection of the tablet and provides a number of simple BASIC programs to read co-ordinates from it but little else.
The tablet uses the same sort of membrane technology as that used by the ZX81 or ZX Spectrum keyboards and provides a 256 by 256 point resolution.
The upper layer is held away from a lower resistive film by an insulating mesh.
Pressure at any point on the upper layer forces the two layers into contact.
The position of the contact is determined by a microprocessor built into the tablet which scans the top film in one direction while scanning the lower resistive film in the other.
This co-ordinate is sent over both the interfaces to the computer although, obviously, only one will be connected.
Interestingly the resolution is below that of the Hi-Res screen displays on several of the computers that the Touchmaster is available for so it will be impossible to resolve to a single on, for example, the BBC Micro in Mode 0.
The tablet uses the serial interface to connect to the BBC Micro and the parallel interface to connect to the Commodore 64 or VIC-20, the ZX Spectrum and the Dragon.
The last two computers also need an interface unit which is supplied in the package.
It is perhaps ironic that this tablet is one of the few on the market which can be interfaced with the Dragon computer as the company which makes it is the remnants of the firm which designed and built the Dragon.
Supplied with the Touchmaster is a drawing program called Multipaint.
While this does provide a demonstration of the sort of facilities that a drawing package could provide it is far from being a good example.
The package is controlled from the tablet's ce, the only time you need to use the keyboard after loading the program is when you want to enter text to appear on the screen or for a filename when saving or loading pictures.
In order to provide a physical ‘menu’ of the facilities available a plastic template is supplied and this fits over the top of the drawing surface.
The right-hand edge of the template is marked with two columns of options and the currently selected ones are displayed in a status window at the bottom of the screen.
This status window shows the currently selected brush type and its width in pixels together with the selected Ink and Paper colours.
Also shown is the currently selected drawing mode which can be Dots, Points or Freehand.
The remaining space in the window is taken up with the currently selected command sequence.
Changing the Paper or Ink colours is done by pressing the required option on the menu until the word appears in the status window, then pressing the required colour.
Once the system has accepted an in put from the tablet it gives an acknowledging Beep from the computer and prompts for the next command to execute the function.
In this case it expects the Go option to be pressed.
Most of the commands work in this simple but effective way.
Five different brush types can be selected and each of these can be in any width from 2 pixels to 32 pixels in steps of two.
Once the required colours and brush types have been selected a number of further options are available allowing the user to create Boxes, Circles, Polygons and rubber-banded lines.
Once created the program does offer the option of Saving them to tape or disc and then Loading them back.
Actually sketching the required design on the tablet is best achieved with a stylus, a suitable example of this is supplied, but a finger can be used instead.
The Touchmaster doesn't seem to suffer from the major problem faced by its nearest equivalent, the Koala-pad in this respect.
With the much larger tablet area a finger's pressure can be translated into a precise co-ordinate rather than an approximation so electronic finger painting is a real possibility!
Unfortunately the Multipaint program offers no more than the most basic of features.
A Fill option is marked and documented but certainly on the ZX Spectrum version tested it doesn't appear to operate in the expected manner.
Neither is there any facility for magnification or editing.
Possibly the most obvious omission, though, is the lack of any means of editing the screen irrespective of the Ink colours used.
On a system like the ZX Spectrum where it is often easier to draw in black and white before adding the colours this in an essential facility.
As a piece of hardware the Touchmaster tablet appears to have a lot going for it compared with its rivals like the Grafpad and the Koala-pad.
It's robustly built and offers a full A4-sized drawing area that can be connected to most of the common home computers.
One significant advantage is that should you upgrade or change your machine in the future you only need a new interface to use the tablet with a new computer—plus the appropriate software, of course.
It is a disappointment that the documentation and software supplied should be so poor compared with the standard of the tablet itself.
Touchmaster are bringing out a range of software designed specifically for use with their tablet; games and educational programs in the main but the real proof of success will come if independent software houses decide to support it.
As possibly the sole surviving remnant of the Dragon empire it surely deserves some backing from the industry.
One of the most powerful selling points of any of today's home computers are the graphics facilities they offer.
With a few simple lines of BASIC great sweeping designs can be made to appear and disappear, colours will change and a new pattern emerges.
Unfortunately, for the really creative user, all this requires programming knowledge.
The concept can't be created on paper first and then loaded into the computer as a completed work.
While there are a number of on-screen drawing programs which allow the creation and manipulation of an image but they cannot be used to copy a picture from a sheet of paper.
Designers, technical draughtsmen and architects as well as interior decorators, landscape gardeners and fashion designers (to name but a few) can all benefit from the facilities that a computer graphics system can provide.
Once the design is safely stored a way on tape or disc it can be quickly loaded back into the computer's memory.
Now, additions and alterations can be tried without wasting valuable raw materials or creating a product that simply isn't quite what the customer expected.
Yet all these potential users of computer systems are limited by the fact that the computer cannot be interfaced to a piece of paper!
The Theory: What is needed is an input device which can translate the lines and curves of the drawing or design into digital information that a computer can then re-create as a display.
In the professional computer market graphics tablets have been around for almost as long as computers but low-cost designs for the home user have only recently started to become available.
High precision graphics tablets, also known as digitisers because they reduce analogue shapes to digit information, use a wide variety of techniques to produce the required information.
Among the most accurate are the magnetic and capacitive systems; a capacitive system can offer accuracies around  of an inch — sufficient for engineers and draughtsmen—while the magnetic method is potentially even better.
The cheapest and simplest digitisers are the various pantographs.
Based on the same principle as the old-fashioned drawing aid they use jointed arms and co-ordinate geometry to provide a direct measure of the position of the stylus.
Variable resistors (potentiometers) are mounted at the two joints and provide a varying voltage to the computer.
This can be interfaced through a suitable analogue port; a joystick socket may be enough, given suitable software.
The resolution of the pantograph is limited by the accuracy of both the variable resistances and the mechanical linkages; typically it is around 5%.
However, sophisticated pantographs based on optical measurement of the rotation of the joints can offer much better results although they still fall short of the sort of accuracies that can be obtained by the best systems.
While the pantograph is probably the simplest type of digitiser there is it is often completely adequate for home computer use.
One stage more advanced than the pantograph, although still lacking the sophistication of a magnetic or acoustic digitiser, is the pressure sensitive digitiser.
Often referred to as a ‘bit pad’(although that is actually the trade name of a specific device) it can take one of two forms.
The simpler of the two is based on a resistive sheet, often just heavy paper with a graphite coating.
If an AC voltage is passed across the sheet a stylus will be able to detect the potential at any point.
Using an electronic sampling method which is locked to the same frequency as the supply voltage it is possible to derive a direct relationship between the voltage detected and the position of the stylus on the sheet.
The second type of pressure sensitive digitiser uses two sheets of resistive material separated by a cellular membrane.
The pressure of the stylus causes the two conductive surfaces to make contact, a principle that was used in the Sinclair ZX81's keyboard.
A high frequency signal is fed into the two layers, the signals are normally either opposite in phase or connected at right angles to each other.
The signal detected by the stylus when it makes an electrical connection between the two sheets provides a sure of its position.
Typical problems encountered with both these systems include changes in the surface resistance due to damage or the pressure of a hand at another point on the surface.
The best type of digitiser that's available to the home user are based on either magnetic or capacitive effects.
Both systems work on having a series of wire grids embedded in the baseboard of the tablet.
In the magnetic system the grids are used to detect the position of the stylus which, in this case, is a coil radiating a pulsed high frequency signal.
The signal detected by the grids is compared with a reference signal and provides a direct measure of the x, y position of the stylus.
The capacitive system works the other way around in that the stylus is used to detect a series of coded pulses fed into a two-layer grid.
The data produced by a graphics tablet must be converted into information suitable for display on the screen and to this end most of the commercial products come with all the necessary software.
However, just entering the data isn't the end of the graphics tablets usefulness.
Once the information is stored in the computer the tablet can be used as an editing tool allowing colour to be added or changed and shapes to be modified.
The surface of the tablet can also be programmed to act as a menu that selects standard options from the program so that the keyboard need only be used for selecting major functions or entering text.
The Practical Application: So much for the theory behind digitisers, what about a version for the Spectrum user?
Just such a device is available from British Micro called the Grafpad.
Previously offered for the BBC Micro the system has recently been adapted to work with the Spectrum and Commodore 64 systems.
The unit comes extremely well packed in polystyrene, not a bad thing considering it costs a fairly staggering £143.75, and consists mainly of a 25mm by 355mm by 260mm black plastic box.
A slight discrepancy from the advertising already, they reckon it's only 55mm wide but what's a simple misprint between friends?
Nothing, really, except that they also reckon it comes with a light pen…
Well, it doesn't—but then it does have a really nice stylus which makes up for it!
Also included in the packing are a multi-way cable to link the tablet to the Spectrum's edge connector, a cassette containing the software, a keyboard overlay and a wad of A5 sized photocopied paper that claims to be a manual.
The tablet is well made, the surface is ruled with a grid corresponding to the Spectrum's graphics resolution of 176 by 256 pixels and also includes a 32-box menu panel which can, in theory at least, be utilised by the user in his own software.
The grid is protected from damage by a she et of clear acrylic over which the stylus can be moved with ease although it does scratch.
The first task is to connect the tablet to the Spectrum.
How hard do you think it would be to plug a cable between the Spectrum's edge connector and an identical connector on the tablet?
Well, it should be no problem at all but, on my Spectrum at least, the aluminium heatsink prevented the plug from being properly inserted.
Out with the toolkit, some minor surgery and the cable now connects perfectly although it's still too short to allow the tablet to go anywhere other than on the right or directly behind the Spectrum.
Fine if you're right-handed but then, not everyone is.
With the cable connected all that remains is to plug in the stylus to the socket at the side of the tablet, load the program and start drawing.
To make life easier for the user a keyboard overlay is supplied which carries the various options.
All of the Spectrum keys are used by the program, most with two functions, a fact that is fairly strange given the presence of the menu panel on the tablet.
To keep the user aware of what's going on the screen display includes a highlighted bar detailing the current screen mode, fore- and background colour selected, the drawing and dot modes.
A neat feature is that the bar always moves out of the way when you get near it, hopping from the top to the bottom of the screen and vice versa.
To activate the stylus it must be pressed down so the microswitch in the tip makes contact, the on-screen cursor now follows the motions of the stylus round the grid.
In order to use any selected function Enter key must be pressed and the function will operate as long as the stylus is depressed—releasing it cancels the function.
The single most difficult thing I found when using the Grafpad was to remember whether I was drawing on the screen or mapping the attributes.
The current screen mode is displayed in the centre of the information bar so it should be simple to keep track of what's going on but dropping into Attribute mode and spraying colour across pixel boundaries can be very frustrating.
The accuracy of the tablet is matched to the Spectrum, the grid inside the tablet's surface consists of a wire mesh 176 by 256, so the movement of the stylus on the screen corresponds exactly to its motion on the surface of the Grafpad.
Drawing freehand requires practice and traced pictures are never really exact.
Fortunately the software makes allowances for this and it's generally quicker to knock up a quick likeness and then use the editing features to tidy up.
Of these the most useful is Magnify which blows up the selected area by up to eight times.
Here the individual pixels are about the size of characters and you can Set and Reset them at will.
The movement of the stylus is also scaled to the current magnification so the picture doesn't leap about all over the place.
Among the other built-in features of note are the line, circle and box drawing routines, all rubber-banded from any given starting point.
Quite what the Vertical and Horizontal line facilities are for is a mystery, they appear completely redundant.
While al most all the routines work very fast indeed the Circle is amazingly slow, any suggestions as to why would be gladly received as there seems to be no obvious answer.
To assist in matching your image to others the program proves two scaling grids but neither really proved very effective.
The highlight grid which produces alternate light and dark background character cells doesn't work with dark backgrounds and while the second grid is better it reduces all the colours to magenta or white making it almost useless for anything other than outlining.
Against these dubious features Grafpad does posses several very useful facilities.
You can invert an image, flip up/down or left/right, store up to two pictures elsewhere in memory or permanently on tape.
Areas can be painted in or you can edit the Attribute screen on a pixel by pixel basis—in magnified mode if you really want to be accurate.
If you want to protect areas of your picture from accidental damage a window facility is provided and only the area inside can be edited while the window is active.
Ab out the only other interesting facility promised by the manual is that you can pick up UDG's but it fails to mention where from…
The manual actually fails to mention quite a lot and I only hope that the one I got is a prototype and not what the paying public will receive!
Quite apart from the mis-spellings and shabby presentation it hardly tells you anything at all.
It's almost as though it was translated from Esperanto by an artificial intelligence program suffering from dyslexia.
(Author's note: all spelling mistakes in this review are the responsibility of the Editor!)
All the commands are dealt with but seemingly in as few words as possible, it's more a quick reference guide than a piece of documentation.
Conclusion If you want to create works of art on your Spectrum's screen then you can certainly do it with the Grafpad…
But then again you can also do it with the various screen-based editors like Melbourne Draw for substantially less than £143.75.
The only thing the Grafpad has to offer that the screen-based packages don't is the facility to use the pen to trace an existing drawing on paper into the computer's memory and even this is limited by the accuracy of the tablet.
If this facility is of over-riding importance to you, and you can find a pantograph for the Spectrum (which I couldn't) that's cheaper I'd say buy the pantograph!
If you simply don't need the trace facility, and I suspect that few Spectrum users really will, then check out the screen-based programs and save a few bob into the bargain.
When you first start to use a program like Ventura or PageMaker there is a period of rapid learning where the basic concepts of the composition program start to become familiar.
In either you may have worked through the supplied tutorial which introduces all the basic concepts, although they do actually introduce one or two bad habits as well!
If you were really fortunate you will have gone on a training course, far too few companies bother to invest in improving their staff's skill in desktop publishing, and have learned at least some of the basic operations.
Unfortunately, all these learning activities tend to take place in the abstract, they do not relate to publications you actually produce as part of your job.
Learning ‘on the job’ is the way that most people acquire their skills with desktop publishing but even though they are producing relevant material they often miss out on a lot of the essential background.
The more complex the program, the harder it is to find out about all those clever little tricks that turn a publication from the ordinary into the special.
It is generally true that PageMaker users find out about some 80–90% of the program's capabilities just by playing around.
This is in part due to the fact that the program has an extremely intuitive use interface but it is also true that the program is essentially quite simple.
The reverse tends to be the case with Ventura which is both extremely complex as a program and is further hampered by a user interface that is not exactly a model of the way things happen in the real world.
Indeed, we have found that even users of some two year's experience often don't know about the basic ‘power features’ such as section numbering, tables of contents and, most worrying of all, how to back-up Ventura publications.
In general, Ventura users have mastery over perhaps 40 to 50% of the program.
However, it is a knowledge of what happens behind the program that makes all the difference in whether a page looks good or not.
Unlike the days of old when typography and design were learned over generations, desktop publishing has provided a fast track where we can take ideas and try them out to see if they work.
The penalty one pays for this is that you never really get to learn and understand the basics behind simple design.
Probably the single most important step in the whole process is learning how to make up a grid and then using it to control the structure of a document.
The difference between a document created by placing elements on a page and one created on a grid is subtle but significant.
Furthermore, it makes the document so much more ‘professional’ that it's hard to think of another single step that can such benefits.
The first decision that you have to take when planning a publication's layout is the underlying grid.
Indeed, if you only define the four page margins and the paper size you have effectively started to design the grid.
Unfortunately, that's where most people stop!
A basic A4 page is too wide for a single column of text, the ‘ideal’ width for a column of text is approximately 55 to 60 characters or around eight to 10 words.
You can work out the column width by multiplying the point size you want to use by two or the lowercase alphabet length by 1.5 to give the number of picas to set the text across.
It is already obvious that the columns vary according to the point size, you can get away quite happily with two columns across an A4 in 12 point, three would be better in 10 point and to get four you'll need to go down to perhaps 8 point.
The size of the type itself varies enormously, 12 point Bookman looks much bigger than 12 point times even though they both occupy the same amount of space vertically on the page.
Even more important than the size of the type, though, is the amount of leading that is inserted between the lines.
Just as we like to define a grid across the page so should we define a grid down the page.
In the days of lead type this was done almost automatically because the pieces all had to fit together without any gaps.
Now that we do it all on a computer screen we need to define the pieces before we can start.
PageMaker defaults to providing ‘Automatic’ leading and that's what many users always stick to on the assumption that PageMaker knows best.
To achieve a level of composition above the ordinary it is important that the user retains the control, not the program so Auto anything should be regarded as a cop out and avoided where ever possible.
Defining the value for the leading of your body copy, that's the stuff you've got the most of—the text in a report or a newsletter, allows you to set the vertical grid.
Let's assume we are producing a three column newsletter and we have already decided to use 10 point Palatino as our typeface.
The first thing we need to do is to set up the vertical grid on the page.
Both PageMaker and Ventura select arbitrary reference points for their on-screen rulers, the top left-hand corner of the page.
This is fundamentally useless and it is amazing that anyone ever manages to get a properly aligned document as a result.
Indeed, the Ventura manual doesn't even get around to mentioning the ruler until the end of section 5 in its manual and there are books on the program that don't mention it at all!
The vertical and horizontal rulers need to be set to a rigidly defined position, at least for the purposes of setting up the grids.
The best place is the top left-hand corner of the copy area, this is a defined point on the page and it won't matter if the page printer offsets a little in either direction (as they almost always do).
The next thing to do is to define the rulers themselves.
The measurement across the page can be in whatever units you are happy with; picas, millimetres, etc, but the vertical measurements should be done in the same units as your leading.
For example, set the text leading to 11 point and that's what the rulers should be set to measure.
Sadly this is only really possible in PageMaker as Ventura's rulers are defined and whilst you can set up vertical grids in XPress you can't change them once defined.
The point of doing all this pre-planning is so that when you come to align columns across the page or to set text next to pictures everything snaps together neatly.
And, as always, it's the little things that make the difference.
You should always, for example, try to make sure that at least the text in the columns lines up across the page-headings and sub-headings may well not but the text really should.
In PageMaker this is easy (providing you remember to use Top of Caps leading) but in Ventura and Quark it can be a bit of a problem.
The easiest trick is to make all the leading values a multiple of the base or text leading—we call this the modulus.
So, for example, if we have 10 on 11 body text we might have 11 on 11 sub-headings and 20 on 22 major headings.
All these sizes can be worked out well in advance of actually typing anything onto the screen—indeed all design should be done well away from the computer.
Virtually all today's desktop publishing programs allow you to set up style sheets so that the characteristics of the typography and, in Ventura's case, the layout as well can all be pre-defined.
This works even better when you pre-tag the text so that when the document is read into the page makeup program all the basic work has been done for you.
In Ventura is it always worth having a completely blank style sheet—except for Body Text, that is—because if anything goes wrong and you need to recover the information you can simply change the style sheet to this blank one.
It is also well worth using this style sheet as the starting point for any new ones.
Many users modify existing style sheets but this can bring along huge amounts of excess styling information that you either don't want or had forgotten was in there.
Adding excess information to Ventura documents becomes something of a hazard the more complex they get.
It is perfectly possible to build a tag that, for example, creates a blank page before it but is not allowed to become separated from the next block of text.
The result is as many blank pages as Ventura can build into the current chapter and you can't get at the tagged block of text to de-select it!
One of the ways that many people are actually taught to use the program can really cause problems and this is the problem of multiple frames.
When you create a document in Ventura it has an underlying frame.
In general this is all that you need to complete most documents, the only extra frames you'll need are for images.
Unfortunately some users are taught that they need to create frames for everything and the problems that can arise from having one set of frames interact with another make you wonder how anybody ever manages to produce a correctly aligned publication.
In earlier version of the program it was impossible to line anything up anyway because the program's internal accuracy was insufficient; the classic 11 point being converted by the program into 10.98 point with the rounding errors occasionally throwing an extra line on or off the page.
In Version 2.0 the accuracy was significantly improved but you need to watch the numbers very carefully, especially if you are using style sheets designed under an older version.
The program also added Vertical Justification which ensures that the top and bottom lines of a multiple column page do align correctly.
Unfortunately, this doesn't mean that any of the others will!
Correct design and a little careful planning will get around most of these problems.
Getting the basic underlying grid structure right is the simple most important step towards getting better looking pages.
There are, however, many other useful little tricks that are worth learning.
All of the following are for PageMaker but the general principles can be applied to most of the page makeup programs.
Precision selection of text
This dodge applies to all those people who have a normal size screen and have trouble accurately selecting areas of text.
Remember that you can always select a word by double clicking and a paragraph by clicking three times but did you know that you can extend these further?
If you insert the text cursor at the wrong place don't bother with the mouse, use the cursor keys to move the insertion point to the right place.
Then, hold down the Shift key and move the cursor to the end of the block you want selected.
If you selected a word hold down the Shift key and click on the last word of the selection—similarly for paragraphs.
It's also worth noting that Control (Command on the Macintosh) plus various keys on the numeric keypad will move you around the text by word, sentence or paragraph.
And did you know that Page Up and Down shifted the whole document up and down on the screen?
Incidentally, all these shortcuts are given on the Quick reference Card but how many people have ever bothered to read it…
Fractions on the PC
If you are using a PostScript printer with ROMs containing version 47 or later then you can get halfs, quarters and threequarters fractions by typing the ANSI codes; 188, 189, 190.
If you are properly set up under Windows then you should have the ANSI.SYS driver in your CONFIG.SYS file, if not then it may well be worth installing it unless you are driving an HP LaserJet in which case you'll be using the Roman-8 character set; the Roman-8 codes are 247, 248 and 245 respectively.
Fractions for the Macintosh
This method involves a little bit of a cheat as the Macintosh keyboard cannot access the PostScript fractions unless you either have a special fractions font or are using one of the new Adobe Expert fonts with an extended and re-mapped character set.
Fortunately, however, there is a special fractions ‘slash’ character and you use it like this.
First type the superior number, say 3, and then key Option Shift 1.
This is a special ‘sticky slash’ that is much more upright than the normal character—it also possesses the power to automatically kern characters on either side of it.
Now type the inferior number, say 8.
Select the ‘3’ and make it superscript then select the ‘8’and make it roughly half the size of the body copy—a little practice helps here.
The result is a perfectly acceptable ‘build’ fraction that will fool most of the people who are likely to see it and, unlike the generic fraction fonts, is actually in the correct typeface.
Condensed and expanded type
Whilst PageMaker does not itself support the condensing and expanding of type (a feature that we hope will be included in version 4.0) it is possible to perform this trick on the Macintosh—sadly not on the PC.
What you do is to select the block of text that you wish to manipulate, ie you use the pointer tool and not the text tool, and then copy it to the Scrapbook via the Clipboard.
If the text is shorter than the width of the block reduce the width to that of the text by dragging the handles in before you copy the text.
Now select the Place command and choose the Scrapbook as the source file.
The Place icon will appear with a number inside it indicating how many elements you have stored, the latest one should be the first.
Place the text block back onto the page and you will discover that it has been converted into a graphic which can be stretched and distorted as much as you want.
Even though it may look a little rough on the screen, when it prints out it will all be reproduced correctly through the magic of PostScript.
Save or Save As?
PageMaker has a very clever habit of remembering all the changes that have been made to a document so that they can either be Undone or Reverted to.
The penalty for all this housekeeping is that the files generated by the program do tend to get bigger and bigger as time goes on.
Take the example of a newsletter which, every month has the text and illustrations removed from the file and the new copy pasted in.
Although the user thinks that they are deleting the material they are only really removing them from the current display list—all the text and graphics are still being held in the file.
As a result you can end up with a file bordering on the megabytes instead of a few tens of kilobytes.
The answer is to do a Save As rather than a Save.
This consolidates the document into its current form and throws out all the previous rubbish.
The reduction in document size can be quite spectacular, 40 to 50% is quite common.
And, as all desktop publishers will be only too well aware, small is beautiful.
Getting the quotes
A wonderful story is told of a concert programme that was prepared using desktop publishing by a fairly well-known organisation.
At the event the desktop publisher was basking in the reflected glory when a lady sitting next to him suddenly said ‘Oh dear, it's all been done on a computer.’
What gave it away?
He had forgotten to use proper typographic quotation marks, the double sixes and nines, and the resulting inch marks were instant proof that the document had been desktop published.
Many programs will automatically convert the quotes in a word processor file into proper typographic quote marks but what about the ones that you typed in on the keyboard?
On the PC it's Control Shift left square bracket for the opening doubles, Control Shift right square bracket for the closing doubles.
For single quotes or apostrophes leave out the Shift key.
Macintosh users should substitute the Option key for the Control key.
(Incidentally, Ventura users will have to resort to ANSI codes 169 and 170 for the doubles and 96 and 39 for the singles.)
The story can, of course, be extended to include ligatures—they are the double letter combinations such as fi, ff, fl, etc but as most PostScript fonts only support fi (Option Shift 5) and fl (Option Shift 6) this may be a little picky.
On the other hand…
Spotlight on Desktop Publishing—an update on the market
Just five years ago the term desktop publishing was, to all but a select few, a totally unknown expression.
Also missing from the personal computer users vocabulary were such words as laser printer, PostScript, page description language and a whole range of typographic terminology that we all now take for granted.
Within those five years desktop publishing has, or so it seems, become an integrated part of the electronic office.
There is scarcely an industry that hasn't been affected by it; from manufacturing through to publishing.
And yet, in real terms, the percentage share of the market that desktop publishing software occupies is very small, less than 10% according to some of the market research, compared with such stalwarts as word processing, databases and spreadsheets.
Even more remarkable is the fact that across the personal computer platforms there are just a handful of players and products that are accepted.
Unlike the traditional software markets where a number of players grew alongside one another as the market expanded, in desktop publishing we have had many fewer successful products and those have tended to totally dominate the market.
Back to the beginning
If we turn the clock back to the beginning of the desktop publishing marketplace in order to trace its development and evolution we first need to establish exactly what desktop publishing was conceived as being in the first place.
To begin with, the term ‘desktop publishing’ was coined by Paul Brainerd, President of Aldus, to describe the facilities that his PageMaker program would offer to the user.
A more accurate term would have been desktop layout or desktop typesetting and page makeup but we've been stuck with the words he used.
What Brainerd and his company had produced was an electronic simulation of the layout artist's workbench.
Text, graphics and other images created in standard office automation programs could be imported into the program, given typographic attributes such as typeface, style and size before being arranged on the page as required.
Given Brainerd's background in the publishing industry, mainly newspapers, and the fact that he had just left Atex it is hardly surprising that the program was designed around the traditional ‘cut and paste’ working methods.
This also fitted in extremely well with the (then newly launched) Macintosh and happened to fit even more perfectly with Adobe's PostScript language and Apple's LaserWriter printer.
It would be unfair and inaccurate to suggest that PageMaker was the first desktop publishing program, that honour probably goes to the now defunct Studio Software's DO-it which actually ran on a PC rather than a Macintosh and, of course, there had been electronic publishing systems based on workstations and mainframes available for several years.
However, the real triumph was the fact that the user interface was matched to the traditional ways of working—which made it both easy to learn and rapidly accepted (though much criticised for its lack of typographic accuracy) by the publishing industry.
Following the leader
A number of programs followed rapidly in PageMaker's footprints but none of those launched for the Macintosh has ever come close to either challenging PageMaker's lead or to matching its intuitive user interface.
Several, indeed most, of the programs have consistently out-performed PageMaker's typography but the launch of the latest version, 4.0, at the beginning of February may change that.
The challengers have also all adopted a slightly different approach to PageMaker in that they have provided many of the creation tools within the desktop publishing program rather than leaving them to the more specialised stand-alone products.
(Once again, PageMaker will begin to introduce these functions with version 4.0) The other primary Macintosh products are, in order of market share, Ready, Set, Go! —marketed by Letraset and Quark XPress — distributed in this country by Computers Unlimited.
The PC world
In the beginning desktop publishing was virtually synonymous with the Macintosh—despite the historical fact that PC software was there first.
The reason for this is two-fold.
First, the Macintosh was designed as a graphical computer and so already possessed the necessary hardware to provide a typographically ‘accurate’ WYSIWYG display and then print it out onto the new LaserWriter printer.
Secondly, Apple was very a very hungry company at that point in time and desperately needed a prop to hold the company up (it was undoubtedly the LaserWriter that saved the company's financial fortunes rather than any of its computers).
It also gave Apple its first opening into the corporate PC market, many companies bought Macintosh systems solely for desktop publishing and then watched them spread throughout the organisation.
The dominance of the Macintosh obviously couldn't last for ever, the numerical superiority of the PC was bound to win in the end, and it was a program called Ventura Publisher that finally did it.
Developed by a team of ex-Digital Research programmers, mainly people who had been responsible for the GEM environment, it was taken on by Xerox who, much to everyone's amazement, managed to market the product worldwide.
It became a runaway success and, until the introduction of PageMaker on the PC, had no real competition.
However, even PageMaker is in a different league compared to Ventura.
Different horses, different courses
Where PageMaker is, despite all the enhancements, still the electronic version of a paste-up table, Ventura is an automatic document generator.
Designed to handle long, regularly structured documents it is more suited to the world of corporate reports, catalogues, books and documentation.
Like PageMaker it lacks the sophisticated text entry and manipulation tools necessary to generate the material it will process but, unlike PageMaker, once it has that material it can produce documents virtually automatically.
It is perhaps interesting to note that the other two competitors in the PC market, GEM Desktop Publisher and Timeworks, both mimic the Ventura approach.
PageMaker still commands mastery of its own particular niche even though its sales lead seesaws with that of Ventura.
A shift in emphasis
During the past year there have been few remarkable changes in the desktop publishing market but rather a definite shift of emphasis.
At one of the early Seybold conferences, I think it was back in 1986, Steve Jobs commented that desktop publishing would disappear within two years as a stand-alone activity because all the major applications would simply absorb its capabilities.
Although he undoubtedly got his timescales wrong the basic inference was correct.
Many of today's spreadsheets and word processors possess extremely advanced presentation capabilities and the launch of programs like Excel, Wingz, Word for Windows, Ami (NB that's i acute as in the French for friend) and WordPerfect 5.1 all tend to confirm this.
These programs lack the lightness of touch that a paste-up program such as PageMaker has, they assemble the document according to a set of rules which tends to make the layouts a little rigid, but they certainly provide a tool that, in some cases, can challenge even the power of Ventura.
And, of course, there is no need to learn either a new program or new skills, the latter part of the equation having proved a major stumbling block for many companies eager to improve the quality of their published work.
Getting advice
The challenge of desktop publishing has proved too great for many companies.
Seduced by the flashy demonstrations or the apparent ease of use of the various environment managers, whether Apple's, Windows or GEM, they adopted desktop publishing wholesale and gave it to secretarial staff on the assumption that those who produce the documents ought to be the ones who make it look pretty.
One of the major parts of the cost of any desktop publishing system is that of training—a fact that has largely been overlooked.
Even worse has been a lack of any forward planning to see how the systems should have been installed and integrated with the existing hardware and software.
Outside of the dealerships, and there are only a few of these who understand the publishing process, a number of companies have established themselves as providers of independent advice, training and support.
The largest of these is The Desktop Publishing Company which uses a network of independent consultants among whom are numbered most of the better-known experts.
A growing trend
The second major change that has begun to emerge, and will undoubtedly continue into the '90s, is that of the migration of electronic publishing products, which previously required the power of a workstation, onto personal computers.
The first to make the move was Interleaf with its Publisher product, a cut-down version of their Technical Publishing System, first for the Macintosh and then for 80386-based systems.
(It is also marketed directly by IBM.)
The difference between a product like Interleaf Publisher and, say, Ventura Publisher is primarily in the level of integration.
Interleaf Publisher provides its own environment which includes a word processor, graphics package and so on.
There is little, if any, need for external software to assist in the creation of the complete document although support is provided for most of the major players.
This is in marked contrast to desktop publishing programs where almost every element has to be created externally and then imported.
While the trend toward increasing the integration has only just begun, we are still awaiting Frame Technology's launch of FrameMaker onto the Macintosh and, possibly, OS/2 Presentation Manager, it is in this direction that desktop publishing is undoubtedly heading during the next few years.
If there is a new term to be coined to describe these integrated products then perhaps ‘document processors’ would suffice.
Getting into print
At the end of the day, however, all the programs produce pieces of paper that need to be reproduced in quantity.
Pure electronic publishing, the so-called paperless office, is still far from being a reality.
While the typographic quality of the documents increases in leaps and bounds, both as the software improves and the operators become more skilled, so too are we experiencing a rapid improvement in the quality of the printing systems that are available.
For a long time the standard has been stuck at 300 dots per inch—the eye cannot resolve a single do smaller than this, or so the theory goes—but we are now beginning to see 400dpi, 600dpi and 800dpi printers.
Producing much more than 800dpi from a dry toner system is a major problem, the particles have to be very precise and tend to clump together, but this level of quality is probably sufficient for anything an office is ever likely to need.
The other major trend that is taking place is the rapid development of colour publishing.
Once again the major players are being driven by the advances made on the desktop publishing systems but here the moves are often collaborative rather than competitive.
Letraset's new ColourStudio includes technology developed by Optronics, Aldus has provided an open interface structure that players such as Hell and Crosfield are working with and Quark has its links with Scitex.
The desktop systems simply do not possess the storage capacity or speed required to manipulate colour documents of more than a page or two, let alone have the operator skills.
Even here, however, moves are being made with expert systems being developed to assist untrained operators and active compression being used to reduce the storage burden.
To try to predict the state of the market in five years time is not easy but it seems likely that the products will be more integrated, have a degree of artificial intelligence to provide unskilled operators with advice on how to compose the pages and support colour both through local printing systems and via links to professional equipment.
Local printing will be done at a minimum of 400dpi and more likely 800dpi while bulk reproduction will be from high speed photocopier derivatives that provide double-sided printing, collation and finishing.
Fonts and their clashes for DTP
If there is one unchallenged law of personal computing it is that, given half a chance, they will make something that used to be simple into a completely bewildering nightmare!
Take, for example, the problems that the electronic publishing industry is currently facing with fonts.
Last year we were all bemoaning the fact that Linotype and Adobe had a stranglehold on the market, they being the only two official PostScript type foundries.
Now we have a situation where Monotype, Compugraphic and AM Varityper have joined the club, together with Autologic and Scangraphic, while Apple, Bitstream, Compugraphic, Microsoft and Sun Microsystems are all rapidly producing alternative mechanisms for storing type in digital form.
Out of this confusion emerge two major problems that, so far as I can tell, are here to stay.
The first is that of font compatibility; ie does Linotype's version of Times really match Bitstream's Swiss.
If it doesn't then what you created on the computer screen and proofed on a page printer may well look rather different to that which you get back from the typesetter.
This problem is, of course, easily avoided by ensuring that you stick to one particular font imaging system throughout the production process; eg PostScript or Bitstream — never a mixture.
The other problem is rather more difficult, both to explain and to suggest ways around.
It's the problem of clashing font IDs.
Before I start it is worth pointing out that this problem is largely restricted to the users of the Apple Macintosh — PC-based software running under either Windows or GEM seems to be rather better behaved although, in the case of the former, installing downloadable fonts is so much of a pain that many people simply don't bother anyway!
To understand the problems of font clashes it is worth turning the clock back to the very first Macintosh system.
This came equipped with two ‘resources’ built into its ROMs that were supposed to manage the future font requirements; FOND — the font family descriptor, and FONT — the ID number of the actual font.
The numbering limits on this were set at 32767 which might, at first glance seem an impressive number.
Unfortunately, the method for coding the various style variations within a font family mean that only 255 unique fonts can be encoded by this system.
And, remember, that Times 12 Roman and Times 12 Italic are two different fonts so it is easy to see that users quickly began to experience problems.
Each FOND refers to the members of a family that are present within a file, be it the System or a Font/DA Mover file — also called a Suitcase.
The FOND only covers those members present within that file, so, for example, if you had Helvetica and Helvetica Italic in the System but Helvetica Bold and Bold Italic in a Suitcase the latter two would not be found by the System.
So, each size and style of font is given a unique number out of the 32767 available.
Unfortunately, that unique number is generated from the FONT ID times 128 plus the size which limits the total to that appallingly restricted 255.
Further, because every system is built differently by its owner there is not, apart from the original LaserWriter Plus font set, much room for additional fonts before the numbers start to clash.
The typical problems that occur are that a file created on your system using downloadable fonts works perfectly but, when you send it to another system, such as a bureau's typesetter, what you had in, say, Bodoni Bold comes back as New Century Schoolbook Italic.
A rather unsubtle change!
The reason that this has occurred is because the bureau has installed a different set of fonts to you and, because of the limited set of font numbers available they have ended up with a different set of IDs to you.
There are solutions to the problem in programs like Suitcase and Font DA Juggler.
These effectively allow you to combine selections of screen fonts into special files called ‘suitcases’ and they then ensure that all the numbers are equally distributed so reducing or eliminating the problem.
Once again, however, this really only works if both systems use the same font suitcases.
With the introduction of System 6.0.2 Apple went some way towards reducing the problem by adding a new resource called NFNT.
This has exactly the same internal format as a FONT except that its ID number is unique and not, as was the case with the FONT resource, the result of a calculation based on the font number, the size and a constant.
This potentially, means that there can now be up to 32,767 unique fonts — each with their four basic stylistic variations, although Apple reserve the first 1,024.
Sadly, of course, it hasn't proved to be the entire answer because the original FOND resource can only cope with the four basic stylistic variations; Plain, Italic, Bold and Bold Italic.
As many fonts also have Semi or Demi, not to mention Extra and Heavy versions these still need to be kept as multiple families, so reducing the number of unique ID numbers.
The other major problem is that many applications still refer to fonts by ID number rather than by name, Aldus PageMaker is an honourable exception.
Apple has been advising developers for some time to use names and not numbers but not all seem to have taken heed — it looks as though they will have to when System 7.0 comes out next year equipped with Apple's own outline font system.
There are other problems too, but of a rather less definable nature.
Why, for example, should a bureau with the depth of experience of the Cotswold Press suddenly find that halfway through outputting a multi-hundred page job from Word that the fonts change?
And, even more unexpectedly, change back a few pages later?
Effects like these are far from isolated and would seem to indicate a deeper and more worrying problem with the actual System itself.
Or at least with the way it converts internal formats into PostScript.
(Bear in mind that Apple are themselves developing a PostScript interpreter…)
So, what can be done to relieve the problems?
The first requirement is good system management to reduce the number of Suitcase that you have fonts stored in.
Most users will seldom have more than, say, half a dozen additional fonts and these will probably all fit quite happily into the System file itself.
Remember, however, to combine the families as you go along if they have been supplied as multiple Suitcases.
This will prevent you ‘losing’ variations—as will happen if you just copy them into a new Suitcase file.
(You also need to be aware that to handle NFNT fonts you need Font/DA Mover 3.8)
Next, if you are using lots of fonts—but only a few at a time—you should combine blocks of fonts into Suitcases and then use one or other of the utilities such as Suitcase to manage them for you.
These programs ensure that you don't get font clashes and also often provide other management routines such as font compression.
Interestingly, Linotype's Concert Series is based around the use of Suitcase as a management tool.
The package also uses another program from Fifth Generation Systems, Fastback, to archive the fonts onto tape cartridges for distribution.
To be frank, Concert Series looks like a good marketing ploy rather than a serious answer to the font numbering problem because not even Suitcase can handle all the fonts simultaneously.
In talking to bureaux and other large users of fonts several other solutions emerged.
Cotswold Press, for example, build unique System files for clients—as will a number of other bureaux—and this seems to be the most reliable method of all in avoiding font clashes.
They also reckon that Monotype's fonts never cause problems — probably because they were all numbered according to the NFNT system from day one rather than being a mix of the two methods.
To sum up, if you use downloadable fonts and send your files off to another system for outputting do make sure that they know what fonts you are using.
It's even worth going to the trouble of sending your own System file of font suitcases.
If you are a stand-alone system then take advantage of programs like Suitcase and Font/DA Juggler but do take the time to read the manuals otherwise you can end up with a worse problem than you started with.
Finally, consider just why you are using all these fonts in the first place — perhaps you should re-think your design and limit the numbers to something more sensible.
(Ed: this from a man with 146 fonts on his System…)
Fonts and how to manage them
With the font world in a state of turmoil following the Apple/Microsoft deal it's time for a few words about maintaining standards.
Henry Budgett explains.
Some twenty years ago a single font would have cost you around $4,500.
And, when you bought it, you knew for certain that it would only work on one specific piece of typesetting equipment.
You were, in all senses of the word, locked into that vendor for the life of the equipment.
Ten years ago the price had fallen to perhaps $450 per font but the restrictions were much the same.
Nowadays a single font will cost, perhaps, $45 and it can be used on almost any make of typesetter.
The key to this remarkable turnaround in what has been one of the most restrictive industries is, of course, PostScript.
Developed by Adobe Systems and launched onto an unsuspecting world in 1984 by Apple with its LaserWriter printer it became the underlying reason that desktop publishing succeeded.
Indeed, Apple believed in the technology to such an extent that they invested in the company and actually owned 20% of the stock at one time.
Simultaneously they were Adobe's largest customer contributing over 40% of the revenues at one point.
PostScript succeeded to such an extent that it became a de-facto standard with almost every major computer manufacturer and printer vendor taking out a license.
It was only in the typesetting world where the relentless march of Adobe was held back.
Linotype took an early gamble and produced a RIP for their 100 system and then the 300.
Now they are on their third generation of RIP and second generation of PostScript imagesetters with the Linotronic 200P.
The other vendors held back, concerned about the costs of PostScript licenses, the speed of the imaging process and numerous other issues of which font availability was certainly one.
By the end of 1988 it has become obvious that Adobe's proprietary font encoding system and hinting technologies (these give good results at low resolutions) were being broken by some of the other font foundries.
It was also clear that the first of a number of PostScript clones, the language definition has always been in the public domain, were beginning to come to the market.
These clones, not having access to the genuine Adobe technologies, were taking their font libraries from other sources, generally Bitstream, with varying degrees of success.
The problem is that although the typeface may have the same name—indeed it may even come from the same original—it may not have been coded up in the same way.
So, for example, Bitstream's Dutch may appear to be a perfect match for Linotype's Times at 300dpi but when they are output at a typesetter's resolution the minute differences will be more exaggerated.
The result can be that line endings may not match or letter and word spacing are different.
In order to bring more of the big guns to bear on the clones Adobe signed a rash of typesetter vendors and font foundries in late 1988.
These included Monotype, AM Varityper, Compugraphic and, somewhat later, Autologic and Scangraphic.
Most of these had been producing un-hinted PostScript fonts for some time but they now all had the tools to create the all-important encrypted Type 1 fonts and had licenses to produce PostScript typesetters.
For the first time ever it would be possible to take, say, an Autologic font and run it, straight out of the box, on a Linotype or Monotype imagesetter.
It finally looked as though Adobe had won the day and that there would now be a single stable standard.
Apple, however, were unhappy with their reliance on an external supplier for such a crucial part of their system.
They had already decided not to go for Display PostScript—the on-screen imaging model that matches the printer language—but to concentrate on enhancing QuickDraw.
In the middle of 1989 they sold their holding on Adobe and announced that they would be seeking to develop their own version of PostScript and their own font technology.
Meanwhile, Microsoft (who, incidentally, were then engaged in legal battle with Apple) had bought a PostScript clone vendor, Bauer Technologies, and were looking for a font technology for OS/2's Presentation Manager.
The two got together and announced at the 1989 Seybold conference that they were going to develop a clone of PostScript based on Bauer's which would use Apple's new fonts on both the Macintosh and under OS/2.
The resulting uproar is still rumbling round the industry.
It is no longer a case of PostScript and the clones but a case of which PostScript.
If the Apple/Microsoft system can be made to work on both PCs and Macintoshes and is actually delivered within a reasonable space of time then it may become a second standard.
If IBM actually endorses it for the Presentation Manager it will become a second standard!
However, none of the font foundries are yet in a position to generate fonts, none of the typesetter vendors have RIPs and until Apple releases its System 7.0 software the whole issue is pretty academic anyway!
Meanwhile, Adobe has opened its doors, lifted the veil on Type 1 fonts and promised to do all it can to make, or rather keep, the current PostScript standard flying.
For the moment, at least, the situation is very clear.
If you want guaranteed matching between your screen image, your page printer proofs and the final imagesetter output then stick to a single standard — Adobe's PostScript.
This includes, naturally, buying only genuine PostScript fonts.
Incidentally, on the Macintosh it is now possible, using Adobe's Type Manager, to generate screen fonts directly from the printer font outlines.
This is one of the claimed benefits for Apple's System 7.0 but Adobe have also promised to deliver ATM for OS/2 as soon as possible.
If you don't want to go as far up the scale as typesetting then it doesn't really matter what imaging method you use; PCL, ACE, PostScript or a PostScript clone—so long as you don't try to mix and match the two
Fonts and how to use them
Setting aside the details of which desktop publishing package you use, the hardware that you run it on and the output device that produces the final pages there is one common element remaining; fonts.
Quite apart from their aesthetic values as part of the overall design of your documents their primary function is as a conveyer of information.
Deciding which to use and where is obviously important, a theme that has been explored before on these pages, but many users seem bewildered by the range of typefaces that are available.
Which work with what software?
And, in the final analysis, are they any good?
To understand the font situation it is necessary to step back to the time before there was desktop publishing, at least in an electronic sense.
Type was available in one of two forms; lead or optical.
The former were either cast separately or as lines or blocks while the optical versions were engraved on glass disks or photographically produced on strips of film.
Regardless of the method used to reproduce it, the typesetting systems of even a decade ago were slow, cumbersome and highly skill-intensive.
Each character was hand-crafted, relatively few sizes were available at any one time and there were limits to the maximum size available so that other methods were often used to generate headlines and so on.
The coming of digital type and computerised typesetting required that all the typefaces owned or licensed by a typesetter manufacturer had to be re-coded for the new systems.
Once again they were relatively complex to use and whilst smaller and faster still restricted the user to a few faces and sizes at any one time.
However, as the entire industry worked with cut and paste technology this wasn't seen as any real problem, headlines, captions and other type elements only really came together on the paste-up table.
Digital type, even five years ago, was almost entirely bitmapped.
Whilst a master outline of the character existed at the typesetter manufacturer or type foundry each font was compiled and tailored to suit the target system—generally at great expense.
It was argued that it would never be possible to produce these bitmaps in real time, ie to create each character as and when it was needed from a master outline.
This technique would save storage space, outlines take a fraction of the memory compared to the bitmaps they produce, and would allow fonts to be scaled to any size on demand.
And so it was that into the middle of this semi-digital world was launched the page printer.
Early page printing systems, such as the Canon CX engine used in printers like the HP LaserJet, were bitmap devices.
Character sets were produced by the manufacturer, stored as a pattern of dots in memory and then printed as required.
The range of typefaces available was small, the range of sizes even smaller and the typographic possibilities limited in the extreme.
However, the potential for desktop publishing as we know it today was born.
At roughly the same time Adobe Systems introduced the PostScript page description language which did the one thing that had been though impossible or, at least, impractical; real time font generation.
By storing each font as an outline they were able to supply either four or 11 complete families of type.
The family group consists, typically, of a Roman set (normal type), bold, italic and bold italic and, through the magic of PostScript, the characters could be produced at any size from around 4 point to, theoretically, infinity.
Typographically these fonts had a pedigree too in that the original designs came from either Linotype or the International Typeface Corporation.
Incidentally, Adobe are one of only two companies to have access to Linotypes originals, the other is Imagen.
So, the world of type is now divided clearly into two camps.
The first is that of the bitmapped font where each size and style has to be hand-crafted from an original master and tailored to suit the resolution of the output device, typically 300dpi.
These fonts are available as cartridges, on smart cards or as downloadable versions but they have two common characteristics.
Firstly, they tend not to originate from a real typographic font but are often variations on an original while, secondly, being bitmaps they cannot be scaled.
While the first point is of little real consequence except to the typographer the second means that if you only have 10 point and 12 point but want 14 point you are going to have a real problem!
Our second camp consists of outline fonts which can be scaled to produce a bitmap of any required size and style.
Here there are two approaches; that of real-time font generation such as that used by Adobe with its PostScript page description language and the off-line approach used by Bitstream with its Fontware package.
Both produce highly acceptable fonts in typographic terms but while PostScript fonts can be produced on demand those from Bitstream are only available in the sizes at which you generated them when the package was installed.
There are no real limits, other than disk storage, to the number of sizes and styles you could produce using Fontware but it can be very frustrating to find that the size you want isn't there and have to go back to the font compiler to produce it.
Bitstream are intending to get round this limitation by getting in league with the various page description language manufacturers and producing real-time fonts through their languages but as none of these are currently delivering we will have to wait in order to judge the result.
There is, however, one enormous fly in the ointment!
PostScript sacrificed performance for flexibility and, as a result, is capable of taking the same original information and producing it at any output resolution; 72, 300, 1270 or 2540dpi.
So far none of the other languages have addressed this problem and all appear to be stuck firmly at 300dpi.
If, as has been widely predicted, 400 or even 600dpi printers become available in the near future fonts produced by either bitmap or compiled outline methods are going to be left behind.
Going from 300dpi to 400dpi requires 84% more memory for both page and font information and whilst memory gets cheaper all the time the manufacturers will have to start moving to storing fonts on disk or even CD-ROM.
The final problem is that of matching fonts.
Each character in a font takes a precise amount of space on the page when it is printed.
The character's width, its height is already known by the point size, is stored in a width table.
For any desktop publishing package to work properly and display correct line endings it must have a screen font that matches the font in the printer; ie the width tables must match.
When dealing with the relatively simple world of a 300dpi page printer this is little trouble.
The font supplier provides one font for the screen so that the user will be able to see the type as it will appear and a second font for the printer.
Installing these does tend to be substantially easier on a Macintosh because here the screen is of a fixed resolution.
Within the PC environment there are at least four common resolutions plus dozens of hybrids which mean that the fonts have to be set up correctly for the display.
They do, however, work pretty well once the initial installation has been carried out.
For those intending to go the whole way and get their desktop publishing typeset the question of fonts and matching width tables really does cause problems.
Many fonts supplied have the same names as famous typographic faces but unless the typographer's width tables have been provided for the target device all sorts of trouble can occur.
Even with PostScript, which has a proven route to typesetting via the Linotron 100 and 300, variations can occur—not all of them minor.
The guilty party here is mathematics as 72 does not divide nicely into 300 nor does 300 divide into either 1270 or 2540.
Rounding errors which were present in one path may disappear in another causing the copy to fit more closely.
Some experiments have shown that changing the output device driver can alter the setting by as much as three or four lines per page!
In order to reduce problems to the minimum the following simple guidelines should help.
First, and most important, stick with fonts that were designed for the printer you are using even if this means giving up some of the typographic niceties.
Secondly, be prepared to experiment with other typeface libraries so long as the format they produce has compatible printer and screen fonts.
One without the other is useless.
Finally, if you want the ultimate flexibility of being able to select the resolution of the output device and scale fonts to the size you want at any time then you must work with outline fonts.
This last point does not necessarily mean that you have to be using a page description language but, for the moment at least, it amounts to the same thing.
There are no hard and fast rules when it comes to choosing which typeface and style to use within a document but there are guidelines which can reduce any potential conflicts.
Most page printers will come with a selection which will invariably include a serif face such a Times, a sans serif face like Helvetica and, often, a monospaced face.
The latter is often best left unused except where tables of figures are concerned.
Here it is quite acceptable and helps alignment which is never easy with proportionally spaced characters.
If we take a document such as a report we can apply the following guidelines.
Firstly, the text will generally look better in a serif face, especially if there is a lot of it.
To draw attention to headings and other important areas requires some form of emphasis so it is quite acceptable to use a sans serif face for these.
Underlining should never be used, either use bold or italic.
Bold serves to add ‘weight’, headings will typically be bolder than the text while italic adds a more subtle emphasis.
The number of typefaces should be restricted, two is adequate, and so should the range of sizes used.
Interestingly, typescript can be set significantly smaller than typewriter output yet be just as readable.
The main body of a report will be perfectly acceptable at 10pt and will actually reduce the amount of paper needed by perhaps 30%.
The key guideline, however, is consistency.
Don't be afraid to use other faces such as Bookman, Palatino or Avant Garde but try to avoid fancy ‘display’ faces like Chancery, Park Avenue and Cooper unless they are actually appropriate.
Using the wrong face can destroy the effect that a document was trying to create just as the wrong colour can ruin a decoration scheme
It must be quite hard for today's generation of personal computer users to grasp what all the fuss is about over the, so-called, ‘font wars’.
The much publicised schism between Adobe and Apple followed by the latter's siding with Microsoft—a company it was then attacking in the courts—all seems a little strange, especially so as there is no actual product involved, only a ‘standard’.
To put it into some form of perspective it is perhaps worth reviewing the whole issue of how fonts get displayed on a computer screen and why the method chosen to display them has become so important.
Turning the clock back to the point immediately before computers got involved in the publishing business there were only two real technologies at work; hot metal and cold metal.
In the former, each character was cast on demand and the composed page was built up either from lines of individual characters (Monotype's method) or from complete lines cast as a single element (Linotype's approach).
Cold setting was carried out by selecting the characters one at a time and placing them in a compositor's stick.
Once the line was complete it was transferred to a metal frame called a chase and, once this was full, the whole page was ready to be printed.
Classic, labour and skill intensive printing technology that was largely unchanged since the days of Gutenberg.
Then came the advent of the digital computer and this brought about the concept of setting type by using light—phototypesetting.
Several methods were evolved but all basically followed the principle of having a character exposed onto a strip of sensitive photographic film or paper which was then developed to give a positive or negative image which could be reproduced by offset printing.
The computer's place in all this was in the control of either the mechanical discs or strips that carried the images of each character or, later on, in the generation and display of the characters themselves on a CRT.
There was much hue and cry among the typesetting and printing community about the quality of this new-fangled technology but the one element that was retained was that of the compositor's skill.
Because computer memory was prohibitively expensive and the machines terribly slow (at least by today's standards) it was impossible for the compositor to see what was being typeset until it had all been processed.
All the changes of typeface and style were carried out by complex codes—each unique to the typesetter's manufacturer—and these took months to learn.
And, as an added constraint, each vendors typefaces would only fit that system.
Gone were the days of the interchangeability of lead type—each vendor and type foundry wanted to vigorously protect its typographic heritage from this electronic heresy.
During the Sixties and Seventies the systems gradually improved, the computer parts got more powerful and cheaper and it even became possible to get some sort of an idea as to what the page might look like.
You couldn't edit the preview display, of course, and the typefaces were generic rather than accurate representations but things were, it seemed, moving in the right direction.
One thing that definitely wasn't moving very much, however, was the cost of type.
At the beginning of the 1980's a typeface would have cost around $4,500 and you would probably have had to wait a couple of weeks while it was digitised from some master copy.
In real terms the cost hadn't changed that much since the days of hot metal when you needed a new matrix for each font and, after all, why should it have.
By the mid 1980's the emergence of lower priced computer systems and the vast increase in demand had forced the price of a typeface down to around $450, the classic ‘generation’ jump that is often seen in computing hardware and software pricing.
What happened next was to so profoundly influence the way the typesetting market operated that it still hasn't fully come to terms with the consequences.
In 1984 a number of key targets were met in the computer industry.
The first was the introduction of the Apple Macintosh which was the first personal computer to be based entirely on a graphical interface as opposed to the more conventional character-at-a-time systems.
(In reality, Apple had already tested the water with the Lisa but this was over-priced and very short on software.)
Much of the technology used in the Macintosh came via Xerox's Palo Alto Research Centre where they had also been investigating page printing technology and methods of transferring complex graphics between screens and the printed page.
The second introduction was Canon's first OEM page printing engine, the CX, which was first seen in Hewlett-Packard's LaserJet printer.
At this point it becomes impossible to determine in what exact sequence events happen but essentially computer memory dropped below $1,000 for a megabyte which allowed a complete page of A4 paper to be created in memory at 300 dots per inch.
This, in turn, allowed Adobe, a company founded by two ex-Xerox PARC researchers, to turn their PostScript page description language into a marketable product that could be built into a page printer.
Their first customer was Apple and this formed the basis of the relationship between the two companies—mainly forged by Steve Jobs, John Warnock and Chuck Geschke.
Apple liked the idea so much that they invested a 20% stake in Adobe making themselves the largest customer.
What Adobe had done that had defeated virtually everyone else, certainly at the microcomputer level, was to build typefaces ‘on-the-fly’ from outlines.
Rather than store a bitmap of each character at every size it might be required, something that takes prodigious amounts of memory or disk storage, they used a single digital outline of the character and generated the required bitmap on demand.
And these weren't any old typefaces, they were Linotype's which meant that they conformed to the highest typographic standards the industry was likely to require.
Of course, outputting them at 300dpi meant making some sacrifices so Adobe build in a mechanism for improving the shapes of the characters at low resolution, the technique is called hinting, and to protect their investment they encrypted both the typefaces and the hinting method so that the faces would only work properly with their own version of PostScript.
The definition of the PostScript language has always been in the public domain and Adobe always anticipated that other companies would produce versions of it.
What those companies were unable to do, however, was unlock the encryption of the typefaces, the so-called Type 1 format, and they were forced to use fonts from other sources coded to the more open, but un-hinted, Type 3 format.
So long as both the computer's screen fonts and the printer or typesetter fonts were from the same source this caused no great problems but if the two were mixed then real trouble could occur.
The world complained about Adobe's restrictions but all the major typesetter vendors realised that a single well defined and maintained standard was better than the previous chaos and so adopted Adobe's PostScript.
In addition, their type foundries also took licenses and began the production of first Type 3 and then Type 1 fonts.
Apple, however, had decided to reduce its reliance on external technologies and, after some considerable debate, decided not to continue with Adobe's PostScript alone but to further develop its own system software so that it could better control both type and graphics.
In the announcement of their forthcoming System 7 software they revealed that they were moving towards the concept of using outline fonts to generate the screen displays and that they were developing their own proprietary format, then known as Royal but subsequently re-named TrueType.
Also buried deep in the text of the announcement was the fact that they were intending to develop their own page description language.
Shortly after this they sold their 20% stake in Adobe, netting a huge profit in the process, and the world began to take notice of what looked like an interesting scenario.
What was unexpected, at least by Adobe, was that Microsoft, who were themselves looking for an outline font technology for Presentation Manager, would side with Apple and agree to adopt TrueType.
In return, Microsoft let Apple have access to the PostScript interpreter which they had acquired by buying up Bauer Industries.
This, remember, was a deal between two companies that were then at loggerheads in the courts!
The problems really begin at this point.
It must be realised that neither System 7, Royal fonts or Bauer/Microsoft's PostScript (now called TrueImage) actually exist as marketable products.
We simply don't know how good they are or how well they will conform to the current Adobe PostScript standards.
However, just prior to the split Adobe had announced, and have subsequently delivered, a mechanism (Adobe Type Manager) for generating on-screen bitmap fonts from outlines—the same outlines that are used for printing.
They have also lifted the encryption on Type 1 fonts and published the hinting specifications in the light of the Apple/Microsoft deal.
Apple, however, are adamant that TrueType and TrueImage (for which no typesetter or page printer currently exists) will be capable of imaging both font formats.
Indeed, Apple have just launched a new, low-cost PostScript printer which uses Adobe's latest software based on ATM and there are indications that Adobe has written the routines that will allow TrueType fonts to be imaged on PostScript printers.
For the PC user, who might have imagined that all this was a storm in a teacup, the world is also about to do a complete volte face.
As PostScript is something of a second fiddle to Hewlett-Packard's PCL in the PC world you might have thought that this was nothing to do with you.
Well, you couldn't have been more wrong.
The launch of Windows 3.0 has been rapidly followed by Adobe's announcement of ATM for Windows and the emergence of a new player, Bitstream.
This company already holds the dominant position in add-on type for the PC and has now announced a product called Facelift that, like ATM, will build screen fonts on-the-fly in Windows 3.0.
Add to this the recent announcements by Kodak and Xerox that they have adopted Adobe PostScript as a future imaging model and you begin to see a whole new world opening up where the PC is, at last, able to hold its head up in the Macintosh dominated publishing market.
At the moment the problems are merely clouds forming on the horizon, users need to be aware of them and the potential problems that they may bring.
When they arrive, and like clouds they may have dispersed by then, we will be able to evaluate the problems and implications.
One thing is certain, however, and that is that Adobe's monopoly on PostScript and its fonts has been broken.
What we have to hope for is that its control over the language and its position as an arbiter of the quality of that language are maintained.
If we end up with two radically different versions of PostScript then we face real and serious problems
Glossary
A/W
an abbreviation for Artwork.
Acetate
a transparent sheet placed over artwork allowing the artist to write instructions or indicate where second colour is to be placed.
(See Overlay)
Addendum
supplementary material additional to the main body of a book and printed separately at the start or end of the text.
Air (US)
an amount of white space in a layout.
Airbrush
a mechanical painting tool producing an adjustable spray of paint driven by compressed air.
Used in illustration design and photographic retouching.
Align
to line up typeset or other graphic material as specified, using a base or vertical line as the reference point.
Alphabet (length or width)
the measurement of a complete set of lower case alphabet characters in a given type size expressed in points or picas.
Anodized plate
an offset printing plate with a specially treated surface to reduce wear during printing.
Apex
the point of a character where two lines meet at the top, an example of this is the point on the letter A.
Apron (US)
additional white space allowed in the margins of text and illustrations when forming a foldout.
Art (US)
in graphic arts usage, all matter other than text material eg illustrations and photographs.
Art paper
a smooth coated paper obtained by adding a coating of china clay compound on one or both sides of the paper.
Ascender
any part of a lower case letter extending above the x-height.
For example, the upper half of the vertical in the letters b or h.
Authors corrections
changes made to the copy by the author after typesetting but not including those made as a result of errors in keying in the copy.
Backing up
to print the second side of printed sheet.
Backslant
letters that slant the opposite way from italic characters.
Balloon
a circle or bubble enclosing copy in an illustration.
Used in cartoons.
Bank
a lightweight writing paper.
Banner
a large headline or title extending across the full page width.
Base artwork
artwork requiring additional components such as halftones or line drawings to be added before the reproduction stage.
Baseline
the line on which the bases of capital letters sit.
Bed
the base on which the Forme is held when printing by Letterpress.
Binding
the various methods used to secure loose leaves or sections in a book; eg saddle-stitch, perfect bound.
Black patch
material used to mask the window area on a negative image of the artwork prior to‘stripping in’ a halftone.
Blanket cylinder
the cylinder via which the inked litho plate transfers the image to the paper.
The cylinder is covered with a rubber sheet which prevents wear to the litho plate coming into contact with the paper.
Bleed
layout, type or pictures that extend beyond the trim marks on a page.
Illustrations that spread to the edge of the paper without margins are referred to as ‘bled off’.
Blind emboss
a raised impression made without using ink or foil.
Block in
to sketch in the main areas of an image prior to the design.
Blow up
an enlargement, most frequently of a graphic image or photograph.
Blurb
a short description or commentary of a book or author on a book jacket.
Board
paper of more than 200gsm.
Body (US)
the main text of the work but not including headlines.
Body size
the height of the type measured from the top of the tallest ascender to the bottom of the lowest descender.
Normally given in points, the standard unit of type size.
Bold type
type with a heavier darker appearance.
Most typefaces have a bold face.
Bond
a sized finished writing paper of 50gsm or more.
Can also be used for printing upon.
Border
a continuous decorative design or rule surrounding the matter on the page.
Box
a section of text marked off by rules or white space and presented separately from the main text and illustrations.
Longer boxed sections in magazines are sometimes referred to as sidebars.
Bristol board
a fine board made in various qualities for drawing.
Broadside
an original term for work printed on one side of a large sheet of paper.
Bromide
a photographic print made on bromide paper.
Bronzing
an effect produced by dusting wet ink after printing with a metallic powder.
Bullet
a large dot preceding text to add emphasis.
Calendered finish
produced by passing paper through a series of metal rollers to give a very smooth surface.
Caliper
the thickness of sheet of paper or board expressed in microns (millionths of a metre).
Also the name of the tool used to make the measurement.
Camera ready
artwork or pasted up material that is ready for reproduction.
Cap line
an imaginary line across the top of capital letters.
The distance from the the cap line to the baseline is the cap size.
Caps
an abbreviation for capital letters.
Caps and small caps
a style of type that shows capital letters used in the normal way while the body copy is set in capital letters which are of a slightly smaller size.
Caption
the line or lines of text that refer to information identifying a picture or illustration.
Carbonless
paper coated with chemicals and dye which will produce copies without carbon paper.
Also referred to as NCR (No Carbon Required).
Caret marks
an indication to the printer of an omission in the copy indicated as () showing the insertion.
Cartridge
a thick general purpose paper used for printing, drawing and wrapping.
Case bound
a hardback book made with stiff outer covers.
Cases are usually covered with cloth, vinyl or leather.
Cast coated
art paper with a exceptionally glossy coated finish usually on one side only.
Cast off
a calculation determining how much space copy will take up when typeset.
Catchline
a temporary headline for identification on the top of a galley proof.
Century Schoolbook
a popular serif typeface used in magazines and books for text setting which has a large x-height and an open appearance.
Chalking
a powdering effect left on the surface of the paper after the ink has failed to dry satisfactorily due to a fault in printing.
Character count
the number of characters; ie letters, figures, signs or spaces in a piece of copy, line or paragraph used as a first stage in type calculations.
Chase
a metal frame in which metal type and blocks (engravings) are locked into position to make up a page.
Close up
a proof correction mark to reduce the amount of space between characters or words indicated as ().
Coated
printing papers which after making have had a surface coating with clay etc, to give a smoother, more even finish with greater opacity.
Cold type
type produced without the use of characters cast from molten metal, such as on a VDU.
Collate
to gather separate sections or leaves of a book together in the correct order for binding.
Colour separations
the division of a multi-coloured original or line copy into the basic (or primary) process colours of yellow, magenta, cyan and black.
These should not be confused with the optical primaries; red, green and blue.
Column inch
a measure of area used in newspapers and magazines to calculate the cost of display advertising.
A column inch is one column wide by one inch deep.
Column rule
a light faced vertical rule used to separate columns of type.
Compose
to set copy into type.
Concertina fold
a method of folding in which each fold opens in the opposite direction to its neighbour, giving a concertina or pleated effect.
Condensed
a style of typeface in which the characters have an elongated appearance.
Continuous tone
an image in which the subject has continuous shades of colour or grey without being broken up by dots.
Continuous tones cannot be reproduced in that form for printing but must be screened to translate the image into dots.
Contrast
the degree of tones in a photograph ranging from highlight to shadow.
Copyright
The right of copyright gives protection to the originator of material to prevent use without express permission or acknowledgement of the originator.
Corner marks
marks printed on a sheet to indicate the trim or register marks.
Cropping
the elimination of parts of a photograph or other original that are not required to be printed.
Cropping allows the remaining parts of the image to be enlarged to fill the space.
Cross head
a heading set in the body of the text used to break it into easily readable sections.
Cursive
used to describe typefaces that resemble written script.
Cut flush
a method of trimming a book after the cover has been attached to the pages.
Cutout
a halftone where the background has been removed to produce a silhouette.
DPI (Dots Per Inch)-
the measurement of resolution for page printers, phototypesetting machines and graphics screens.
Currently graphics screens reproduce 60 to 100dpi, most page printers work at 300dpi and typesetting systems operate at 1,000dpi and above.
Dagger and double dagger
symbols used mainly as reference marks for footnotes.
Dash
a short horizontal rule used for punctuation.
Descender
any part of a lower case letter that extends below the x-height, as in the case of y and j.
Die
a hardened steel engraving stamp used to print an inked image.
Used in the production of good quality letter headings.
Disk Operating System (DOS)-
software for computer systems with disk drives which supervises and controls the running of programs.
The operating system is ‘booted’ into the computer from disk by a small program which permanently resides in the memory.
Common operating systems include MS-DOS, PC-DOS (IBM's version of MS-DOS), CP/M (an operating system for older, 8-bit computers), Unix and BOS.
Display type
larger type used for headings etc.
Normally about 18 point or larger.
Dot matrix printer -
a printer in which each character is formed from a matrix of dots.
They are normally impact systems, ie a wire is fired at a ribbon in order to leave an inked dot on the page, but thermal and electro-erosion systems are also used.
Double density -
a method of recording on floppy disks using a modified frequency modulation process that allows more data to be stored on a disk.
Double page spread
two facing pages of newspaper or magazine where the textual material on the left hand side continues across to the right hand side.
Abbreviated to DPS.
Downloadable fonts -
type faces which can be stored on a disk and then downloaded to the printer when required for printing.
These are, by definition, bit-mapped fonts and, therefore, fixed in size and style.
Drawn on
a method of binding a paper cover to a book by drawing the cover on and gluing to the back of the book.
Drop cap
a large initial letter at the start of the text that drops into the line or lines of text below.
Dry transfer (lettering)
Characters, drawings, etc, that can be transferred to the artwork by rubbing them off the back of the transfer sheet.
Best known is Letraset.
Dye transfer
a photographic colour print using special coated papers to produce a full colour image.
Can serve as an inexpensive proof.
EGA (Enhanced Graphics Adapter)-
a graphics standard for the PC which can be added or built into a system to give sharper characters and improved colour with the correct display device.
Standard EGA resolution is 640 by 350 dots in any 16 out of 64 colours.
Egyptian
a term for a style of type faces having square serifs and almost uniform thickness of strokes.
Eight sheet
a poster measuring 60 × 80in (153 × 203cm) and, traditionally, made up of eight individual sheets.
Electronic Publishing -
a generic term for the distribution of information which is stored, transmitted and reproduced electronically.
Teletext and Videotext are two examples of this technology in its purest form, ie no paper.
Desktop publishing forms just one part of the electronic publishing market.
Em
in printing terms it is a square unit with edges equal in size to the chosen point size.
It gets its name from the letter M which originally was as wide as the type size.
Em dash
a dash used in punctuation the length of one em.
Embossing
relief images formed by using a recessed die.
En
a unit of measurement that is half as wide as an em.
En dash
a dash approximately half the width of an em dash.
End papers
the four page leaves at the front and end of a book which are pasted to the insides of the front and back covers (boards).
Epson emulation -
the industry standard control codes for dot matrix printers were developed by Epson and virtually all software packages and most dot matrix printers either follow or improve on these codes.
Exception dictionary -
in word processing or desktop publishing this is a store of pre-hyphenated words that do not conform to the usual rules contained in the hyphenation and justification program (H).
Some programs, PageMaker for example, only use an exception dictionary.
Expanded type
a typeface with a slightly wider body giving a flatter appearance.
Express -
a printer control language developed by OASYS.
Face
an abbreviation for typeface referring to a family in a given style.
Filler
extra material used to complete a column or page, usually of little importance.
Flag
the designed title of a newspaper as it appears at the top of page one.
Flexography
a rotary letterpress process printing from rubber or flexible plates and using fast drying inks.
Mainly used for packaging.
Floating accent
an accent mark which is set separately from the main character and is then placed either over or under it.
Floppy disk -
(see disk)
Flush left
copy aligned along the left margin.
Flush right
copy aligned along the right margin.
Flyer
an inexpensively produced circular used for promotional distribution.
Foil blocking
a process for stamping a design on a book cover without ink by using a coloured foil with pressure from a heated die or block.
Font (or fount)
a complete set of characters in a typeface.
Form letter -
used in word processing to describe a repetitive letter in which the names and addresses of individuals are automatically generated from a data base or typed individually.
Forme
type and blocks assembled in pages and imposed in a metal chase ready for printing.
Four colour process
printing in full colour using four colour separation negatives—yellow, magenta, cyan and black.
French fold
a sheet which has been printed on one side only and then folded with two right angle folds to form a four page uncut section.
Full measure
a line set to the entire line length.
Full point
a full stop.
GEM -
Digital Research's Graphics Environment Manager.
A graphical interface designed both to make the operation of software simpler for the non-expert and to allow programs to communicate with one another.
Two key desktop publishing packages, Ventura and DR's own GEM Desktop Publisher operate under this environment.
GSM
Grams per square metre.
The unit of measurement for paper weight.
Galley proof
proofs taken from the galleys before being made up into pages.
Galleys
the printing term for long metal trays used to hold type after it had been set and before the press run.
Gatefold
an oversize page where both sides fold into the gutter in overlapping layers.
Used to accommodate maps into books.
Gathering
the operation of inserting the printed pages, sections or signatures of a book in the correct order for binding.
Gloss ink
for use in litho and letterpress printing on coated papers where the ink will dry without penetration.
Golden ratio
the rule devised to give proportions of height to width when laying out text and illustrations to produce the most optically pleasing result.
Gothic
typefaces with no serifs and broad even strokes.
Gravure
a rotary printing process where the image is etched into the metal plate attached to a cylinder.
The cylinder is then rotated through a trough of printing ink after which the etched surface is wiped clean by a blade leaving the non-image area clean.
The paper is then passed between two rollers and pressed against the etched cylinder drawing the ink out by absorption.
Greeking -
a software device where areas of grey are used to simulate lines of text.
One of desktop publishing's less clever methods of getting round the slowness of high resolution displays on the PC.
Grey scale -
a range of luminance values for evaluating shading through white to black.
Frequently used in discussions about scanners as a measure of their ability to capture halftone images.
Basically the more levels the better but with correspondingly larger memory requirements.
Grid
A systematic division of a page into areas to enable designers to ensure consistency.
The grid acts as a measuring guide and shows text, illustrations and trim sizes.
Guard
a narrow strip of paper or linen pasted to a single leaf to allow sewing into a section for binding.
Gutter
the central blank area between left and right pages.
Hairline rule
the thinnest rule that can be printed.
Hairlines
the thinnest of the strokes in a typeface.
Half up
artwork one and a half times the size which it will be reproduced.
Halftone
an illustration reproduced by breaking down the original tone into a pattern of dots of varying size.
Light areas have small dots and darker areas or shadows have larger dots.
Halftone screen
a glass plate or film placed between the original photograph and the film to be exposed.
The screen carries a network of parallel lines.
The number of lines to the inch controls the coarseness of the final dot formation.
The screen used depends on the printing process and the paper to be used, the higher the quality the more lines can be used.
Hanging punctuation
punctuation that is allowed to fall outside the margins instead of staying within the measure of the text.
Hard disk -
a rigid disk sealed inside an airtight transport mechanism.
Information stored may be accessed more rapidly than on floppy disks and far greater amounts of data may be stored, typically 20M as opposed to 1.2M for a floppy disk.
Often referred to as Winchester disks.
Hardback
a case bound book with a separate stiff board cover.
Head
the margin at the top of a page.
Helvetica
a sans serif typeface.
Hickies
a dust particle sticking to the printing plate or blanket which appears on the printed sheet as a dark spot surrounded by an halo.
Highlight
the lightest area in a photograph or illustration.
House style
The style of preferred spelling, punctuation, hyphenation and indentation used in a publishing house or by a particular publication to ensure consistent typesetting.
ISBN
International Standard Book Number.
A reference number given to every published work.
Usually found on the back of the title page.
Icons -
pictorial images used on screen to indicate utility functions, files, folders or applications software.
The icons are generally activated by an on-screen pointer controlled by a mouse or trackball.
Imposition
refers to the arrangement of pages on a printed sheet, which when the sheet is finally printed on both sides, folded and trimmed, will place the pages in their correct order.
Impression cylinder
the cylinder of a printing machine which brings the paper into contact with the with the printing plate or blanket cylinder.
Imprint
the name and place of the publisher and printer required by law if a publication is to be published.
Sometimes accompanied by codes indicating the quantity printed, month/year of printing and an internal control number.
Insert
an instruction to the printer for the inclusion of additional copy.
Interface -
the circuit, or physical connection, which controls the flow of data between a computer and its peripherals.
International paper sizes
the International Standards Organisation (ISO) system of paper sizes is based on a series of three sizes A, B and C. Series A is used for general printing and stationery, Series B for posters and Series C for envelopes.
Interpress -
Xerox Corporation's page description language which was the first such product to be implemented.
At present the language still has to be adopted commercially by a third party.
Italic
type with sloping letters.
Ivory board
a smooth high white board used for business cards etc.
Justify
the alignment of text along a margin or both margins.
This is achieved by adjusting the spacing between the words and characters as necessary so that each line of text finishes at the same point.
K (Kilobyte)-
1024 bytes, a binary 1,000.
Keep standing
to hold type or plates ready for reprints.
Kerning
the adjustment of spacing between certain letter pairs, A and V for example, to obtain a more pleasing appearance.
Not all DTP systems can achieve this.
Keyline
an outline drawn or set on artwork showing the size and position of an illustration or halftone.
Kraft paper
a tough brown paper used for packing.
Laid
paper with a watermark pattern showing the wire marks used in the paper making process.
Usually used for high quality stationery.
Laminate
a thin transparent plastic coating applied to paper or board to provide protection and give it a glossy finish.
Landscape
work in which the width used is greater than the height.
Also used to indicate the orientation of tables or illustrations which are printed ‘sideways’.
See Portrait.
Laser printer (see also Page printer)-
a high quality image printing system using a laser beam to produce an image on a photosensitive drum.
The image is transferred on to paper by a conventional xerographic printing process.
Currently, most laser printers set at 300dpi with newer models operating at up to 600dpi.
Lateral reversal
a positive or negative image transposed from left to right as in a mirror reflection of the original.
Layout
a sketch of a page for printing showing the position of text and illustrations and giving general instructions.
Lead or Leading
Space added between lines of type to space out text and provide visual separation of the lines.
Measured in points or fractions thereof.
Named after the strips of lead which used to be inserted between lines of metal type.
Legend
the descriptive matter printed below an illustration, mostly referred to as a caption.
Also an explanation of signs or symbols used in timetables or maps.
Letraset
a proprietary name for rub-down or dry transfer lettering used in preparing artwork.
Letterpress
a relief printing process in which a raised image is inked to produce an impression; the impression is then transferred by placing paper against image and applying pressure.
Letterset
a printing process combining offset printing with a letterpress relief printing plate.
Letterspacing
the addition of space between the letters of words to increase the line-length to a required width or to improve the appearance of a line.
Library picture
a picture taken from an existing library and not specially commissioned.
Ligature
letters which are joined together as a single unit of type such as oe and fi.
Lightface
type having finer strokes than the medium typeface.
Not used as frequently as medium.
Line block
a letterpress printing plate made up of solid areas and lines and without tones.
Line gauge
a metal rule used by printers.
Divided into Picas it is 72 picas long (11.952in).
Linen tester
a magnifying glass designed for checking the dot image of a halftone.
Lineup table
a table with an illuminated top used for preparing and checking alignment of page layouts and paste-ups.
Lining figures
numerals that align on the baseline and at the top.
Linotype -
manufacturers of a range of high resolution phototypsetting machines such as the 100, 202, 300 and 500.
The 100, 300 and 500 series are capable of processing PostScript files through an external RIP and setting direct from disk at 1270dpi and beyond.
Lithography
a printing process based on the principle of the natural aversion of water to grease.
The photographically prepared printing plate when being made is treated chemically so that the image will accept ink and reject water.
Logo
short for logotype.
A word or combination of letters set as a single unit.
Also used to denote a specially styled company name designed as part of a corporate image.
Loose leaf
a method of binding which allows the insertion and removal of pages for continuous updating.
Lotus 123 -
the classic spreadsheet package combining from which the vast majority of PC-based business graphics are generated.
Lower case
the small letters in a font of type.
M (Megabyte)-
one million bytes.
MG (Machine glazed)
paper with a high gloss finish on one side only.
MS (Manuscript)
the original written or typewritten work of an author submitted for publication.
Machine glazed (MG)
paper with a high gloss finish on one side only.
Macro -
a series of instructions which would normally be issued one at a time on the keyboard to control a program.
A macro facility allows them to be stored and issued automatically by a single keystroke.
Magnetic ink
a magnetized ink that can be read both by humans and by electronic machines.
Used in cheque printing.
Make-up
the assembling of all elements, to form the printed image.
Making ready
the time spent in making ready the level of the printing surface by packing out under the forme or around the impression cylinder.
Manilla
A tough brown paper used to produce stationery and wrapping paper.
Manuscript (MS)
the original written or typewritten work of an author submitted for publication.
Margins
the non printing areas of page.
Mark up
copy prepared for a compositor setting out in detail all the typesetting instructions.
Mask
opaque material or masking tape used to block-off an area of the artwork.
Masthead
details of publisher and editorial staff usually printed on the contents page.
Matt art
a coated printing paper with a dull surface.
Measure
denotes the width of a setting expressed in pica ems.
Mechanical binding
a method of binding which secures pre-trimmed leaves by the insertion of wire or plastic spirals through holes drilled in the binding edge.
Mechanical tint
a pre-printed sheet of dots, lines or patterns that can be laid down on artwork for reproduction.
Memory -
the part of the computer which stores information for immediate access.
Nowadays this consists exclusively of RAM, random access memory, which holds the applications software and data or ROM, read only memory, which holds permanent information such as the DOS bootstrap routines.
Memory size is expressed in K or M.
Menu-driven -
programs which allow the user to request functions by choosing from a list of options.
Metallic ink
printing inks which produce an effect gold, silver, bronze or metallic colours.
Mock-up
the rough visual of a publication or design.
Modem (MOdulator-DEModulator)-
a device for converting digital data into audio signals and back again.
Primarily used for transmitting data between computers over telephone lines.
Modern
refers to type styles introduced towards the end of the 19th century.
Times roman is a good example of modern type.
Moire pattern
the result of superimposing half-tone screens at the wrong angle thereby giving a chequered effect on the printed half-tone.
Normally detected during the stage of progressive proofs.
Monospace
a font in which all characters occupy the same amount of horizontal width regardless of the character.
Montage
a single image formed from the assembling of several images.
Mounting board
a heavy board used for mounting artwork.
Mouse -
a handheld pointing device using either mechanical motion or special optical techniques to convert the movement of the user's hand into movements of the cursor on the screen.
Generally fitted with one, two or three buttons which can control specific software functions.
Mutt
a typesetting term for the em space.
Newsprint
Unsized, low quality, absorbent paper used for printing newspapers.
Nipping
a stage in book binding where after sewing the sheets are pressed to expel air.
OCR (Optical Character Recognition)-
a special kind of scanner which provides a means of reading printed characters on documents and converting them into digital codes that can be read into a computer as actual text rather than just a picture.
Oblique stroke
(/)
Offprint
a run-on or reprint of an article first published in a magazine or journal.
Offset lithography
(see Lithography) a printing method whereby the image is transferred from a plate onto a rubber covered cylinder from which the printing takes place.
Oldstyle (US)
a style of type characterised by stressed strokes and triangular serifs.
An example of an oldstyle face is Garamond.
Onion skin
a translucent lightweight paper used in air mail stationery.
Opacity
term used to describe the degree to which paper will show print through.
Optical Disks -
video disks on which large amounts of information can be stored in binary form representing characters of text or images.
The disks cannot be used to view the information using a modified compact disk player and TV.
Mainly used for reference works such as dictionaries, encyclopedias, etc.
Optical centre
a point above the true centre of the page which will not appear ‘low’ as the geometric centre does.
Orphan
line of type on its own at the top or bottom of a page.
Outline
a typeface in which the characters are formed with only the outline defined rather than from solid strokes.
Overlay
a transparent sheet used in the preparation of multi-colour artwork showing the colour breakdown.
Overprinting
printing over an area already printed.
Used to emphasise changes or alterations.
Overs
additional paper required to compensate for spoilage in printing.
Also used to refer to a quantity produced above the number of copies ordered.
Overstrike -
a method used in word processing to produce a character not in the typeface by superimposing two separate characters, eg $ using s and l.
Ozalid
a trade name to describe a method of copying page proofs from paper or film.
Page Description Language (PDL)-
a special form of programming language which enables both text and graphics (object or bit-image) to be described in a series of mathematical statements.
Their main benefit is that they allow the applications software to be independent of the physical printing device as opposed to the normal case where specific routines have to be written for each device.
Typical PDLs include Interpress, imPress, PostScript and DDL.
Page Printer -
the more general (and accurate) name used to describe non-impact printers which produce a complete page in one action.
Examples include laser, LED and LCD shutter xerographic printers, ion deposition, electro-erosion and electro-photographic printers.
Page proofs
the stage following galley proofs, in which pages are made up and paginated.
PageMaker -
the software program from Aldus Corporation that everyone associates with desktop publishing due to its immense success on the Apple Macintosh.
Now available on both the Macintosh and the PC it is still used as a benchmark product although certain aspects of its design are coming under attack from other, more recent, products.
Pagination
the numbering of pages in a book.
Pantone
a registered name for an ink colour matching system.
Paper plate
a short run offset printing plate on which matter can be typed directly.
Paragraph mark
a type symbol used to denote the start of a paragraph when the text is not indented.
Also used as a footnote sign.
Parallel fold
a method of folding; eg two parallel folds will produce a six page sheet.
Paste up
the various elements of a layout mounted in position to form camera-ready artwork.
Perfect binding
a common method of binding paperback books.
After the printed sections having been collated, the spines will be ground off and the cover glued on.
Perfector
a printing press which prints both sides of the paper at one pass through the machine.
Photogravure
(see Gravure) a printing process where the image is etched into the plate cylinder.
The main advantage of this method of printing is the high speed, long run capability.
Used mainly for mail order and magazine work.
Pi fonts
characters not usually included in a font, but which are added specially.
Examples of these are timetable symbols and mathematical signs.
Pica
a printing industry unit of measurement.
There are 12 points to a pica, one pica = 0.166in.
Picking
the effect of ink being too tacky and lifting fibres out of the paper.
Shows up as small white dots on areas of solid colour.
Pipelining -
the ability of a program to flow automatically text from the end of one column or page to the beginning of the next.
An extra level of sophistication can be created by allowing the flow to be re-directed to any page and not just the next available.
This is ideal for US-style magazines where everything is ‘Continued on…’!
Point
the standard unit of type size of which there are 72 to the inch (one point = 0.01383in).
Point size is the measured from the top of the ascender to the bottom of the descender.
Portrait
an upright image or page where the height is greater than the width.
Positive
a true photographic image of the original made on paper or film.
PostScript -
a page description language developed by Adobe Systems.
Widely supported by both hardware and software vendors it represents the current ‘standard’ in the market.
John Warnock and Chuck Geschke of Adobe both worked for Xerox at the Palo Alto Research Centre where PDLs were invented and set up their company to commercially exploit the concepts they had helped develop.
Preview (soft) mode
a facility within a non-WYSIWYG program which shows a formatted page in true type size.
Preview mode -
a mode where word processing or desktop publishing software which doesn't operate in WYSIWYG fashion can show a representation of the output as it will look when printed.
The quality ranges from acceptable to worse than useless.
Primary colours
cyan, magenta and yellow.
These three colours when mixed together with black will produce a reasonable reproduction of all other colours.
Print engine -
the parts of a page printer which perform the print-imaging, fixing and paper transport.
In fact, everything but the controller.
Printer Command Language -
a language developed by Hewlett Packard for use with its own range of printers.
Essentially a text orientated language, it has been expanded to give graphics capability.
Progressives
colour proofs taken at each stage of printing showing each colour printed singly and then superimposed on the preceding colour.
Proof
a copy obtained from inked type, plate, block or screen for checking purposes.
Proof correction marks
a standard set of signs and symbols used in copy preparation and to indicate corrections on proofs.
Marks are placed both in the text and in the margin.
Proportional spacing -
the ability to vary the amount of horizontal space occupied by each character according to its width so that, for example , ‘i's occupy less space than ‘m's.
Proportional spacing
a method of spacing whereby each each character is spaced to accommodate the varying widths of letters or figures, so increasing readability.
Books and magazines are set proportionally spaced, typewritten documents are generally monospaced.
Pull-down menus -
developed from Xerox research (like just about everything else we take for granted in desktop publishing) these are a method of providing user control over software without cluttering up the screen with text.
Using the mouse or cursor keys the user points to the main heading of the menu he or she wants and the menu pulls (Windows) or drops (GEM) from the heading.
When the required function has been selected the menu rolls back up into the menu bar leaving the screen clear.
Pulp
the raw material used in paper making consisting mainly of wood chips, rags or other fibres.
Broken down by mechanical or chemical means.
Quadding
the addition of space to fill out a line of type using en or em blocks.
Quire
of a ream (25 sheets).
Rag paper
high quality stationery made from cotton rags.
Ragged
lines of type that do not start or end at the same position.
Ranged left/right
successive lines of type which are of unequal length and which are aligned at either the right or left hand column.
Raster Image Processor (RIP)-
the hardware engine which calculates the bit-mapped image of text and graphics from a series of instructions.
It may, or may not, understand a page description language but the end result should, if the device has been properly designed, be the same.
Typical RIPs which aren't PDL-based include the Tall Trees JLaser, the LaserMaster and AST's TurboLaser controller.
A basic page printer comes with a controller and not a RIP which goes some way to explaining the lack of control that can be achieved with printers like HP's LaserJet and Ricoh's 4080.
Ream
500 sheets of paper.
Register
the correct positioning of an image especially when printing one colour on another.
Register marks
used in colour printing to position the paper correctly.
Usually crosses or circles.
Resolution
the measurement used in typesetting to express quality of output.
Measured in dots per inch, the greater the number of dots, the more smoother and cleaner appearance the character/image will have.
Currently Page (laser) Printers print at 300, 406 and now available 600 dpi.
Typesetting machines print at 1200 dpi or more.
Rest in Proportion (RIP)
an instruction when giving sizes to artwork or photographs that other parts of the artwork are to be enlarged or reduced in proportion.
Retouching
a means of altering artwork or colour separations to correct faults or enhance the image.
Reverse out
to reproduce as a white image out of a solid background.
Revise
indicates the stages at which corrections have been incorporated from earlier proofs and new proofs submitted.
Eg First revise, second revise.
Right reading
a positive or negative which reads from left to right.
Roman
type which has vertical stems as distinct from italics or oblique which are set at angles.
Rotary press
a web or reel fed printing press which uses a curved printing plate mounted on the plate cylinder.
Rough
a preliminary sketch of a proposed design.
Royal
a size of printing paper 20in × 25in (508 × 635mm).
Ruler
rulers displayed on the screen that show measures in inches, picas or millimeters.
Runaround (see also Text wrap)
the ability within a program to run text around a graphic image within a document, without the need to adjust each line manually.
Running head
a line of type at the top of a page which repeats a heading.
S/S (Same size)
an instruction to reproduce to the same size as the original.
SRA
a paper size in the series of ISO international paper sizes slightly larger than the A series allowing the printer extra space to bleed.
Saddle stitching
a method of binding where the folded pages are stitched through the spine from the outside, using wire staples.
Usually limited to 64 pages size.
Sans serif
a typeface that has no serifs (small strokes at the end of main stroke of the character); eg Helvetica.
Scale
the means within a program to reduce or enlarge the amount of space an image will occupy.
Some programs maintain the aspect ratio between width and height whilst scaling, thereby avoiding distortion.
Scaling
a means of calculating the amount of enlargement or reduction necessary to accommodate a photograph within the area of a design.
Scamp
a sketch of a design showing the basic concept.
Scanner
a digitizing device using light sensitivity to translate a picture or typed text into a pattern of dots which can be understood and stored by a computer.
To obtain acceptable quality when scanning photographs, at least 64 grey scales are required.
Scraperboard
a board prepared with black indian ink over a china clay surface.
Drawings are produced by scraping away the ink to expose the china clay surface.
Section
a printed sheet folded to make a multiple of pages.
Section mark
a character used at the beginning of a new section.
Also used as a footnote symbol.
Security paper
paper incorporating special features (dyes, watermarks etc) for use on cheques.
Serif
a small cross stroke at the end of the main stroke of the letter.
Set off
the accidental transfer of the printed image from one sheet to the back of another.
Set size
the width of the type body of a given point size.
Set solid
type set without leading (line spacing) between the lines.
Type is often set with extra space; eg 9 point set on 10 point.
Sheet
a single piece of paper.
In poster work refers to the number of Double Crown sets in a full size poster.
Sheet fed
a printing press which prints single sheets of paper, not reels.
Sheetwise
a method of printing a section.
Half the pages from a section are imposed and printed.
The remaining half of the pages are then printed on the other side of the sheet.
Show-through
see opacity.
Side heading
a subheading set flush into the text at the left edge.
Side stabbed or stitched
the folded sections of a book are stabbed through with wire staples at the binding edge, prior to the covers being drawn on.
Sidebar
a vertical bar positioned usually on the right hand side of the screen.
Signature
a letter or figure printed on the first page of each section of a book and used as a guide when collating and binding.
Sixteen sheet
a poster size measuring 120in × 80in (3050mm × 2030mm).
Size
a solution based on starch or casein which is added to the paper to reduce ink absorbency.
Slurring
a smearing of the image, caused by paper slipping during the impression stage.
Small caps
a set of capital letters which are smaller than standard and are equal in size to the lower case letters for that typesize.
Snap-to (guide or rules)
a WYSIWYG program feature for accurately aligning text or graphics.
The effect is exercised by various non-printing guidelines such as column guides, margin guides which automatically places the text or graphics in the correct position flush to the column guide when activated by the mouse.
The feature is optional and can be turned off.
Soft back/cover
a book bound with a paper back cover.
Soft or discretionary hyphen
a specially coded hyphen which is only displayed when formatting of the hyphenated word puts it at the end of a line.
Spell check
a facility contained in certain word processing and page makeup programs to enable a spelling error check to be carried out.
Dictionaries of American origin may not conform to English standards and the option should be available within the program to modify the contents.
Dictionaries usually contain between 60,000–100,000 words.
Spine
the binding edge at the back of a book.
Stat
photostat copy.
Stem
the main vertical stroke making up a type character.
Stet
used in proof correction work to cancel a previous correction.
From the Latin; ‘let it stand’.
Strap
a subheading used above the main headline in a newspaper article.
Strawboard
a thicker board made from straw pulp, used in bookwork and in the making of envelopes and cartons.
Not suitable for printing.
Strike-through
the effect of ink soaking through the printed sheet.
Style sheet
a collection of tags specifying page layout styles, paragraph settings and type specifications which can be set up by the user and saved for use in other documents.
Some page makeup programs, such as Ventura, come with a set of style sheets.
Subscript
the small characters set below the normal letters or figures.
Supercalendered paper
a smooth finished paper with a polished appearance, produced by rolling the paper between calenders.
Examples of this are high gloss and art papers.
Superscript
the small characters set above the normal letters or figures.
Surprint (US)
(see Overprinting) printing over a previously printed area of either text or graphics.
Swash letters
italic characters with extra flourishes used at the beginning of chapters.
Swatch
a colour sample.
Tabloid
a page half the size of a broadsheet.
Tabular setting
text set in columns such as timetables.
Tagged Image File Format (TIFF)
a common format for interchanging digital information.
Tags
the various formats which make up a style sheet- paragraph settings, margins and columns, page layouts, hyphernation and justification, widow and orphan control and automatic section numbering.
Template
a standard layout usually containing basic details of the page dimensions.
Text
the written or printed material which forms the main body of a publication.
Text type
typefaces used for the main text of written material.
Generally no larger than 14 point in size.
Text wrap
see Runaround.
Thermography
a print finishing process producing a raised image imitating die stamping.
The process takes a previously printed image which before the ink is dry is dusted with a resinous powder.
The application of heat causes the ink and powder to fuse and a raised image is formed.
Thin space
the thinnest space normally used to separate words.
Thirty two sheet
a poster size measuring 120in × 160in (3048mm × 4064mm).
Threaded or Chained (US)
see Pipelining.
Thumbnails
the first ideas or sketches of a designer noted down for future reference.
Tied letters
see Ligature.
Tint
the effect of adding white to a solid colour or of screening a solid area.
Tip in
the separate insertion of a single page into a book either during or after binding by pasting one edge.
Tone line process
the process of producing line art from a continuous tone original.
Toolbox
an on screen mouse operated facility that allows the user to choose from a selection of ‘tools’ to create simple geometric shapes—lines, boxes, circles etc. and to add fill patterns.
Transparency
a full colour photographically produced image on transparent film.
Trash can (US)
the icon selected for the deleting of files or objects.
Trim
the cutting of the finished product to the correct size.
Marks are incorporated on the printed sheet to show where the trimming is to be made.
Turnkey
a system designed for a specific user and to work as an integrated unit.
Usually has built-in contractual responsibilities for hardware and software maintenance.
Twin wire
paper which has an identical smooth finish on both sides.
Typeface
the raised surface carrying the image of a type character cast in metal.
Also used to refer to a complete set of characters forming a family in a particular design or style.
Typescript
a typed manuscript.
Typo (US)
an abbreviation for typographical error.
An error in the typeset copy.
Typographer
a specialist in the design of printed matter, and in particular the art of typography.
Typography
the design and planning of printed matter using type.
U
an abbreviation for UPPER and lower case.
Universal Copyright Convention (UCC)
gives protection to authors or originators of text, photographs or illustrations etc, to prevent use without permission or acknowledgment.
The publication should carry the copyright mark, the name of the originator and the year of publication.
Varnishing
a finishing process whereby a transparent varnish is applied over the printed sheet to produce a glossy finish.
Vellum
the treated skin of a calf used as a writing material.
The name is also used to describe a thick creamy book paper.
Ventura Publisher
the desktop publishing package developed by Xerox.
The Ventura approach is a document-oriented one working on the basis that each page will have a similar format.
The package with its design attributes lends itself to the production of manuals and directories
Vertical justification
the ability to adjust the interline spacing (leading) and manipulation of text in fine increments to make columns and pages end at the same point on a page.
Vignette
a small illustration in a book not enclosed in a definite border.
WYSIWYG What-you-see-is-what-you-get (pronounced ‘wizzywig’)
used to describe systems that preview full pages on the screen with text and graphics.
The term can however be a little misleading due to difference in the resolution of the computer screen and that of the page printer.
Watermark
an impression incorporated in the paper making process showing the name of the paper and/or the company logo.
Web
a continuous roll of printing paper used on web-fed presses.
Weight
the degree of boldness or thickness of a letter or font.
Wf
an abbreviation for ‘wrong fount’.
Used when correcting proofs to indicate where a character is in the wrong typeface.
Windows
a software technique that allows a rectangular area of a computer screen to display output from a program.
With a number of programs running at one time, several windows can appear on the screen at one time.
Information can be cut and pasted from one window to another.
The best known version of ‘windows’ is that developed by Microsoft.
Wire
the wire mesh used at the wet end of the paper making process.
The wire determines the textures of the paper.
Wire stitching
see saddle or side stitching.
Woodfree paper
made from chemical pulp only with size added.
Supplied calendered or supercalendered.
Word break
the division of a word at the end of a line.
Word wrap
in word processing, the automatic adjustment of the number of words on a line of text to match the margin settings.
The carriage returns set up by this method are termed ‘soft’, as against‘hard’ carriage returns resulting from the return key being pressed.
Work and tumble
a method of printing where pages are again imposed together.
The sheet is then printed on one side with the sheet being turned or tumbled from front to rear to print the opposite side.
Work and turn
a method of printing where pages are imposed in one forme or assembled on one film.
One side is then printed and the sheet is then turned over and printed from the other edge using the same forme.
The finished sheet is then cut to produce two complete copies.
Wove
a finely textured paper without visible wire marks.
X-height
the height of a letter excluding the ascenders and descenders; eg ‘x’, which is also height of the main body.
Xerography
a photocopying/printing process in which the image is formed using the electrostatic charge principle.
The toner replaces ink and can be dry or liquid.
Once formed, the image is sealed by heat.
Most page printers currently use this method of printing.
imPRESS -
a page description language developed by Imagen and supported by over 60 software products including Crystal, TeX, Superpage and AutoCAD.
Almost certainly the first commercially available PDL.
The concept of icons and pointers (the WIMPS environment) was first developed by Xerox at the Palo Alto Research Centre (PARC).
There is a wind of change blowing through the corporate environment these days, one that has long been predicted but that few expected to actually see.
That change is one of attitude, attitude towards a computer that many MIS managers regarded until recently as ‘a toy’ or ‘that thing with a mouse’.
The Apple Macintosh.
Some five years ago when I first encountered the system on a trip to America I recall being both impressed and disappointed.
Impressed that the system was so easy to use, so much more intuitive than the conventional CP/M and MS-DOS computers that I was then used to, let alone the minis and mainframes.
Disappointed, though, that it had so little capacity, that the machine's power was squandered so liberally on the user interface rather than running the applications.
My feelings have changed over the years as the system acquired first more memory and then bigger and faster processors.
It looks as though the opinion of the corporates has changed too.
The reasons are many and well worth examining.
First there is the almost legendary ease of use.
This is not confined to just making the applications do what they are supposed to but the whole concept of the Macintosh is that anyone can look after it.
All the peripherals plug into obviously labelled sockets, there's no danger of connecting the video cable to the serial port or of confusing the printer interface with the synchronous communications adaptor.
And, unlike the PC system which dominates the industry, all the peripherals work together, there is no clashing of interrupts when you add a scanner or a large screen.
In short, not only does the user have a better time, the support desk gets far fewer calls to come and deal with apparent equipment failures.
Indeed, this benefit has been the over-riding consideration for at least one major corporate in its decision to implement a joint PC and Macintosh strategy.
The next part of the jigsaw is rather more subtle.
Most of the major PC packages; Lotus 1–2–3, Microsoft Word, WordPerfect, PageMaker, dBase, etc, etc, all now have direct Macintosh equivalents that read and write the same file structures.
The major local area network vendors, Novell, 3-Com and TOPS all now provide solutions that run seamlessly across both platforms.
In short, the only technical thing that is different between the two platforms is the fact that they cannot actually run the same programs off the same disk.
And even this is beginning to change with programs like Soft PC and the add-in hardware products that give the Macintosh direct PC compatibility.
So, how are the major corporates implementing this joint strategy?
It would be fair to say that desktop publishing was undoubtedly the beginning of the revolution; the programs are just so much easier to use on the Macintosh than on a PC.
But, in itself, this would never have been enough.
Consider one major multi-national corporate of our acquaintance whose IBM-only purchasing policy was recently changed, if only slightly.
Within three months a conventional in-house print facility was converted onto desktop publishing systems and, because of their particular needs, the lack of time for training and the previous graphics experience of the staff there was only one logical system, the Macintosh.
On the basis that it was to be a ‘one-off’, and following conclusive proof that it could read DCA/RFT files directly off the company network, the syste was allowed.
Of course, it didn't stay as a ‘one-off’ for very long!
There is now quite a clutch of them within the company and the numbers are growing, if not spectacularly then at least steadily.
They will never replace the PCs completely, after all straight text processing is a little too trivial for a Macintosh, but they are starting to appear in other areas dominated by specially adapted, and very expensive PC systems.
Already there is talk of using Macintoshes for packaging design, 35mm slide and OHP production and a host of other graphics oriented functions.
An even more interesting example of the Macintosh's insidious nature, once installed, is given by a large plc whose staff newspaper was produced on Macintosh systems.
Needless to say, the mainstream computing functions of the company are all IBM but, unlike the previous example, there was little evidence of a stable software environment.
People were using any of a large range of software products to perform what appeared to be the same basic tasks.
In one discussion staff described their use of three word processors, two spreadsheets, one database and no less than four graphics packages.
How could all the data be integrated into a single publication?
The answer was to expand the existing Macintosh operation and link it to the PC's, either through a small local area network such as TOPS or via a hard wired link such as MacLink.
Both systems feature a comprehensive set of translation routines that will take virtually any PC format and turn it into a Macintosh one.
The advantage is that, on the Macintosh, there are only three or four real standards; one for text, one for bitmaps, one for object graphics and one for scanned material.
Indeed, with the new Macintosh IIcx and SE/30 systems the need for a hardware link is completely removed as the floppy disk drive will now read and write IBM format disks.
A third example of the way Macintoshes can ‘invade’ IBM territory cam with one company who bought another.
Whilst the one that did the buying was predominantly PC-based the one that was bought used Macintoshes widely.
Most of the systems disappeared during the transition, except for those in the accounting department.
Nothing, it seemed, was going to part those book keepers from their copies of Excel!
Learning a PC package from scratch was not a viable option but they were prepared to change to a Macintosh package that more closely matched the corporate standard.
And there is another one of the reasons that people choose Macintoshes.
It used to be thought that being a ‘power user’ equated to being a ‘PC user’but not a bit of it.
The average Macintosh user can proficiently operate around six packages while the PC user can manage just three, of which one is the dreaded operating system.
Indeed, some people never even seem to master that whereas the Macintosh user hardly even notices the underlying System and Finder.
As for whether the Macintosh will ever oust the PC from the corporate market, well that's another matter.
The current shortage of both the SE/30 and IIcx machines is quoted as being caused by a larger than expected take-up in the corporate market.
And that's in the US.
The supply problems over here are even worse.
Perhaps, while consistently maintaining its unique character, Apple has at last moved the Macintosh sufficiently close to the PC that corporates are now prepared to take the ‘toy’ very seriously indeed.
And, after all, that's the way computers, like any other item of equipment, should be considered.
It's the task that's important, then the tool
Desktop Publishing At The Sharp End
Producing a magazine or newsletter by traditional methods is, simply because of the nature of the beast, a time consuming operation.
Most of the time is consumed by waiting for the various processes of typesetting, page design and layout, proofing and so on to occur.
The production cycle of a monthly magazine I once edited was over five weeks for features, news fared slightly better at two weeks, and these represent the time taken to get the magazine to the printer, not onto the newsagents shelves.
Much has been written about the ‘new technology’ methods currently being introduced throughout the newspaper and magazine industry but few individuals ever come into actual contact with the equipment and working methods they use, we merely read the end results at our breakfast table.
And yet there is now a way in which a small business can introduce ‘new technology’ methods for producing its internal documentation, manuals, price lists, brochures, indeed anything that previously would have been sent to a designer or printshop.
The term used to describe this dramatic change in working methods is Desktop Publishing.
It describes perfectly what the operation entails; you can publish material from a normal office desk.
The new technology element doesn't exactly creep in in this business either; personal computers, laser printers, document scanners and the like are vital elements of the system.
The market is currently dominated by Apple's Macintosh computer and LaserWriter combination but the IBM compatible market is rapidly getting its act together with several new products scheduled for release by the end of the year.
The combination of computer and laser printer effectively replaces the work that would normally be carried out by a typesetter, a proofreader and a layout artist.
To achieve anything like a professional result you still need the services of a designer to create the master pages but this is a once-off requirement for each publication.
Illustrations and line drawings are quite happily handled by the scanner although photographs, half tones to use the correct term, still need to be done by hand.
It is possible to scan them with the existing equipment and incorporate their digitised image directly into the page design but the quality is still rather poor.
Quality, of design and typography rather than editorial matter, is a burning issue as far as desktop publishing is concerned.
The low cost of setting up such a system allows people who have never ventured beyond typewriter or wordprocessor to produce material which looks as though it has been professionally typeset.
I say ‘looks’ because to a trained eye the difference is readily apparent.
This is not to say that the product is inferior, indeed many desktop publishing systems can do things that no typesetting equipment ever could, merely that it has to be recognised that the technology has its place.
We often refer to the output as ‘disposable typesetting’, it's ideal for things with a short shelf life like magazines but not really up to being used for presentation material such as a company report.
One of the great strengths of the Apple system in this respect is that the files produced on a Macintosh can be proofed on a LaserWriter and then run out, with no changes needed, on a true phototypesetter such as the Linotron 101.
This is made possible by the use of a universal description method called a Page Description Language.
Elements of the page are described by their mathematical form instead of as a series of dots, typefaces are stored mathematically rather than as digitised characters.
This allows a large number of variations in style to be incorporated into a single page, something that cannot be achieved with digitised fonts as these, by definition, are of a fixed size and style.
The page description language also allows graphics to be incorporated; rules, tones, line drawings and so on.
It is this incredible flexibility that allows us to juggle page layouts in just a few minutes and produce a fresh piece of artwork each time rather than wait hours, even days, for the re-worked page to come back from the artist's studio.
Once we have achieved the result we want we can then decide whether laser printed output is suitable or use the services of a bureau to get the same file photoset on the higher resolution equipment.
Lasers run at 300 dots per inch, about four times better than a matrix printer.
Photosetters such as the Linotron 101 produce 1270 dots per inch and this is regarded by some as still being insufficient.
Many commercial photosetting systems run at 2000 dots per inch and beyond.
All this technology is fairly meaningless unless we can express its capabilities in comparison with the traditional methods.
In terms of straight production time we have found that we can cut the time taken to assemble 16 pages of editorial from word processed files on a PC-compatible to finished pages on a Macintosh to just one working day.
Indeed late news stories can be added just moments before the final pages go off to the printers.
Yes, we still have to use a printer to produce the newsletter, printing more than a handful form a laser printer simply isn't an economical proposition.
Our newsletter is not the first to be produced using desktop publishing methods, in the UK that honour probably goes to The Wordsmith, a bi-monthly journal for authors and writers.
What is certain, however, is that ours won't be the last either.
With end users now being in a position to fund the hardware, software and production costs for around £10,000 a whole new range of self-published magazines, books and newsletters is bound to emerge.
It is going to be interesting to see how the traditional publishers react.
Dialtext Newspaper system
The seemingly inexorable march of new technology in the newspaper industry has taken on a new complexion over the last couple of weeks.
Manufacturers such as Atex, Magna and Mentor have suddenly found that they have a new British competitor, Talbot Dialtext.
Well, to be fair, the software's British, it runs on Apple's Macintosh computer and uses the newly announced AppleShare network file server software.
Talbot acted as a primary test site for AppleShare and one of their customers, the Poole Advertiser, has actually been using it in anger for about three months.
Even more newsworthy is the fact that Eddy Shah has adopted the system for the Stockport Messenger Group and his recently acquired Guardian Group.
Although the Macintosh may be thought of as a ‘small’ computer, compared with the workstations installed by Atex and the like, it offers an exceptional degree of flexibility and considerable price advantages.
The Poole Advertiser system, admittedly a test site so the costs are not truly representative, has four working locations, two networks and a total of 18 workstations with a price tag to date of some £40,000.
The Messenger Group and Guardian system is much larger with 86 workstations across 14 sites and a price tag of around £250,000.
Compared with the £1M plus that an equivalent Atex system would have cost it certainly seems a bargain.
The obvious question is whether the Dialtext system offers correspondingly less than the other products and, based on what has been seen, the answer must be no.
Certainly the Poole Advertiser are more than happy with the way in which the system has fitted in with their original working methods.
In the beginning Talbot developed a text editor program called Intext to be used on the, then, newly introduced laptop systems such as the Epson HX-20 and PX-4.
In conjunction with this they produced a communications system designed to offload the text onto a host computer with the maximum possible reliability.
The Independent has recently taken delivery of 65 laptops fitted with the software for their journalists to use on the move.
The problems of getting copy onto the system from a remote source was, therefore, already solved.
The main elements of an editorial system were still to be tackled.
Talbot chose the Mac because of its technical benefits, especially the lack of a hostile DOS environment and the fact that a local area network was already built-in.
At this stage there was no multi-user capability, each terminal performed separately although files could be passed.
The transmission of files from one user, say a writer, to another, perhaps an editor, used the common newspaper analogy of baskets and spikes.
Copy posted into a basket could no longer be altered be the sender, only the recipient.
Material placed on the spike can be copied and edited but the original is maintained, the Messenger Group system refers to the spike as ‘carbons’ which is possibly easier to visualise.
The text editing software running on Dialtext is fundamentally the same as Intext but further developed.
The user can select any screen font he or she prefers and can enter copy in almost any fashion.
The system ignores all this formatting completely and, virtually automatically, tides up the copy into a common format once transmitted.
At the editor's workstation, which isn't a particular Mac but the one he happens to be logged onto, formatting codes are applied to the copy to generate the typeset material.
Incidentally, Talbot have coined the acronym ATAT, Any Terminal, Any Task.
These codes are built into the system and control default fonts, typefaces, sizes and column measures.
Simple codes embedded into the text files define the format that the article will adopt when printed; for example, a bold heading set across two columns, with the text in single columns below.
This can be soft previewed at any time to ensure that the output matches with the designers intention.
The software also computes the depth that the article will take, space can be added for photographs if needed, and when everything fits the article is queued for printing.
Both the newspaper groups currently using the software are printing onto page printers and the output is then cut up manually and pasted into position on the page.
However, as the format of the article has been defined before printing this process is very much easier than the traditional methods.
There are also plans for full page planning and, later, makeup to be integrated into the system.
The results are very good, considering that the software is still being developed.
The Poole Advertiser has slightly more advanced software than the Messenger Group but both systems are evolving almost daily.
New features are constantly being asked for and added; fractional leading, better hyphenation routines, faster transmission from remote sites, etc.
The real proof, however, is the fact that both systems are running live producing weekly newspapers.
At the Poole Advertiser the original typewriters were simply removed overnight and the Macintosh network installed.
A case of sink or swim.
The system could not function properly without the presence of a file server on the network and the fact that Talbot were given the go ahead to use the AppleShare software gives some degree of indication how seriously the project was being taken.
The server is actually a piece of software that runs on a Macintosh AppleTalk network and allows multiple users to access common information.
All the clever file and record locking has to be handled by the application, Dialtext in this case, but the product does provide building blocks that allow this to be achieved relatively easily.
Local network security is enforced by user name and password, these not only identify the user but also the level of access to facilities.
The software works with all ‘legal’ Macintosh hard disks and allows a single application, not a user, to operate on the same computer; a print spooler or electronic mail package, for example.
The whole thing is, ideally, completely invisible to the users and only the network supervisor software can modify the various priority levels.
Questions about the products suitability for use with forthcoming Apple products are met with a degree of silence reminiscent of a Trappist monk but the general assurance is that the product is ‘future proof’, at least so far as Apple is concerned.
It also works with the AppleTalk PC card that was announced at the same time.
Software is in short supply here but we know of two electronic mail products that will work across both PC and Macintosh environments.
The implications are interesting, to say the least.
In the Dialtext product virtually the entire Macintosh desktop has been blocked off from the user in order to prevent potential disasters like the erasure of disks or files.
In the beginning this security measure was not enforced but on-site experience changed the approach!
The look and feel of the Mac are preserved, though, with both mouse and keyboard commands for most functions.
If Talbot's Dialtext develops to its logical conclusion with editorial page planning and makeup plus classified and display advertising facilities it will become a very powerful product indeed.
Even at today's stage of development it offers an extremely viable alternative to any of the more well-known newspaper composition systems
The Businessman's Guide to DTP
One of the talking points of the year so far has been the coming of desktop publishing.
Much has been written about the subject in terms of the various packages, both actually available and merely promised, but remarkably little has been conveyed about their actual usefulness for the businessman.
The situation today is very muddled, software is available for both the Apple Macintosh and the IBM PC and its compatibles but even more is just around the corner and it won't be until towards the end of the first quarter of next year that the market will have stabilised.
For anyone seriously looking at the desktop publishing market it is vital that you have a clear understanding of what you want to do with the technology, regardless of the actual hardware or software.
If you are searching for a solution to an undefined need it is more than likely that you'll be seduced by the obvious attractions of graphics oriented programs like PageMaker, Ready Set Go and so on.
If you define your needs first it is much more likely that you'll go for a mix of simple word processing and basic graphics.
The reason is simple, around 80% of all personal computers are used primarily for word processing or related tasks.
The bulk of all business documents are text; solid, wall to wall text.
Certainly there may be the odd chart or graph thrown in for luck but the basic requirement is for high quality text.
Add a page printer like the HP LaserJet, Canon A1 or one of the Ricoh-based products to a good word processing packages such as WordPerfect, Microsoft Word, Wordcraft or the latest incarnation of Samna and you have an instant solution.
No fancy page makeup programs, no page description languages, just plain simple word processing that you already know how to cope with.
With the exception of Samna IV none of the products mentioned will give you any sort of WYSIWYG display on a PC whereas an Apple Macintosh almost always gives a WYSIWYG display, but with a little perseverance it is relatively easy to convert from typescript to pseudo typeset for just the cost of a page printer.
Should you need really good quality typesetting from your page printer that it may pay to look at products like scLaserPLUS, JetSetter, TeX or JustText.
The difference here is that the aesthetic appearance of the output will be vastly superior to that of a word processor.
The software will not be as familiar, nor is it usually as easy to use but the results could well be worth it.
If you need increased quality in terms of output resolution it is vital to look for products that will connect to true typesetting equipment.
Any software that uses a page description language called PostScript will talk to Linotype photosetters, TeX talks to just about anything ever made or you could go for a specialist product such as Itek's PTW which links to their Digitek photosetter.
The desktop publishing market that has been exploited so effectively by Apple in recent months probably represents the top 20% of the market.
Page makeup software such as Ready Set Go, PageMaker, MacPublisher and LetraPage have been used to illustrate the enormous potential of small computer systems to design and create artwork ready for printing.
If your business creates flyers, brochures, catalogues, price lists or anything that involves the combination of text, graphics, illustrations and even photographs into a single document you will need page makeup software.
Compound documents of this type are traditionally assembled by layout artists from the various elements which may have come from a typesetting house, design studio, photographer or elsewhere.
The concept behind page makeup software is that all the elements; text from the word processor, graphics from the drawing package or spreadsheet, illustrations from a scanner, and so on, are electronically combined and manipulated.
The finished artwork is then printed out on a page printer.
Software that uses a page description language is virtually essential, PostScript and DDL are names to look for, and the page printer must understand the same language.
Products like PageMaker and Harvard Publisher are just becoming available on the PC, those currently available include Fleet Street Editor (very limited on features and capability), Front Page and Portfolio.
To operate in the PC environment you may additionally need a windowing environment like GEM or Microsoft Windows, an EGA or Hercules card and matching screen, a mouse and, in some instances, an AT rather than a PC.
The skills needed for this kind of work are almost certainly totally alien to the average businessman.
Services like these would normally be contracted out, the text supplied and the finished design returned for approval.
However, given suitable training simple jobs can be accomplished in remarkably short order indeed and, from there on, just using the system is often training enough.
In all but the most complex of tasks, those that use multiple colours or require photographs, all the artwork can be prepared in-house.
Should the next level of output quality be needed it's just a matter of taking the disk to the nearest bureau service and getting it run out on a typesetter.
A peculiar, almost hybrid, class of desktop publishing application is that of document assembly.
The design and construction of manuals, parts lists, catalogues and so forth is an area that requires more control over the whole document than, say, a word processor but doesn't require the control over every item that a page makeup program provides.
Complete systems such as the various Interleaf implementations, Kodak's KEEPs for example, or Xerox's recently announced Documenter provide a powerful solution to the problems facing companies who have to produce such material.
Software is becoming available on personal computers that, in one way or another, emulates these larger and often more expensive solutions.
Xerox bought the marketing rights to a product called Ventura earlier this year.
As yet not officially launched in the UK it is beginning to make the odd appearance through various channels and is a remarkable product.
Running under Digital Research's GEM environment it provides an almost uncanny level of control over both simple and compound documents.
Also worth looking at, but on the Macintosh this time, is Orange Micro's Ragtime.
A strange mix of word processor, spreadsheet and page design it is unique in many of its capabilities.
Don't expect it to do all the fancy layout stuff that PageMaker can handle but look at it as a tool for creating automatic invoices, business forms, price lists and so on.
The third product I'd put in this category is CLUE, a British program no less.
CLUE is the only data base publishing product that I am aware of which runs on standard PCs.
Its power and capabilities are vast, Blackwells use it to produce their book catalogues which are both complicated and BIG.
If you need to present information held on a data base in typeset form take look at CLUE.
By being able to hand a printer finished artwork the cost of several stages of labour intensive work can be virtually eliminated.
Savings vary from job to job and company to company but, given that the system is installed for the right reasons, it should be possible to recover the hardware and software costs within two years.
In many cases having the equipment in-house allows you to do other things that you might otherwise never have considered so saving even more.
If it is possible to apply rules to a subject such as desktop publishing then there are probably three.
First, make sure you know what you want to do before you go looking for a solution.
Second, buy the solution that most closely fits your current working practices so the minimum disruption occurs.
Third, only consider stable, proven products from sources that can provide training and support.
The last rule may sound rather trite but desktop publishing is unlike any other business use of computers, it's a blend of art, craft, rules of thumb and a whole load of experience most businessmen have never been in a position to acquire.
That apart, it's fun
Article on higher resolution printers (<) for DTP
Mention the term ‘page printer’ to most people and the response is a fairly blank look.
Use the phrase ‘laser printer’ instead and there is comprehension.
Indeed the term laser printer also carries with it two other bits of information; the first is 300dpi resolution and the second is that the output quality isn't really professional.
Perhaps, before the rest of this article gets under way, it might be wise to have a look at some of the myths about page printing technology and see just where it all came from and how it has acquired the reputation it has.
Perhaps the first thing to realise is that not all page printers use laser beams; there are many other successful technologies including LED arrays, LCD shutters, ink-jet, magneto-deposition and ion-deposition.
However, they all share the same concept of imaging the page onto a charged drum.
The charge is then transferred onto a sheet of paper where it then attracts (or repels) particles of finely ground black plastic and so creates the black and white areas of the finished page.
Simply because the first mass-selling device, Hewlett-Packard's LaserJet, used a laser-based imaging system we have grown accustomed to calling them laser printers.
And, again because of the success of that original Canon engine — the LBP-8 CX — which the Hewlett-Packard printer was based on, we assume that 300dpi is the norm.
We seldom, if ever, reflect on why.
There are two reasons why 300dpi became the standard.
First is that the cost of a megabyte of memory fell below the $1,000 mark during 1983 and you need a megabyte to hold the bitmap of an 11″ by 8.5″ page at 300dpi.
The second reason is that  of an inch is the point at which the human eye can no longer distinguish individual dots and, for Japanese typography at least, the division between quality and low-resolution.
It is worth stressing that Japan does not have a history of fine typography like Europe's…
Today, some five years on from the introduction of Canon's first mass-market page printing engine, the world no longer revolves around 300dpi.
Canon themselves already have a 400dpi version of their SX engine, that's the device used in Hewlett-Packard's LaserJet Series II and Apple's second generation machines.
This has appeared already in Genicom's 400dpi ACE printer, the 6142, and NeXT's PostScript printer.
It is also rumoured to be the basis of Apple's new generation printers based on their own outline font system, Royal, that will appear when System 7.0 is released early in 1990.
Other vendors too have printers that run at 400dpi or more.
Agfa have the 406dpi P400 and the slightly less beefy P3400 — both are also available in PostScript forms.
AM Varityper has its 600dpi PostScript printer, the VT600, which is available in both A4 and 11″ by 17″’ formats.
And, last but not least, there is IBM with its rather idiosyncratic 4250 ElectroCompositor which spark erodes either special paper to create positives or an aluminium coating on film for negatives.
These latter pages can be loaded directly onto printing presses as plates.
There are, however, other printers which use modified standard printing engines to increase their output resolution.
The favourite trick, and this has been around for several years now, is to simply double the horizontal scanning frequency so that a 300 by 300 printer becomes a 300 by 600.
For straight text this is generally acceptable but there are inevitable problems with providing special drivers while 300dpi is really too low a starting point anyway.
LaserMaster, one of the few surviving proprietary RIP vendors, played this game with their LX-6 RIP which offered 600 by 300 out of a standard Canon SX engine.
The improvement was significant, italics looked better and there was a general increase in sharpness to larger characters.
However, as the frequency was only doubled in the horizontal axis the benefits were lost if you printed landscape format text!
There were also problems with halftone screens but anyone expecting decent halftones at 300 or even 600dpi is on a loser anyway.
By using the 400dpi engines as their new output device, LaserMaster have now upped the resolution to 1,000 by 400 and the output is significantly better.
Even text out of a tint looks pretty good — it has none of that ‘hairy’ appearance that we have grown used to with 300dpi systems.
There are still blemishes, subtly dished characters show quite visible stepping in the vertical plane but the overall results look excellent.
Another company which has long been ploughing the higher resolution furrow is Printware.
Based in Minnesota they have had little if any real distribution in the UK until Terry Shearer, who did so much at Spandex to get IBM's 4250 accepted by the printing industry, took them on through his new company, PrePress Solutions.
The 720 IQ runs at 1,200 by 600 and is designed as a high throughput production printer.
This ‘plain paper typesetter’— a term already used by AM Varityper to describe their 600dpi VT600 — can handle 20,000 pages per month and runs either under its own drivers or through a PostScript interpreter developed by Printware and using the Bitstream font library.
On specification alone it would seem to be a logical alternative to an imagesetter for any small to medium volume publishing house who were not obsessed with typographic detail — ie the majority…
There is, of course, a catch to all these higher resolution devices — more than one in fact.
The first and most obvious is that they still won't allow you to do decent halftoning — you need a minimum of 800 by 800 to achieve anything like quality results in terms of both grey levels and screen values.
Next is the fact that the more dots you have the longer it's going to take to process them and the more memory you'll need to hold the bitmap.
An 8.5″ by 11″ page at 300dpi needs 1 megabyte of memory, the same page at 400dpi needs nearly 2 megabyte while Printware's 1,200 by 600 needs a massive 8.5 megabytes.
Processing this, especially if it contains greyscale information, is going to need a significant amount of power which probably explains why the Printware device contains two Motorola 68000s.
To put all the above into context, and that's something that no published review is ever likely to achieve, require a detailed understanding of what methods are currently being used to produce documents.
There are many documents that can be happily produced at 300dpi and either photocopied or short-run printed and no-one will ever be aware that they haven't been typeset.
Indeed, figures have been put forward in the US that suggest that maybe 40% of all documents currently typeset could be output in this way.
The next breakpoint is 600dpi — so long as it is a true 600dpi system and not an interpolated one where the dots in the middle are filled in if the ones on either side are present.
Interestingly, as an aside, IBM's 4250 uses a dot pitch of 600dpi but the spots themselves overlap by some 40% so creating a very smooth edge.
The 600dpi printer will provide adequate quality setting for perhaps 60% of all typeset documents — according to the same American report — and many magazines and journals are created in just this way.
An ideal product for 600dpi reproduction is a newspaper as the quality of the paper is such that high definition typesetting is simply wasted and, as Eddy Shah found with the Messenger Group papers, you actually need less printing ink.
For all the above screened halftones should be added at the printing stage if anything like reasonable quality is to be achieved.
The next psychological breakpoint is the 1,000dpi mark which was the point at which digital phototypesetting began to be accepted back in the late 60s and through the 70s.
There's no real numerical significance, it's not even an exact number of megabytes of memory, but it does allow you to achieve a 115 line screen at 60 levels of grey which, according to the greylevel versus screen value chart that we use seems to be a critical point.
It is worth noting that many of the current imagesetting systems also offer a ‘proofing’ resolution of less than 1,000dpi — Linotype's Linotronic 300, for example, offers 635dpi — and it is interesting to speculate just how much material is output at this resolution to keep the throughput speed up.
Virtually any publication other than a fine art title or a typographically critical one could be happily output at 1,000dpi.
The next step is to 1,200dpi — 600dpi has four times the bandwidth of 300dpi, 1,200dpi is four times that of 600dpi — and this is the point at which page printing technology starts to break down.
It is no longer possible to either create a toner particle small enough to stick to a single pixel of charge or to maintain that pixel of charge in isolation long enough for the toner, were it there, to stick.
So, a 1,200dpi by 1,200 page printer is currently unlikely to make it to the market and searchers after increased resolution must turn to other technologies such as optics.
It's worth noting that there's now little real price differential between the top of the page printer market and the bottom of the imagesetting market.
The only disadvantage in moving across is the fact that you need to process the resulting film or bromide photographically — an extra stage which costs both time and money.
The future of page printers is fairly obvious.
Canon have already announced an n by 508dpi engine where the horizontal scan frequency can be set by the OEM and which, even more significantly, can handle pages up to 24″ by 36″ or will take roll-fed paper up to 13′.
This would be ideal for most local newspapers and many others besides.
I also suspect that all the major players will shortly move to 400dpi as their base resolution, it's probably only a question of waiting for the engine manufacturers to get production rolling for the new CCITT Group IV facsimile standard and then taking the excess.
Beyond that I suspect that 1,000dpi will become the breakpoint at which imagesetting based on optical methods takes over with the prices reducing significantly in that market as volumes increase.
Linotype's strong showing with their 200P is a significant indicator of this and there are others ready and waiting, Itek being one.
The only technology which hasn't yet really blossomed in the page printer market is that of the inkjet and it is likely that this will replace the current 300dpi page printers in the not too distant future.
Devices like Hewlett-Packard's DeskJet are becoming very significant in the office market just as the first wave of page printers is due to be pensioned off
Adobe Illustrator 88
Until recently there were only two categories of computer art; bitmap graphics and vector graphics.
The first were created by simply turning display pixels on or off and were, therefore, simple to program and relatively simple to use.
Indeed, it is claimed, many early sales of the Macintosh were clinched by the inclusion of the MacPaint program which proved to the customer how easy the system was to use.
The over-riding disadvantage of these programs, however, is that they are limited by the screen resolution of the system on which they were created.
This was perfectly acceptable when the only output device was a dot matrix printer but with the gradual move to page printing systems and the introduction of desktop publishing packages the limitations became painfully obvious.
Vector graphics, on the other hand, are created by defining the start and end points of a line or curve together with the necessary angle and weight or thickness of the line.
Because these work to a co-ordinate system they are reproducible at any resolution and, more usefully, they can be scaled without destroying the original information.
Bitmaps scale very badly because, like a silk screened tee shirt, if you stretch the image the pattern breaks up while compressing it loses all the detail.
The disadvantage with vector graphics, however, is that they are not tools for the casual artist, more precision instruments and correspondingly more care and effort is required on the part of the user.
Neither of these two methods, both of which are widely implemented on almost every computer architecture, addresses the third artform, technical illustration.
This is the creation of high quality artwork using material that may already exist in a number of forms and modifying it to suit the current need.
Newspaper and magazine graphics are a classic example of this sort of art; stock illustrations are used over and over again, weather maps for example, but each one is slightly modified from the previous.
These drawings could be created by using either of the conventional artwork programs but the amount of effort wasted is significant.
What was needed was an easily modifiable vector format that wasn't restricted to just simple curves and lines.
In 1987 Adobe Systems, creators of the PostScript page description language, introduced a package for the Macintosh called Illustrator which offered many of these facilities.
The history of Illustrator is an unusual one; it was originally not a drawing package at all but a font manipulation tool.
Adobe needed to produce Bezier curve outlines of various fonts for use with their PostScript page description language and Illustrator, in a cruder form, was what they developed and used.
The product allows the artist, and it needs to be stressed that this is not a product for the amateur doodler, to create mathematically correct lines and curves by placing anchor points and stretching lines between them.
The angle or curvature of the lines is controlled by ‘handles’ that can be manipulated at each of the anchor points.
Illustrator was also the first commercial program to avoid the Macintosh's own graphics routines, QuickDraw, and produce its screen image by using PostScript.
(In reality this had already been demonstrated by the JustText composition program but not released.)
This gave a previously unseen level of correspondence between the screen display and the eventual printed result.
It was also the realisation of the fundamental concept behind page description languages, in that they were originally intended to be used for creating displays rather than driving printers, and the beginning of Adobe's attempt to create a standard for graphics systems, now known as Display PostScript.
The beauty of the Illustrator system is its simplicity and the ease with which lines can be modified once drawn, something that the other graphics packages lack.
However, it was not easy to use and required a certain amount of both skill and effort to achieve decent results.
The original version of Illustrator picked up several awards but neither was nor is a mainstream graphics tool in the same way as MacDraw has become.
The recent launch of Illustrator 88 has increased both the product's ease of use and substantially enhanced its performance.
While Illustrator can be used as a straight drawing tool, it is really most at home tracing and improving existing artwork.
This can be either scanned into the Macintosh or it could be an already created MacPaint format drawing.
The artist then laboriously traces the outline of the image placing anchor points and stretching the curves or lines between them.
The results are superb; genuine scalable vector art that can be reproduced at any resolution.
However, there was no facility to simply draw a line and let the computer work out the curves.
The recently introduced Aldus FreeHand package allows this and it should come as no surprise that Illustrator 88 now has a freehand mode too.
This is best controlled with either a tablet and either a stylus or a puck but, given a steady hand, it works pretty well with a mouse.
Once drawn, of course, the line can be modified at will by simply selecting the anchor point you wish to modify and either dragging it or adjusting the handles to alter the curvature of the lines.
What the users, especially the less artistically talented, cried out for was a method of automatically tracing a scanned image.
This has now been provided with the auto trace tool.
Any MacPaint format image, whether existing art or a scanned illustration, can now be traced at the click of a button.
The user has the option of selecting the number of pixels gap that the anchor points will jump across rather than fitting round but, apart from that, the Macintosh looks after it all.
Interestingly, the algorithms are extremely tight and prove Adobe's original point that, while the process could be achieved they were unwilling to incorporate it until they had a solution that worked properly.
Once traced, of course, the image can be manipulated just like any other set of anchor points and curves.
Users of conventional vector drawing programs like MacDraw have often faced the frustrating task of re-drawing all their work in Illustrator and, like me, have probably decided not to bother.
With Illustrator 88, Adobe are supplying a utility called DrawOver which, automatically, converts MacDraw 1.9 or 1.9.5 files saved in PICT format (with a.
PICT extension) into Illustrator 88 format.
Straight lines, regular shapes and curves are accurately mapped as are tones and tints.
Lines drawn with the MacDraw freehand tool are converted so that each vector point becomes an anchor point which can mean that there are rather more points than might be expected, but these are easily tidied up.
The changes covered so far are really simple extensions to the basic Illustrator concept and, indeed, all the files created with them can be saved in Illustrator 1.1 format for use in the original program.
A number of substantial improvements and additions have also been made to the product, mainly in the area of colour.
The most dramatic new facility is the blend tool which is not a kitchen utensil but rather a means of modifying one form or colour into another.
Its most subtle use is as a colour modifier where it can be used to transform one shade into another in a smooth and, apparently, stepless transition.
The image on a colour screen and the output from a colour printer such as the Mitsubishi thermal engine used in both the Tektronix and QMS devices is acceptable but the system really comes into its own when used in conjunction with a high resolution typesetter such as the Linotronic 300.
Blending can also be carried out on shapes where the tool produces the in-between stages.
Once the two basic shapes have been created a single point is selected on each object using the blend tool and the program then creates the required number of ‘in-between’ stages.
A considerable amount of fine tuning is required to find the ‘right’ points on each object so that the transformation is a smooth one but the results are well worth the effort.
Walt Disney may well have appreciated a tool like this for taking the drudgery out of the cartoon business but it has more serious applications in logo design and very effective business graphics; one of the stock Adobe illustrations is a plot of the stock market showing a bull turning into a bear!
The whole business of colour is one that Illustrator 88 addresses in greater detail than any other current package we've seen.
There are several commercial methods for determining colour match but probably the best known is the Pantone Matching System or PMS for short.
Adobe have worked with Pantone to provide over 700 colour shades and combinations that are provided in a reference library on disk.
Obviously this works best if you have a colour monitor but even without one it is possible to produce colour overlays and designate the exact Pantone number for each which the conventional printer can then reproduce.
Custom colours can be created and added to the library by mixing percentages of the three primary printing colours; cyan, magenta and yellow.
Black can be mixed in as well and these, and the PMS colours, can be used both for fills and as line or text.
It is worth noting, a point that Adobe stress heavily, that these colours are created using a very different set of rules to the way printing inks actually created.
Ink, like paint, uses subtractive colour mixing while the video monitor uses the additive colours; red, green and blue, to produce the same effect.
In order to ensure that there is at least a decent degree of match between the colour on the screen and the colour that will eventually be printed, Adobe have built in a compensation system.
After about 20 minutes of use the average colour monitor has warmed up and stabilised and, at this point, Adobe suggest you adjust the colour balance so that it matches a progressive colour bar that you get from your printer.
This shows the three basic primary colours; cyan, magenta and yellow, together with their mixed combinations and can be compared with the colours displayed on the monitor.
The actual monitor controls are never altered, the adjustments are made with the standard colour wheel control of the Macintosh, but the end result should be a pretty close approximation.
It is even possible to adjust the colour of the ‘paper’ on which the drawing is to be made.
Creating the coloured image on the screen is the easy part, printing it is quite another.
An ordinary page printer can, of course, only produce a black and white image which can incorporate a few levels of grey, perhaps up to 16 for a 300dpi PostScript printer.
Printing in colour is a little harder as there are only two colour printers available; the Tektronix model which uses QuickDraw and the QMS ColorScript 100 which uses the same engine but has the PostScript language as well.
With a price of $25,000 there are only so many people who can afford the latter!
Sadly, whilst remarkable in their own right, the output from these printers is only of use as a proof or a one-off print for two simple reasons.
The first is the basic cost of producing the print while the second is rather more technical.
The Mitsubishi G650 thermal transfer engine passes the sheet of paper through its mechanism four times; once for cyan, once for magenta, etc, etc.
The colour is built up by using heat to lay down coloured wax-based dyes onto the paper one at a time.
However, the colour quality is not good enough for a conventional printing system to reproduce, what that needs is colour separations.
These consist of four sheets, one for each of the colours plus black, which contain those parts of the illustration that incorporate the colour or a percentage of it.
If, for example, we were to create a drawing of a No Smoking sign the cigarette would appear on the black sheet while the red circle and bar would appear on both the magenta and yellow sheets because the shade of red we chose requires both.
The cyan sheet would, of course, be blank.
Colour printing is a very precise operation and Illustrator will control the angle and density of the halftone screen required to produce the final image.
The separation process is actually carried out outside Illustrator 88 by a utility program which allows both Pantone and process colours to be extracted from the file.
Each separation is identified as to its colour, screen angle and frequency as well as carrying the colour progressives, registration marks and a star target which is used as a resolution check.
Whilst these can be printed out on a page printer they are only really of any use if they are created on a Linotronic 300 as films rather than as bromide.
This significantly reduces the amount of work that the printer will need to undertake and can lead to some genuine cost savings.
Illustrator can also produce colour traps which are extra rings of colour around an area of colour which is going to be printed over another.
As printing presses are always subject to slight variations this prevents halos of colour showing around an area if the press gets slightly out of alignment.
Overprinting is another option that the program provides.
PostScript normally eliminates whatever lies under another object but, by using the overprint option, it can be forced to leave the background intact so that the topmost colour combines with that underneath to produce a different effect.
This needs to be handled with care because if the separations are printed in the wrong order the effect will be completely different.
An interesting variation on the colour theme is the use of patterns.
Here individual objects may be created and used as the basis of a repeating pattern.
This pattern library can be enlarged as the use of the program develops.
The selected object is surrounded by a rectangle, which forms the background but does not necessarily have a border, and these tiles can then be arranged as required, used as fills or combined with the clipping function.
Patterns can be set to either remain fixed while shapes rotate over them or they can rotate with the shape, the two modes cannot be mixed within an illustration.
Clipping is an inherent part of the PostScript language in that any shape can be used as a window through which the rest of the illustration is viewed.
Interestingly, and extremely non-intuitive, is that the clipping shape has to be at the ‘back’ of the drawing and not in front as might be expected.
Pasting the pattern or other parts of the illustration over the top of the clipping shape causes them to be constrained to the clipping shape.
The final major addition to Illustrator 88 is that it can now incorporate Encapsulated PostScript files within illustrations and, while this has obvious benefits for artists who wish to combine images, it will really start to get some serious use when Letraset's typeface manipulation program, LetraStudio.
There are several other additions to the program which improve the ease of use including a measuring tool which displays the distance between any two points, and an overall upgrade of the measurement system.
All the major transformation tools now have accompanying dialogue boxes that allow the user to specify exactly the numerical value of the transformation; be it shearing, rotating or enlarging.
This, together with the new basic preferences option, allows much more accurate use of the program than was previously possible.
As an aid to training both the new and upgrade user, Adobe have repeated their inclusion of a video which both demonstrates features and provides a basic tutorial.
Unlike the previous version, which featured Adobe's John Warnock, this is a slickly produced affair and, because of its American origins, slightly jarring to the user at times.
However, it is a painless way to get started for the novice and will quickly introduce the user who is already familiar with the earlier version to the new features.
It's a shame that more software companies don't follow Adobe's lead in this area.
Overall, the changes made to Illustrator in order to create the new version are both sensible and beneficial.
An experienced user will find a number of commands have been moved or re-named but there will be little trauma in adjusting.
For those that have been put off by the laborious nature of the program's drawing method the new freehand and auto trace tools offer a quick and easy method of generating high quality artwork from scanned or existing material.
The addition of colour, and specifically the facility to produce separations, is of substantial benefit to the professional graphic artist but, unless he or she already possesses a colour Macintosh II, is likely to be of little real benefit to the average user other than as a ‘feature’ to show off.
Indeed the whole colour market is rapidly moving upwards beyond the reach of the amateur following Adobe's tie-up with Scitex.
All users will be able to enjoy the blend tool, instant transformations from one shape to another will start to invade all sorts of artwork before very long!
It's certainly fun as well as being easy to use and, in the right hands, can produce stunning results that would probably never be attempted by conventional methods.
Its use with colour is equally, if not more spectacular but is likely to see as much use in the hands of the average user.
Perhaps the changes to Illustrator are best summed up by stating that the program has simultaneously made itself more accessible to the average user and significantly more useful to the professional.
As to whether there is any common ground, I have my doubts.
The biggest change that the end user may find, other than the obvious alterations to the program, is that Letraset are now Adobe's primary distributor for Europe following McQueen's decision to move into the manufacturing and acquisition of software rather than its distribution.
It will be interesting to see how the two company's product lines merge; Letraset distribute Ready, Set, Go! 4 and Adobe's offerings as well as their own ImageStudio and the forthcoming LetraStudio and its accompanying display face type.
Illustrator 88 Vs FreeHand
Like the development of the original version of Illustrator from a font creation tool, Aldus's recently introduced FreeHand product was developed by Altsys from a similar background, in this case their Fontographer product.
With the successful launch of Illustrator and its rapid acceptance by the professional market it became obvious that programs of this type were marketable and Aldus took on FreeHand.
Its fundamental differences to the original Illustrator product were that it simplified the user interface both by the introduction of a freehand tool and the classification of anchor points into line, corner and curve types while simultaneously introducing the benefits of colour.
Among the other differences are the ability to quickly and easily lock text to any arbitrary path (and see the result on screen) and the provision for custom PostScript functions to be built into the illustration.
According to Aldus the program has outsold their expectations but these are early days yet.
With the launch of Illustrator 88 certain ‘deficiencies’ are now apparent in FreeHand — strange how the balance changes!
The most obvious is the lack of an auto trace feature and, paradoxically, the freehand tool now looks a little crude compared to its new rival.
However, FreeHand is simpler to use for the amateur or casual artist and this may be all the motivation he or she needs to buy it in preference to Illustrator 88.
Professionals, on the other hand, are more likely to be swayed by the precision and enhanced colour features of Illustrator 88—not to mention the blend tool!
From a purely personal viewpoint, when FreeHand first arrived I took Illustrator off my hard disk, together with a couple of high-powered drawing programs.
FreeHand is still there but it has now been joined by Illustrator 88.
Only several months more use of both products will determine which, if either, remains as a permanent resident.
The InteSoft Range of Integrated Programs
The dictionary definition of integration is ‘the completion of an imperfect thing by the addition of parts’ —a target that many software houses seem determined to achieve by adding more and more features or modules to a central theme.
Today's well known examples of integration include such industry mammoth's as Lotus' 1–2–3, Jazz and Symphony, Ashton Tate's Framework, Microsoft's up and coming Excel together with a host of upstarts like Twin and Integrated 7 from Mosaic.
Almost without exception these packages, if one can still call them that, are based around the spreadsheet and provide overlays to offer additional functions such as word processing, data base and communications.
The first attempt at integration through modules, and one that I rate extremely highly against all comers, is Smart.
This runs from a central core and only the current module is resident in memory, dramatically reducing the amount of memory needed, roughly half that needed by Symphony for example.
Data can still be transferred between the current module and the other segments by using an internal ‘Send’ command.
Open Access, previously a massive single integrated package has recently been stripped into modules along the same lines.
There is another way of achieving the same ends but with your favourite programs as opposed to those from a single publisher, and that involves the use of a ‘manager’ such as Caxton's Memory Shift which lets, say, Wordstar, dBase and Multiplan, all co-exist in RAM.
Data can be passed between these programs but only in a limited way through a copy buffer.
Imagine a suite of software that used the central core concept controlling integrated modules and gave you the ability to run your own software as well.
Just such a product has been introduced into the UK, although it has been around for a while in the US, under the generic name InteSoft.
In theory each of the separate modules; word processor, spreadsheet, planner, data base and so on, will run independently or under the central control of a master module called InteMate.
Written by Schuchardt Software Systems [sounds like a chocolate to me]and handled in the UK by Berenzoid [these names get worse!]and Compucount the theory certainly sounds promising.
Regardless of the worthiness of any concept the actual product will stand or fall by its quality and here InteSoft leaves something to be desired.
Despite being very nicely presented in a slip binder with well printed manuals, shame they didn't follow the ‘industry standard’ for size, the first thing the new user sees is a license agreement that effectively disclaims all responsibility for anything.
Not unusual in this industry but does it really take an entire A4 page to say it?
Having taken the plunge and opened the package I was delighted to find that the software isn't copy protected—no problems running it on my hard disk systems here, or so I thought.
The first problems soon began to emerge.
If you follow the exact instructions in the manual to install the software on a winchester you are likely to be in for a shock.
The InteSoft suite, quite literally, takes control of your machine by replacing any AUTOEXEC file you may have had with its own.
It also creates a whole raft of sub-directories for the various additions you may, or may not, have bought!
Be warned, this could have some unpleasant effects if your system was nearly full before you started.
Quite apart from this, fortunately I examined the BATch file first to see just what it would do, the instructions leave you with a system that doesn't always operate correctly anyway.
It took four hours and a long phone call to find the answer.
To be fair the answer was in the manual but this only highlights the fact that the various packages don't automatically integrate themselves with the InteMate manager.
The InteMate program itself is soon (or so I understand) to be merged with IntePlan as a complete ‘desktop system’, is worthy of comment in itself.
Despite being launched six months or so ago in the US, with almost singular lack of impact, this part of the package has been accepted internally as a program integrator by no less an august institution than IBM itself.
Even more amazingly, it is currently being specified by IBM as part of a large US Air Force contract based around enhanced 3270 PCs.
What, one wonders, has become of TopView if this information is correct!
In the simplest of terms InteMate consists of calculator and notepad utilities, cute but not very usable compared with the likes of Sidekick, and an applications editor.
This utility allows you to perform simple file management tasks such as copying and formatting disks as well as allowing you to create menus which provide access to software other than the InteSoft series.
Setting up these menus is one of the areas that leaves a lot to be desired, it is tedious and likely to be a constant source of hotline support enquiries to InteSoft.
Nevertheless, if you manage to set up a menu you can then run other, non Intesoft, applications under the control of InteMate.
Whilst a high degree of integration is possible within the InteSoft series external integration is rather more limited.
Files must be sent in the format that the next receiving application can understand and to this end a couple of automatic conversion routines are supplied.
Wordstar text files are automatically converted to either carriage return stripped format so the target word processor can re-format for new margins or with hard carriage returns as ASCII files.
Any spreadsheet files sent in DIF format to InteCalc will be converted to its own internal format or if destined for an external program they will be sent as text.
The final automatic conversion is for Lotus 1–2–3 files which are first converted to DIF files by Lotus' own WKSDIF utility and then treated in the same manner as DIF files.
Although the IntePlan program is currently sold as a separate item the promise of its combination with InteMate in the very near future will offer an interesting challenge to programs such as Desq and Menu Ease, not to mention Windows and TopView.
IntePlan is basically a diary/database program and although the sample supplied was a self-running demo it certainly seemed attractive.
Diary entries can be coded in a wide number of ways allowing activities to be carefully tracked and even accounted for through the built-in billing system.
One interesting feature is that entries labelled ‘to-do’ follow the user throughout the calendar until they are checked off.
The data base is a fairly simple cardbox-type which should be perfectly adequate for personnel information, telephone numbers and addresses.
Information, needless to say, can be passed to other programs in the series for further operations such as automatic mailing.
Of the half dozen or so packages available the two sent for test were InteCalc and InteWord; a spreadsheet and word processor respectively.
The spreadsheet uses a three-dimensional technique, up to 256 pages of data with each page being 256 cells by 256 cells.
In operation it reminded me strongly of Supercalc, having no immediate on-screen command line, while in concept is seems not unlike Report Manager with its ability to slice data through a model.
However the lack of any real on-screen help and virtually no graphics capability, the latter is supplied by another module, puts InteCalc about a year behind the times in terms of user friendliness and features.
InteWord, the second of the packages sent for inspection, follows the same overall command structure as InteCalc, essential for modular integration, but suffers from many of the same limitations.
It is a perfectly satisfactory word processor but lacks the sparkle of many of the currently available rivals; Word, WordPerfect, Volkswriter and so on.
One interesting quirk that emerged during installation was that the everything worked fine on the Zenith Z-150 [an excellent IBM clone]yet when the program was installed on a Compaq Plus [also extremely compatible]with the special Compaq driver everything went subtly awry.
Re-installing for an IBM and re-booting cured the problem but perhaps someone in Schuchardt knows something about compatibility nobody else does!
Although the packages tested conform to a common theme there are a number of subtle exceptions.
For example, in InteWord you can list the directory of files available from the Storage sub-menu while you cannot in InteCalc.
Further, when you've inspected the directory you have to remember the name and then re-type it for the Load command.
InteCalc claims that pressing the right arrow key will scroll through the currently available files but this wasn't the case on my sample.
Shortly after trying this out InteCalc crashed fatally anyway so perhaps having Version I.0.0.0 is tempting fate…
Although this is an isolated example it is typical of the problems I encountered and which led me to the conclusion that the product simply isn't ready for release into the market in its current form.
The methods by which Berenzoid intends to sell the product are interesting and may actually get around most of my objections, as they intend installing the packages for their existing bureau customers.
By marketing the software in this way they will, at least, ensure adequate support, having some 30 local offices round the country, and much of the software would be supplied ready tailored for the user.
Pricing is still currently in dollars while Berenzoid and InteSoft conclude negotiations and are as follows.
InteMate $249, IntePlan $195, InteWord $249, InteCalc $295 or $395 with IntePert ($249 on its own).
Any three packages may be bundled together for $595 and corresponding discounts are available for buying even more at one go.
At the end of the day I still have strong reservations about the software, eighteen months ago it would have been fine but exposure to everything from 1–2–3 to Open Access has left me expecting rather more from an integrated package.
In a completely stand-alone environment or where exposure to other products has been limited, its ability to incorporate, and to a great degree integrate, external packages is a big bonus.
Indeed, for the first time computerization of a business it may well represent a better bet than the over-featured products such as Framework and Symphony.
In a professional environment, however, it simply cannot hold its own.
Joysticks
Technological change is something that the personal computer industry is only too familiar with; buy the latest home computer this week and it's likely to be out of date within six months!
In some areas, though, changes are welcome, especially if they lead to a better and more reliable product.
One area of the market that instantly springs to mind, or should it be hand, is that of the humble joystick.
Indeed, since the subject was covered in Issue 3 (p56) a completely new type of joystick has been launched onto the market.
A conventional joystick uses a pair of potentiometers mounted at right angles to each other, the spindles being mechanically linked to a central knob.
The most common alternative system is based around a number of microswitches.
These are set around the edge of a disc which can be tilted in any direction by a central knob.
The pressure makes or breaks the appropriate microswitch contacts.
The potentiometer joystick produces an analogue signal corresponding to the position of the stick and this must be converted into digital form, either by the computer or a suitable interface.
The switch joystick gives a direct digital output corresponding to the direction in which it is moved.
While this system is quicker it doesn't provide the true proportional control of an analogue stick.
The first system to break away from the conventional mechanical systems was blessed with the name of Le Stik.
It consisted of a contoured handgrip fitted with a top-mounted fire button and a side mounted pause control.
There were no moving parts at all, the joystick was simply tipped from the vertical in the direction the user wished to go and, seemingly by magic, the spaceship or whatever was being displayed moved.
The mechanical system of microswitches had been completely replaced by a sealed ‘cup’ filled with mercury.
As the joystick tilts away from the vertical the mercury flows in the chosen direction and makes one or more electrical contacts, just as though a switch had closed.
Tipping the handgrip back to the vertical allows the mercury to flow back into the bottom of the cup, so breaking the contact.
The response of the system has to be experienced to be believed, indeed it is often too sensitive, especially if the game is written for use with the conventional types of joystick.
The newest method of converting hand movements to signals the computer can understand is called Trickstick.
The system used here also has no mechanically moving parts at all, apart from the player's fingers!
Trickstick is based on a novel electrical effect, it uses the human body as an aerial to pick up mains hum.
The joystick itself consists of a sealed tube that is held vertically in both hands.
There are three pairs of pads set into the surface of the tube; one pair set on the top control the forward and backward motion, the second pair mounted on the side at the top control the up and down motion.
The remaining pair of pads, mounted at the bottom of the tube, are used as fire buttons.
The theory is that the mains hum that the human body picks up is transmitted, through these touch pads, to sensitive circuitry.
Here the pulses are converted into signals that provide the directional information, just as with a conventional switch type joys tick.
However, the signals can also be used to show how much you want to go that way, the harder one presses the stronger the signal and the more rapid the output to the computer.
In this way the Trickstick combines the proportional control of the analogue joystick with the fast direct digital control of a switch-based unit.
Because different people will affect the circuits in different ways the Trickstick can be adjusted for sensitivity and it is also possible to use it in a switch-type mode.
The Stack Light Rifle
The standard weapon of an infantryman in the British army, a type of camera and the latest aid to computer games playing may all share the same initials but that's about as far as any similarity between them can be made to stretch.
Although the Stack Light Rifle or SLR combines the looks of a gun with part of the optical system of a camera it can hardly be rated as a precision piece of equipment.
The idea behind this particular add-on is to provide the user with the feel of really being able to shoot back at screen.
The main component of the Light Rifle System is the electronic target pistol which is connected to the computer by a generous length of lead.
At the computer end, depending on the version, there is a connector for the appropriate socket or edge connector.
In the case of the ZX Spectrum version the connector contains two chips and a couple of simple components to interface the main electronics inside the gun to the computer.
To make the pistol more accurate it is supplied with a shoulder stock which clips and secures to the rear of the pistol, a barrel and a make-believe telescopic sight.
The electronics inside the pistol consist of a light detector or photo-diode and a small amplifier and buffer.
Light coming down the barrel is focussed by a small plastic lens onto the photo-diode and the device is sensitive enough to detect the changes in intensity of the picture.
Once the amplifier has boosted the signal it is clipped to provide a digital pulse rather than an analogue waveform and then fed to the computer via the switch.
At the moment the computer receives the pulse from the Light Rifle it compares the value of its scan registers with the screen position of the target and, if a match is found, the player has hit it.
Variants of the Light Rifle are currently available for the ZX Spectrum, Commodore VIC-20 and Commodore 64 and all perform the same function.
Stack provide three games on cassette with the Light Rifle but that's about the limit of the support provided.
While various independent software houses produce games which would appear to be eminently suited to this type of user control very few have actually produced or converted programs to work with it; Micromania are an exception to this.
Possibly even more damaging to the potential of the Light Rifle is the fact that Stack don't provide any driver routines for programmers.
This omission, together with a lack of any technical details on how it actually works combine to make the Light Rifle somewhat less of a genuine alternative to a joystick and more of a gimmick.
The Light Rifle is based around the same theory of operation as a lightpen, it's just much bigger and is designed to be held up to about 10′ from the TV set rather than in contact with the screen.
To help filter out any ambient light the Light Rifle is provided with both a long dark tube, the barrel, and a lens.
These combine to provide a reasonable degree of accuracy, although it's not perfect, and allow the user to ‘shoot-em-up’ from the comfort of an armchair.
The games that are supplied are rather poor examples of what should be possible, both the use of graphics and their actual ‘playability’ are hardly outstanding.
One of the major problems in programming lightpens, or even giant versions such as the Light Rifle, is that the program needs to be very efficiently written.
In all the examples supplied by Stack the game obviously stops when the trigger is pulled.
The reason for this is because the requirements of continuously scanning the screen, as is usually done for a lightpen, would slow the games down too much.
So, when the trigger is pulled on the Light Rifle the software must freeze the action and establish whether the target on the screen is aligned with the position of the gun.
Once the software has determined whether the player has actually hit the target or not the game can continue accordingly.
In thy, once the trigger has been pulled the amount of code necessary to establish the current screen position of the scan should be very small indeed but observing the software in action tends to indicate that this isn't the always case.
On a computer such as the BBC, for which there is as yet no version of the Light Rifle, the provision of a lightpen facility within the video chip would make the task of the software much simpler.
The Commodore 64 also offers a similar system but the ZX Spectrum, on which the Light Rifle was tested, doesn't and the deficiency shows up in the time taken to calculate the position of the rifle when the trigger is pulled.
The Software
Of the three games supplied by Stack to illustrate the potential of its Light Rifle by far the best is High Noon.
Here a random and never-ending stream of gunslingers march across or up the screen.
Your task is simple, shoot them before the shoot you!
The animation is reasonable, the cowboy shooting at you is especially well done, and the action is also smoother than with the other two games.
Stack have also made an attempt at a title page but it's a very poor effort indeed compared with its commercial rivals.
Both Grouse Shoot and Shooting Gallery provide a single target which must be hit before it goes out of bounds.
The grouse turn a nice shade of red and fall from the sky but the halt in the action when the trigger is pulled is very noticeable.
Missing the target brings the penalty of a lowering skyline—the grouse disappear faster.
With both of these the jerky quality of the animation makes it more difficult that it first appears.
Using the Light Rifle about 10′ from a 22″ television set gave a reasonable degree of control over the game.
Somewhat surprisingly the closer the rifle is to the set the harder the games became to play.
Removing the barrel and leaving just the pistol made the Light Rifle easier to handle but reduced the accuracy substantially.
Stack claim that the gun is balanced for colour as well as brightness of the image but all the games seemed to play with the same degree of accuracy even with a blackimage.
Of Mice and Men
Not so very long ago computers were communicated with through large electro-mechanical typewriters called, almost universally, Teletypes.
These unreliable, noisy and cumbersome objects have gradually been replaced by the swift and silent Visual Display Unit.
Waste paper is no longer generated by the ton and almost every home has one in the form of a television set—imagine the popularity of home computers if Teletypes were still used!
However, what both the mechanical terminal and the VDU suffer from is their restriction to a line-by-line, character-by-character format.
The user cannot zoom around the screen selecting items from a menu here, altering data there, changing files and programs without resorting to the keyboard.
Certainly this freedom is obtained when using graphics terminals or playing computer games with their trackballs and joysticks but how can a serious user benefit?
Most of the currently available home computers are equipped with cursor controls; the screen cursor can be moved around a program listing or a text document to the point where changes are needed.
However, the cursor can only move in character-sized steps, the user cannot move it directly to its destination.
If, in some way, the text cursor could be treated like a graphics cursor, which is free to roam under the control of a joystick or trackball, these ideas could be put into practice.
As long ago as the 1960s the possibility of this form of cursor control was being looked at by the Stanford Research Institute in California and the first mouse was patented in 1970.
The name was coined simply because of the physical similarities of size and shape; a mouse is small enough to fit into the palm of the hand and usually has ‘ears’ and a ‘tail’to complete the picture.
The reason that conventional trackballs and joysticks aren't used is because the precise positioning that they provide simply isn't needed.
The mouse works by detecting its motion across any surface in both the up/down and left/right directions.
These movements are directly converted to movements of the screen cursor, or pointer as it is ten called.
The majority of the currently available mice use a mechanical coupling to transfer the movement of the wheels or roller to the sensors but there are other methods.
The two main ways of converting the rotation of the internal rollers to electrical signals are partially conductive wheels and optical discs.
In the first system the rotation of the mouse's wheels or ball bearing are transferred to rollers.
The ends of these rollers are fitted with wheels which have alternate tracks of conducting and non-conducting material.
The pulses received are counted by the driving software and give a direct reading of the cursor's position on the screen.
In the optical system two slotted discs fitted to the end of the rollers.
A light is continuously shone at the discs and the beam is detected on the other side by a photocell.
The pulses of light passing through the slots are converted to electrical signals by the photocell and are treated in just the same way as those of the mechanical system.
One of the most innovative systems is that found in the optical mouse used with the Xerox Star business computer.
This mouse has to be used in conjunction with a special pad that is covered with a pattern of dots.
A light inside the mouse's body illuminates the area of the pad that the mouse is covering and this pattern is detected by a special optical processing chip.
Any movement of the mouse will change the pattern that the chip detects and it can instantly calculate how far it has moved in any direction.
Whilst this system has the advantage that it has no moving parts it is very much more expensive.
Once the cursor has been positioned at the required place on the screen its position can be locked by pressing one of the ‘ears’.
These are just buttons connected to microswitches and the number fitted differs according to the manufacturer.
Some systems use as many as three, Microsoft has chosen to fit two and the Apple Lisa mouse has just one.
The buttons can be used to select items from a menu; programs such as Microsoft's MultiTool Word use this facility along with letting the mouse handle the normal cursor motion.
Alternatively they can be used with more sophisticated software such as that provided on the Apple Lisa.
Here the button is pressed once to select an ‘icon’ from the screen menu and twice to open a file for that particular piece of software.
The main attribute of all the various mice and the software that has been produced around them is that is generally easier to use by those unskilled with a keyboard.
Rather than having to type in the name of a program or press certain letters or numbers to select a function the user simply ‘points’ to what is required and presses a button.
Unfortunately the mouse doesn't eliminate the keyboard completely, the basic information still has to be fed into the computer but what is does do is to make the manipulation of that information much simpler.
Tests conducted by Apple during the development of the Lisa showed that a completely unfamiliar user can grasp the rudiments of the mouse-driven software in as little as 15 minutes.
Similar software running on a conventional system took around 20 hours to become familiar, mainly because of the problems of keyboard interaction and the requirement to learn lengthy and complicated commands.
As more and more computer systems are aimed at the professional sectors who generally have very little keyboard experience the number of mouse-related software packages is bound to increase.
Unlike their warm-blooded cousins they are quiet and clean, they also tend not to scare the faint-hearted as much as the sight of a full QWERTY keyboard!
JustText
Merely the concept of a non-WYSIWYG desktop publishing program on the Macintosh is usually enough to reduce most people to quizzical silence but such a product does, indeed, exist.
JustText, the program in question, is a very high quality tool capable of producing superbly crafted typesetting with a limited amount of page layout.
It isn't a page makeup program, indeed there is very little interaction involved whatsoever, but if you have a requirement for properly typeset material then it may be your only solution.
JustText obeys the normal Macintosh rules of pull-down menus and so on but all the commands to control the way in which the text will be printed have to be typed in as codes like{f9}or{us}.
No indication of what the final result will look like is given as these codes are added, nor is there a preview capability.
However, it must be stated that anyone who has used a code driven word processing program ought to be capable of achieving results fairly quickly.
To make the best use of the program it is necessary to understand what you wish to achieve, and how to achieve it before embarking on the coding.
JustText can read text files from any word processor, it even tidies them up slightly as it does it, and there is a utility to read MacWrite files but within limits.
Once in, and JustText is a perfectly reasonable text editor it its own right, the material can be ‘marked up’ for the various fonts and styles required.
Overall there are some 80 plus codes that control everything from the font required, the justification format, the numbers of columns, kerning, tracking, leading and a host more.
JustText's typographic control is excellent but currently type can only be set in increments of a single point and leading control is similarly limited.
This will be changed in a future revision to allow control to a thousandth of a point.
Kerning and microspacing are implemented and offer this degree of control already.
To make the assumption that JustText was only capable of producing text would be to do it a grave disservice.
It is unique in being able to incorporate MacPaint images and run the text around them, regardless of their shape.
PostScript images can also be read in but these will be boxed to provide a regular shape for the run-round.
Included on the JustText disk is a utility to convert a Thunderscan image into PostScript, so allowing artwork or simple halftones to be incorporated into the page.
If your desktop publishing requirements are based upon the need to produce professional looking typeset material with a limited number of rules od simple illustrations; a book, for example, or a simple newsletter, then JustText offers a solid foundation.
It would be fair to say that JustText is a professional tool which, without an understanding of typography and design, it is impossible to fully exploit.
It would be grossly unfair to suggest that it cannot be used by anyone else, but the degree of achievement attained by such users will be limited
Ask a hundred people what their least favourite part of the Spectrum is and the odds are heavily stacked in favour of the keyboard being pointed out as a prime culprit.
Hardly surprising really considering it feels not dissimilar from a hunk of exceedingly dead meat!
Added to the peculiarities of its india-rubber action are the allied quirks of a non-standard spacing and a fiendishly complicated system of Shifts and Symbol Shifts to access the various keywords and punctuation symbols littered around the keyboard.
While Sinclair's revolutionary keyword and syntax checking system works well for the beginner it tends to stifle the development of keyboard familiarity that occurs on a regular computer keyboard.
Fast typing is simply not possible on the membrane keyboard but whether in spite of or because of this there are several word processing programs available!
Obviously many of the major objections raised here could be alleviated by simply bolting on a full QWERTY keyboard using full-travel keys this is surely not the ideal answer.
Many of the difficulties experienced by users trying to cope with the idiosyncratic Shifting system could be solved through adding extra keys to handle the more commonly occurring characters such as the punctuation, mathematical symbols and Delete.
While taking advantage of this re-organisation of the keyboard an astute designer can also build in switches to control the power and isolate the EAR lead while recording.
Further enhancements could include a case big enough to hold various components of the system like the power supply unit and Microdrive interface or other add-ons.
In judging the six keyboards under test all these possible options have been looked at to see how far the producers have gone to creating the ‘ideal’ replacement.
The final sting in the tail, however, is that adding a decent keyboard to your Spectrum is, while adding to its usefulness, going to raise its price to a level where you'd have got a decent keyboard included in the cost.
LoProfile Keyboard
The description ‘Big, Black but Slim’ could be misconstrued but as dedicated readers of a computer magazine I'm sure you'll realise that I'm talking about the keyboard!
At first sight this looked really nice, a decent set of keys, properly laid out with a numeric pad set to the right.
All the legends are clearly printed on the keytops in the same colours as the original, the only missing one is Break which ought to be on the Space bar but isn't.
The cursor keys are repeated on the numeric keypad which has its own Symbol Shift and ‘.’
as well.
The casing is much wider than it needs to be, I suppose bigger looks better, and although the top is made of a substantial plastic the base isn't and tends to give under pressure.
The keyboard surround is also rather flexible, it had provision for 11 mounting plates but only six were fitted, and this added to the slightly tacky feel.
Internally the keyboard can only accept the ZX Spectrum's main PCB with the various connectors hanging out of the back through slots.
The keyboard was supplied with a photocopy of the advertisement, presumably to give to a friend, and a single sheet showing how to fit it all together.
Using logic it would be easy to fit but they don't mention that you've got to unplug the old keyboard or that the Spectrum's PCB must go in the right way round.
Overall the unit worked very well but the initial feeling that it looked really smart slowly evaporated once it had sat on the desk for an hour or two.
One for those who judge by appearances rather than practical application.
dk'tronics Cased Keyboard
One for the DIY fanatic here!
A really solid black plastic case with a real key copy of the Spectrum's existing keyboard on the left and a 12-key numeric/editing keypad on the right.
Insufficient support is provided for both keyboard and keypad which sag under pressure but the key actions are quite nice.
The DIY element comes in when you find the sheet of self-adhesive stickers to label the blank keytops with! It's cheap, messy and unlikely to last as long as the legends painted on the original rubber ones.
The Spectrum's PCB is screwed onto four plastic pillars using the screws that came out of the Spectrum so don't drop any of them!
The power supply will also fit inside the case but has to be removed from its casing before you can install it.
This means that there is a healthy 240 volts floating just an inch or so away from the Spectrum PCB and the keyboard.
The manual points out that mains can kill and I reckon that it doesn't meet any of the safety standards.
DON'T RISK IT!
If the keyboard was supplied with the keytops engraved or moulded then this would be a very reasonable product.
However, with the sticky label approach and the possibly dangerous method of fitting the power supply—the mains hum will affect the picture quality if nothing else happens—the unit slips into the second rank.
Ricoll Electronics
If you find sheer weight a good judge of a products quality you'll be pleased by this one!
Tipping the scales at just over 3.5lbs this metal cased keyboard seemed to be a solid prospect.
Unfortunately, apart from a full-size Space bar the keyboard is once again a real key copy of the original.
Because there is no numeric keypad added the unit is compact and being built of heavy gauge metal it'll certainly last.
The same cannot be said of the keyboard itself which uses really nasty little keytops and has stick-on legends but at least they have been stuck on for you this time.
Keyboard support is better than many of its rivals and the main board is firmly locked onto four metal studs mounted on the base.
The manual consists of two photocopied sheets plus an extra note slipped in.
This warns that one of the leads to the keyboard must be twisted, and the user should beware of long component leads from the Spectrum's PCB shorting out on the metal base.
This could have been a winner if the quality of the keyboard was up to that of the casing.
As it is it's still a whole lot better than the Spectrum's rubber pads and very reasonable value for money.
The FDS Keyboard
A sleek black plastic casing surrounds this contender and it's really rather pleasant to look at.
The standard set of Spectrum keys have been added to in an intelligent way too.
There's a cluster of cursor keys, a full size Space bar and a Shift key on each side of the keyboard.
Also included are keys labelled Rubout, f1, f2 and Sym which are all in bright red—the rest are grey or black.
The first obvious problem was a complete lack of any instructions!
Inside the case are two sets of possible mountings for the Spectrum's PCB but only one clears the keyboard so that was easy to solve.
Sadly only two of the four posts lined up with corresponding holes on the PCB which makes the mounting very rocky indeed.
The power lead from the transformer has to go to the keyboard first and a short lead from here connects to the PCB.
There appear to be mountings for the transformer but once again I suspect that these are best ignored for safety reasons.
One of the two ribbon cables was damaged, a wire had broken off at the joint between the cable and the plug, and both were rather short making installation harder than it should have been.
Once in operation the extra keys f1 and f2 selected the lower and upper keywords printed on the keytops, a neat idea and one which saves playing octaves across the keys to reach both Shift and Symbol Shift.
The legends are screen-printed on, that's one better than stick-on, but so badly done in some cases that it's a toss up as to which is the worst method!
Overall the Fuller could have been a very decent unit but the quality of finish badly lets it down.
Better keytop printing is a must and the installation of the PCB needs to be made much more secure.
I have serious reservations about the power supply being installed inside the box, it really isn't safe enough.
Transform Keyboard
For £70 you really expect to get something special, or at least you ought to.
While the Ricoll unit was built of really solid metal formed into a proper box this thing is a flimsy as they come.
Covered in sharp angled corners it feels as if the slightest pressure would collapse it.
Being made of metal obviously gave the designers a problem, how to isolate the Spectrum's PCB from the case.
They solved it by getting you to leave the bottom half of the Spectrum case attached to the PCB, hardly the neatest of ways around the problem.
The power supply goes in too, the whole thing in its case, and is stuck down with one of those double sided pads.
They provide you with a power switch and LED but unless you are really competent at soldering I'd leave well alone as the instructions are not very clear.
Added to this is the fact that the case isn't earthed and, once again, you've got mains voltages hanging around waiting to bite you!
The extra keyboard facilities include both Delete and Edit keys and a numeric keypad but once again the Break function isn't labelled.
The flimsiness of the case means that there is very little support for the keyboard which flexes badly.
With the similar sized LoProfile selling at about £20 less I don't think this product justifies its pricing.
Quite how one of the other magazines managed to rate it as the ‘top keyboard at the moment’ is utterly beyond me!
K-Board
Described as a Professional ZX Spectrum Keyboard this has to be the worst thing you could ever do to your Spectrum!
The concept is, perhaps, not so bad.
You are supplied with a PCB fitted with miniature keyswitches, a pile of gold and red lettered keytops, a frame and a substantial quantity of double-sided pads.
What you have to do is rip the old keyboard overlay off the Spectrum, remove the membrane and replace it with the PCB which plugs into the normal connectors.
The old keyboard overlay goes back on top, raised up by a plastic cowling, and you stick the whole lot together with the sticky pads.
All that remains is to snap on the keytops and there you are with a ‘Professional ZX Spectrum Keyboard’.
Whilst I am happy to bolt Spectrum PCBs into metal or plastic cases and generally perform the role of tester I must confess that I balked at performing this simple assembly job.
For starters, I wanted a working Spectrum back at the end…
Someone, somewhere has got to be joking!
Conclusion
Just one of the six keyboards on test came close to meeting the criteria I initially laid down for a replacement keyboard, the Fuller FDS. Even here the poor workmanship left much to be desired.
The best made by far was the Ricoll and given a set of decently engraved keytops this would rate very highly as a direct replacement system and is also quite attractively priced.
Of the rest the LoProfile had most to offer but lacked the extra function keys of the Fuller.
It could also do with more support for its keyboard.
The dk'tronics unit needs to be supplied with the keys engraved or moulded, stick-on labels that the customer has to apply are not really on.
The Transform unit is substantially overpriced and doesn't offer anything over its rivals while being poorly designed and made.
Which leaves us with the amazing K-Board and I've already passed judgement on that!
Now that Sinclair has perfected the newer type of membrane system used on the QL it would be interesting to speculate on which of the add-on companies is going to be the first to offer replacements for this!
By and large the world of commerce has come to terms with word processing, be it a simple electronic typewriter, an Amstrad PCW or a full-blown secretarial system running on dedicated PCs.
Even as the salesmen are expounding the virtues of the paperless office the systems their customers install are doubling the number of printed pages produced by businesses every three years.
Indeed, it has been calculated that by the end of the decade some 3 billion pages of information will be published by businesses worldwide.
The use of the word publish in this context may come as something of a shock but that's exactly what the dissemination of information in printed form is; publishing.
The small businessman may not think of himself as being in the same league as the Maxwells and Murdochs of this world but if he produces leaflets, price lists, brochures or any other form of printed material, he has some degree of affinity with them.
There is one fundamental difference, however, between the material which is produced within a business and that produced for external consumption.
Internal documents tend to be word processed, they look as though they have been typed, whereas brochures and price lists would generally be professionally produced using typeset material.
Producing such material has until recently been the preserve of highly skilled individuals using methods which effectively date back to Caxton and Gutenberg.
The first breakthrough came during the 1960s when the first all-electronic phototypesetting equipment appeared.
Instead of using lumps of lead with the shape of the required letters moulded into their surface or spinning glass disks with the letters etched into them, the world was going digital.
The text to be typeset was displayed as a pattern of dots on a high resolution screen and transferred optically to the photographic paper, digital typesetting was born.
As with all new ideas it met with resistance and considerable doubts were expressed about the quality of such type compared with previous methods.
Needless to say digital phototypesetting is now the accepted standard and the older methods have all but faded away.
The relevance of this little piece of history is considerable, we are effectively going through just such an evolutionary change today.
Small personal computers used in conjunction with page printing systems such as laser printers offer the businessman a chance to do all his production in-house rather than contracting out for typesetting, design and so on.
Many of the programs currently available, and the majority of those being prepared for launch within the next few months, will run on perfectly ordinary business computers, the same systems on which you currently perform word processing or accounting.
Apart from the obvious requirement of a personal computer of some sort the other equipment required depends almost entirely on what sort of work the system will be used for.
If, for example, the idea is simply to produce text files that can then be passed on disk to a typesetting bureau you'll probably need no more equipment than a basic word processing system.
At the other end of the scale is the much vaunted desktop publishing system which requires high resolution graphics; either Extended Graphics or Hercules for a PC system, special software such as Aldus PageMaker or Harvard Publisher, and an intelligent page printer.
The dividing line which separates true desktop publishing from other forms of electronic publishing is the ability to create the basic elements, assemble them electronically and print the final result all from the same system.
There is, however, desktop publishing and desktop publishing!
Unless the both the page printer and the page makeup software support a page description language such as PostScript or DDL the results that can be achieved are limited.
Basic page printers such as the Hewlett Packard LaserJets, the Canon A1 and A2 and most of the Ricoh or Kyocera based models have no internal intelligence.
They are, in effect, extremely fast dot matrix printers.
Certainly the resolution is better, 300 dots per inch, but the method of creating different sizes of type is limited.
Fonts are supplied in cartridges at specific sizes and while custom fonts can be obtained these tend to be expensive.
An intelligent page printer such as Apple's LaserWriter contains its own computer, in this instance the processor is actually more powerful than the Macintosh!
Instead of feeding the printer with a bit by bit image of the screen to reproduce the software uses a page description language to describe, literally in ‘plain English’ what is on the page and where.
The computer inside the printer builds up all the elements in its own memory and prints them.
Fonts are not stored as digitised images but as mathematical representations of the shape of each character.
This allows them to be produced at virtually any size and in a number of different styles as required.
At the moment the desktop publishing market is extremely muddled.
Everything from a simple word processor that can drive a basic page printer to a complete document production system, such as Xerox's Documentor, is being labelled as desktop publishing.
Whilst this may be attractive for the marketing companies it is of very little help to the consumer.
Fortunately there are a number of useful guidelines that can be applied to both the systems on offer and the facilities you need.
There are really three types of published material; text only, text with graphics such as simple charts or tables, and compound documents which include photographs or complex illustrations.
For the first category the two main concerns are that the software will accept input from whatever word processor you are currently using and that the page printer will support your required fonts.
It is advisable, but by no means essential, to have a graphics screen so that some idea of the final format can be achieved.
Many of today's popular word processors; Microsoft Word, WordPerfect, Smart, Wordcraft, Samna IV and others, all support page printers but only Samna IV provides any kind of preview of what the actual printed page will look like.
The WYSIWYG that word processors offer has always been based around monospaced fonts because that is all that the computer and printer have been able to cope with.
In desktop publishing true, proportionally spaced fonts are used and, for the PC market at least, none of the common word processing packages have yet worked out how to handle displaying true fonts on the screen.
Documents containing both text and simple graphics can be created using much the same equipment except that a graphics screen will now be essential in order to see the charts and graphs.
Several of the previously mentioned word processors will quite happily mix simple graphics with text; Lotus 123 charts for example.
One point to keep an eye on here is that the page printer has sufficient memory, a full page graphic at 300 dots per inch needs about 1M of RAM.
Our final category of document is the most interesting but probably only represents around 20% of the market compared with its simpler counterparts.
The production of compound documents requires a different approach, no single program can really be expected to be a word processor, graphics package, illustrator and page makeup in one.
There are currently two methodologies being developed; page makeup and document formatting.
Once the style of document which you wish to publish has been established the second stage of the process is to seek out the suitable hardware and software.
Almost regardless of the use to which the software will be put the very first question that needs to be established is whether the program will accept data from the software you currently use.
If it can achieve this, and many of the packages will accept input from a variety of other programs, a large part of your current investment will be preserved.
That apart the choice of product becomes fairly straightforward.
It is generally sensible to limit the additional capabilities that the new desktop publishing product will give you to the bare minimum.
Learning a simple document formatter may take a couple of days, a full page makeup system may require months of experimentation before the results look professional.
So, if you are in the market for a text only system stick to something that resembles your current word processor while if you already use business graphics you'll find the simpler page makeup programs fairly straightforward.
The word processing market is rapidly coming to terms with desktop publishing, particularly on the PC.
While Macintosh users have always had the luxury of integrated text and graphics with full WYSIWYG display and page printer drivers the PC market has lagged far behind.
Word processors such as Microsoft Word, Samna IV, Wordcraft and WordPerfect can certainly drive page printers but that's just about the limit of their desktop publishing capabilities.
One thing's for sure, the situation will change very soon.
Plain paper typesetting is a term that crops up now and again in conjunction with desktop publishing.
Traditional phototypesetting uses expensive photographic materials so the financial advantages of producing proofs, or even the final result, on plain paper are obvious.
Traditional typesetting equipment costs tens or even hundreds of thousands while a small desktop publishing system based on a page printer may cost less than £10,000.
If the quality isn't high enough for the final product the flexibility gained by using industry standard coding or a page description language such as PostScript means the same file can be passed to a professional typesetting system without the need for re-typing.
Once again the Macintosh has the upper hand with its graphics capability but for much of this market WYSIWYG is irrelevant, the trained operator ‘knows’ what's going to happen to the text when it is run out on the page printer or phototypesetter.
Some of the recently introduced products, Itek's PTW for example, do include full WYSIWYG and are menu rather than command driven but they sacrifice the raw power of products like TeX (pronounced tech) or JustText.
Page makeup software is the flamboyant end of the market.
Indeed it is the ability of the Apple Macintosh to integrate text and graphics so elegantly that has driven the market forward.
Before the Macintosh such capabilities would have cost around £25,000.
Workstation based publishing systems like Interleaf are an industry standard but offer very little more than the Macintosh in terms of actual capabilities.
Although programs like DO-IT existed for the PC before anything appeared for the Macintosh it and its close cousins cost several thousand pounds.
Undoubtedly the product that set the pace was Aldus PageMaker.
Heavily promoted by Apple and unlike anything ever seen before in terms of power for the price it, together with Apple's PostScript-based LaserWriter printer virtually defined the market single handed.
Text could be created on the Macintosh or passed as a file from any other computer, graphics were catered for by MacPaint, Draw or business graphics programs like Microsoft Chart.
Using the Macintosh's mouse-driven user interface to the full it allows complete tyros to become publishers almost overnight.
It doesn't teach you what is right or wrong in terms of style but does allow you to practice and develop ideas with almost consummate ease.
Fast on its heels came MacPublisher and Ready-Set-Go but somehow neither caught on in the same way.
PageMaker shipped 30,000 units in its first year and has now become regarded as the benchmark for today's competitors.
For tomorrow's yet more sophisticated market there are other products in store.
Aldus have a second generation product waiting for December release on both Macintosh and PC systems, MacPublisher has been acquired by the graphics giant Letraset and will re-appear in improved form under the name LetraPage while Ready-Set-Go version 3 looks very impressive indeed.
The first generation of products were relatively unsophisticated in terms of typographical ability.
True hyphenated justification and the ability to adjust spacing between letters was not common.
Tomorrow's products all boast both Hand kerning, terms which reassure the cognoscenti but can deter or confuse the potential customer.
Basically it is good to have them, but you may never need them!
On the PC front, in addition to the new PageMaker, we have a pair of products being marketed by Software Publishing, the pfs: people.
Harvard Professional Publisher, developed by Bestinfo, is a high level product in the PageMaker vein.
Unusually for the PC it doesn't require an environment manager like Windows or Gem which means it can run on a standard hard disk PC system.
Their second product is being sold in the UK as Mirrorsoft's Fleet Street Editor but is actually T/Maker's Clickart.
If you're confused, join the club!
In a totally different vein is Xerox's Ventura Publisher.
Again an acquired product, it was developed by Ventura, it runs under the Gem environment and can function on standard hard disk PCs.
The approach taken by Ventura is substantially different in that instead of making up individual pages the idea is that the whole document is created in one go.
Once the outlines for the pages have been set up using a system of ‘style sheets’ text and graphics are merged in a single operation.
Individual pages can be adjusted at any time to allow for changes and these alterations cause the remainder of the document to be re-structured completely automatically.
Ventura can accept files from a large number of programs so formatted text from, say, WordPerfect will appear just as it was typed.
It is possible to specify the various style elements within the word processor file so making the document generation process almost automatic.
Just as PageMaker provides almost infinite control over each element of each page so Ventura looks after the complete document.
It would be impossible to tell the results apart but the methods used to achieve them are very different.
The biggest single volume of published material is almost certainly directories and catalogues.
In this area there is a surprising lack of desktop publishing software as it is obviously a prime candidate.
One product that is making a name for itself is CLUE.
Developed in this country as an applications generator it has been used to create a data base publishing system of exceptional power.
As well as handling basic text it can incorporate graphics both from other packages and from scanners.
CLUE isn't a page makeup system as such but it can be used to create very impressive documents, Blackwells recently used it to publish their book catalogue.
One unique product is Orange Micro's Ragtime.
Written for the Macintosh by two physicists in Germany it combines a word processor, a spreadsheet and a page creation system in one program.
Whilst being unsophisticated in terms of typography it does allow you to create documents which contain ‘live’ spreadsheets.
Imagine an automatically adjusting price list, just change the discount structure or exchange rate and you get a complete new document.
Automatic invoicing, financial results and common office forms are simple to create and easy to update.
It cannot really be called page makeup but it's probably more useful for the businessman than any page makeup program.
Up till now we have only considered the potential uses of the various desktop publishing products but it is important to look at what can be done with the things that they produce.
Text and graphics produced on a 300 dots per inch page printer is visibly not such good quality as that produced by a typesetting system.
However, for many items it is both perfectly adequate and extremely cost effective.
If the end result is eventually going to be thrown away; memos, reports, flyers, price lists and so on, then page printer output is probably more than adequate.
Display material, advertisements and so on need the extra quality and, if these are the products which you will be producing it is important to ensure that you can move between the systems without having to change the data.
Page description languages like PostScript, Interpress or DDL are key elements to look for when it is important to transfer between various output devices.
Another common misconception about desktop publishing is the ability of the system to produce bulk copies of the documents.
A basic page printer has a rated life; Canon engines are good for 3,000 pages per month, Ricoh's can handle 5,000, and you should expect them to last around three years at the full rated use.
Pages produced by a page printer are, therefore, relatively expensive and running off a thousand copies of a 10 page price list will put a severe dent in the machines life expectancy.
Of course there are bigger and faster page printers but the best approach is to use the output as a master copy and get the bulk printed by traditional methods.
This generally works out cheaper, allows you to incorporate photographs and colour and produces a better result.
At the moment the whole of the desktop publishing market is in a state of almost continual change.
New products are being announced or introduced almost weekly, mainly in the highly competitive page makeup category.
Some will make it to the market, others just fade away into their particular niche.
As yet we have no comparable word processor for the PC to anything available for the Macintosh in terms of true WYSIWYG and mixed text and graphics capabilities.
This situation cannot last for too much longer.
The most obvious future trend is that the vast investment in word processor training is not going to be wasted.
Some 80% of all personal computers are used primarily for word processing activities and there is obvious crossover from this position to the full featured page makeup package.
Word processors are obviously going to incorporate many of the features found in page makeup or document assembly programs; text will simply be passed to a parameter file called, say, REPORT and the document will automatically be set out according to the house style.
True page makeup is only likely to be needed by, at most, 20% of the total market.
To succeed the programs need to be able to accept input from all the common word processors, data bases, graphics packages and so on as well as scanners and document readers.
They will almost certainly be used by specialists while all the basic material is created in much the same way as now, then transferred across to be assembled into the final document.
Steve Jobs recently prophesied that desktop publishing as a separate market would be dead within two years and he's quite probably right.
The skills required to successfully design and make up complex documents are not learnt overnight.
Much better that the simpler jobs be handled by word processors with intelligent formatting systems while leaving the complex work to those trained to handle it.
Tomorrow's desktop publishing systems certainly won't look like today's page makeup software.
DTP and The Dealer
Of all the opportunities that have been placed before dealers during the past year the one which has undoubtedly received most press coverage is desktop publishing.
Has this coverage been hype or does DTP really represent a new application that will continue to develop and expand during coming months?
That there is an application called desktop publishing is certainly not in doubt; when IBM sets up a Business Unit (the last one was to develop the PC) you know that something is going on.
To begin to see how much might be going on it is worth taking a look at some relevant figures.
Worldwide, since its launch some fifteen months ago, PageMaker has shipped in excess of 30,000 units for the Macintosh.
The UK distributor has performed the best of all overseas market, so well in fact that Aldus have set up a UK subsidiary.
For the PC and related MS-DOS hardware Aldus may add a further 100,000 units during the coming year, with its PC version, nice business if only the dealer can get a share.
However, the extent to which products like PageMaker, Ventura, Harvard Professional Publisher or Ready, Set, Go will impact on a dealership's day to day customers is not at all clear.
The overall size of the potential market is even less clear.
Recently published Dataquest figures indicate a potential market size of $300 million by 1990 but with less that a year of history to go on this can hardly be taken as anything more than a guideline.
The current dominance of Apple will certainly be broken, according to Dataquest 60% of the market will be PC based, but interestingly the company is predicted to retain 27%, the largest slice for any single vendor.
Given this apparent potential it is interesting to see how the various manufacturers are coping with the current market expansion.
Apple, who started the whole ball rolling, politely reckon that they may eventually get 30 dealers who can cope with selling, installing and supporting DTP systems.
Hewlett Packard and Apricot, both of whom are going with the Aldus/Microsoft package, are rather more conservative and reckon perhaps 15 to 20 each.
Given that there are currently some 2,400 active dealers (according to the latest Romtec listing) this represents a tiny fraction which the manufacturers judge as being capable.
Apricot are actually sending their prospective dealers on a two day up-front training course just to familiarise them with the market and what it is likely to entail.
If the manufacturers are so pessimistic about the capabilities of their outlets what can dealers do for themselves?
Roughly 80% of the potential market for desktop publishing is based in the office and much of the work can be achieved perfectly happily on PCs running advanced word processors like Microsoft's Word or SSI's WordPerfect.
Given proper training, always a useful sideline for any dealer, these packages can achieve most requirements for office publishing.
The customer doesn't need complicated products like PageMaker or Ventura to produce reports, memos or mailshots.
The need for such products only begins to arise when documents containing mixed text and graphics are considered; newsletters, brochures or catalogues for example.
To break into the desktop publishing market as portrayed by the press, however, requires the investment of a large amount of time familiarising staff with a completely new technology and learning about the markets into which you intend to sell.
Most personal computers are used to run software like word processors, spreadsheets, data bases and so on.
These deal in simple concepts and require no artistic skills to operate and relatively little training or backup.
Desktop publishing, on the other hand, requires artistic skills and a large degree of understanding of the print and production processes if the results are to look at all professional.
Even the terms used to describe the actions of the software are meaningless to many people; kerning, tracking, leading, picas and points being just a few.
The rewards to be had from investing the time and effort are pretty good, however.
Products such as page printers, scanners and optical character readers, high resolution graphics displays and windowing environments are all part and parcel of the desktop publishing scene.
The equipment you'll sell will tend to be of premium quality, the software certainly doesn't come cheap and there's lots of training and backup possibilities.
If, however, this investment of time and effort for training and research into the market is beyond the reach of your dealership, there are, after all, only so many things that can be tackled in a day, it is worth looking at the alternatives.
Desktop publishing, as I explained earlier, does not have to involve high powered layout software.
What many dealers would appreciate is software that can be used by virtually anyone yet produce the same basic results as a complicated program such as PageMaker.
If one analyses the appeal of desktop publishing the basic appeal is its capability to generate material that looks printed, not like something that came off a daisywheel or dot matrix printer.
The ability, in other words, to drive printers such as the HP LaserJet or one of the other ‘laser’ printers.
Few of today's PC based word processors can drive these devices properly and none of them currently produce a genuine WYSIWYG display although a couple are now including a preview capability.
From such apparently humble beginnings a competent operator can produce very professional documents indeed.
Not only does this approach have the benefit of using skills already present, it also starts to build a link between the word processor and the full-blown desktop publishing applications.
Files produced by software such as Word, WordPerfect and Wordstar can all be directly read into desktop publishing software like PageMaker or Ventura without losing any of the formatting.
The upgrade path is simple and can be undertaken whenever the relevant skills have been learned.
Establish yourself as a genuine desktop publishing VAR and the next twelve to 18 months could be very prosperous.
Try to do it on the cheap, however, and you could get lumbered with a lot of high priced product you simply don't know how to shift.
Better, in this case, to stick with lower capability systems based on high performance word processors and concentrate on the upgrade market when you've learnt the ground rules.
Henry Budgett is Editor and Publisher of Desktop Publisher, a specialist newsletter on desktop publishing.
He also runs a desktop publishing consultancy serving both dealer and end user communities
Desktop Publisher certainly wasn't the first newsletter to be produced using computers, many titles are word processed, nor was it the first publication to be desktop published, that honour probably goes to The Wordsmith, but we were the first newsletter to specialise on desktop publishing!
Further, we were almost certainly the first publishing operation set up from scratch to capitalise on the new technology.
We also had a solid background in print, publishing and editorial practices on which to build.
I began my career hand-setting lead type for printing on Adanas and treadle presses before moving first into the world of computers and then journalism while Jim, my co-director, had spent some 34 years with British Airways looking after the production of their timetables from data bases.
He had also been heavily involved in setting up their extensive Prestel operations.
So, we were hardly novices at the print and publishing game, both conventionally and electronically.
Our electronic publishing operation began when we looked at buying Computing Today, a magazine I spent some four years editing, which Argus were closing down.
A detailed look at the books and some simple arithmetic proved that it would be cheaper to launch a new, specialist title than to revive an old one!
Some three months of investigation followed while we selected an appropriate market.
At the time we were also tracking the development of desktop publishing, a newly created use for personal computers.
Using word processors was already standard practice for us and it became rapidly apparent that desktop publishing was the way to go, so far as production systems were concerned.
From there it was only a short step to deciding to publish a title about the technology.
In January 1986 we set up The Desktop Publishing Company and bought a complete Apple Macintosh desktop publishing system.
Sadly, we were too far ahead of the game and, despite the title being ready for a May launch we were forced to hold off because the software was one step behind our hardware!
We launched in June by mailing to 1,000 carefully selected individuals and, with a little help from the Sunday Times and The Guardian, the ball was rolling.
Pre-planning had ensured that, from day one, we had a fully computerised subscription fulfillment system and a means to record information about potential subscribers.
Both have proved invaluable and we now operate a rolling prospect list of some 3,700 names, every one generated by the title and not bought-in.
Because neither of us are designers it was essential to invest, up-front, in some careful design in order to make the production as easy as possible.
Text comes in either from our own word processing systems, on disk from various sources or over the Telecom Gold Email service.
Since the day we installed it, the Macintosh has also been linked to the various PCs we have around the office, a simple enough task but one which has caused considerable wonderment, even among the dealer community.
Comments such as‘You can't do that!’ from Apple dealers have not been unknown!
Because production speed is important but flexibility more so (the system has to be used for other things as well) we adopted Aldus PageMaker as our standard layout package, we run it on both Macintosh and PC systems, and Word Perfect as our word processor.
The two are fully compatible so, for example, bold text appears bold without any extra effort.
After two solid years of operation we wouldn't change the system, at least so far as newsletter production is concerned.
Our foray into book publishing, soon to be repeated, used Ventura and this too is now part of our arsenal.
The fact that we write about desktop publishing means that the world and its grand-mother send us software to evaluate.
Name it and it's probably on the shelf in our offices.
At the last count there were over a dozen packages waiting, patiently, to be called upon.
Strangely, apart from one or two specialist applications, we tend to find that we simply don't need them!
The adoption of a simple format, please don't call it boring, has meant that production is quick and easy.
There are two typefaces; Palatino and Avant Garde, and with everything based on an 11pt leading, we can avoid the single most common failure, column alignment.
Indeed, using the latest version of PageMaker, we can go from a word processor text file to camera ready pages in roughly three minutes per spread and that includes pictures.
Because we use the output from our page printer as camera ready copy rather than going to the expense of typesetting we are unable to use scanners to integrate pictures into the text as we make the pages up.
This is no bad thing as the cost of a decent scanner (around £2,000) would take about five years to get back costed against the amount of halftones we use.
Instead we leave the pictures to be stripped in at the printers, and get a better image as a result.
Colour is also left to the printer although we can, now, automatically produce spot colour separations and, shortly, will be able to handle full process colour although this does need access to a typesetter.
On the rare occasion where we need the additional quality of typesetting the only thing we need to take are the disks.
There are many bureau equipped with Linotron typesetters and the necessary RIP to convert from one format into another.
The cost should average out at about £6 per page, less for longer runs, but you will have to allow for the extra time.
For a newsletter, such as ours, where time is important we feel that the 300dpi output of our page printer is more than adequate.
Half-way houses such as Agfa's 400dpi and AM Varityper's 600dpi printers are available and, certainly with the latter, no normally sighted reader is going to be able to tell the difference.
A year ago desktop publishing was being written off by professional publishers as lacking quality, control and support.
Today we are actively advising many publishers to put aside their prejudices and look again.
Indeed one major publishing chain, having taken our advice, is now in the throes of turning virtually all its titles over to desktop publishing.
There are considerations; the unions being an important one, but fortunately (for us) those are problems that the publisher has to consider.
One thing is certain, regardless of how big or small your publishing operation; desktop publishing is now a technology you cannot afford to ignore.
On one title we recently advised we are looking to save one week a month on the production cycle and, eventually, reduce their annual typesetting budget by £200,000.
In another case we have managed to eliminate the first galley stage completely The first setting is now carried out at the first page proof stage and even this will save around £50,000 per year—more than the cost of the entire system.
If your publishing operation doesn't typeset at all then desktop publishing is going to cost you money rather than save it—at least in the initial stages.
However, the aesthetic quality of your publication will rise and you should save up to 30% on paper and, as a result, something on postage as well.
Whether this is important to you is not for us to say.
We are firm believers in using appropriate technology and if the title is being put together by one person with no experience of word processing, let alone typesetting, there is quite likely to be disaster rather than a success!
If you are using word processors already then half the battle is won.
If there is typesetting involved and it costs more than £8,000 over three years then you have probably completed the equation.
Anywhere in between and you'll need to take a long hard look or call in the professionals.
As any market matures it tends to split into clearly defined areas, mainly as a result of targeted marketing rather than any particularly identifiable product differences.
The electronic publishing market is no exception to this process but does seem to have been affected rather faster than most.
When Online began its Electronic PublishingShow the market was dominated by heavyweight companies delivering documentation systems, typesetting equipment and precious little else for the individual user.
The past four years have seen the introduction of CD-ROM technology, desktop publishing and, this year, desktop presentation and office publishing.
Underlying the whole market is, of course, the desire to reduce the amount of manual intervention required for the production of printed or published material.
Whilst the typewriter is still the dominant method of putting words onto paper the ubiquitous word processor marches inexorably onward and by the time this decade ends the majority of published material will at least be electronically created.
Once the information is captured in one format it is almost inevitable that it will be the wrong one for a typesetter or publishing company and a whole industry exists to convert both disk and software formats.
Companies like Intermedia and Altertext exist solely to serve this market and are ever adding to the range of formats that they can handle.
Once the basic information is captured in electronic form there is technically no limit to what can be achieved with it.
The reality, however, is that there are other considerations such as quality, quantity and intended use which have to be taken into account.
The simplest form of electronic publishing is word processing with a typographic style of output; office publishing, if you will.
In the considered opinion of many experts this poor relation of the industry will probably take 80% of the market by volume.
The reasons for its expected dominance are simple.
To begin with the user needs little if any re-training and certainly no real deign or layout skill while the software is a simple upgrade from existing word processing with the ability to dive page printers and incorporate simple graphics.
Next up the quality ladder is desktop publishing of which much has been written over the past two years.
EPhas seen its fair share of new product launches and 1988 is unlikely to be an exception with new versions of Aldus PageMaker, Ragtime and Letraset's Ready, Set, Go!
Companion technologies such as page description languages and page printers have been developing apace but the real strides seem to be being made in the scanner market with both better grey scale capability and higher resolutions.
Agfa will be showing a pair of new devices while Xerox will have its new 1,200dpi ProImager device.
At last it is becoming possible to include production quality scanned images in desktop publishing.
An interesting offshoot from desktop publishing is the rapidly growing desktop presentation market.
In Europe we lag far behind the US in the use of both prepared OHP materials and 35mm slides.
This is mainly due to the cost of preparing quality materials, bureau typically charge £20 for a fairly simple text-only slide and so users tend to stick with hand lettered foils or the flip-chart.
The introduction of software such as Harvard Graphics, Cricket Presents…and Aldus' FreeHand has allowed users to put together excellent quality presentation material on their own computer systems and merely use the bureau for the output stage.
In many cases the OHP foils can be printed on an ordinary page printer and there are now many low-cost imaging systems that allow slides to be produced in the office, should the demand make it economical.
Desktop publishing is also making its mark on the professional publishing industry with products like Quark XPress, PageMaker, Ventura and, for more specialised users, Talbot's Dialtext system.
Two years ago the professionals poured scorn on the low-cost packages but now many of the restrictions have been overcome and newspapers, magazines and books are all being created with these and other packages.
Traditional typesetter like Linotype, Compugraphic and Monotype have moved to accommodate output from the low-cost software, generally by accepting PostScript instructions as an input, while the professional packages from companies such as Magna, GB Techniques among others now pay more than passing attention to facilities like soft preview and laser proofing.
The WYSIWYG approach of desktop publishing certainly isn't everyone's cup of tea, most typesetting is still code driven, but for composition systems it has changed the way we work beyond all recognition.
Publishing information as part of everyday business activity and publishing for profit are only two of the three mainstream publishing activities.
The third, publishing on demand, is often called Corporate Publishing (CEPS for short) and is the hardest area to define.
Covering everything from the production of technical documentation to printing individual insurance policies.
Based on workstations rather than personal computers and invariably networked with either high volume page printers or typesetters for back-end output, companies such as Xerox, Xyvision, DEC and Context are pre-eminent.
This is a world where document management and revision tracking are probably more important than the finer points of typography, the ability to pull information out of the corporate data base more vital than a range of typefaces and sizes.
Only one event pulls together all the strands that go to make up the complete electronic publishing market, Electronic Publishing1988.
The conference will cover the leading edge of the technology as well as providing user feedback while the exhibition will allow both current and potential users a unique chance to see the market leaders under one roof
Ever since the beginning of the ‘desktop publishing revolution’ there have been two, quite separate schools of thought about the way in which such packages should operate.
The first group firmly believes that any document can be broken down into a series of discrete specifications which can then be used to automate the production process be embedding encapsulated versions, often called tags, within the source material.
Once these tags reach the publishing package they assume the correct typeface, size, style and other typographic characteristics.
In some cases these tags will control the page layout as well; the number of columns, the size of the margins and so on .
A typical example of such a package would be Xerox's Ventura.
The other school believes that the traditional skills of the paste-up artist should be retained rather than sacrificed on the altar of automation.
They have, after all, several centuries of established methodology behind them as virtually all the documents created up until very recently indeed were all hand assembled.
Where the system falls down, of course, is when someone changes their mind about the typeface that's going to be used or the number of columns per page.
With an automatic system a few simple alterations to the style sheet and it's all done for you.
With the manual systems such as PageMaker, the leading exponent of this method, it is, quite literally, back to the drawing board.
During the first two years of desktop publishing much argument has raged about which is the better system.
Ventura has been criticised for taking away the exquisite and interactive control while PageMaker has been similarly slated for its tedious approach to standard formats and layouts.
Both products have gone through minor cosmetic revisions; PageMaker migrated onto the PC from the Macintosh at in it's third release while Ventura tidied up numerous loose ends with version 1.1.
Nothing particularly dramatic, just good, sensible enhancement.
All that has changed, or so Aldus would have us believe, with the launch of Version 3.0 of PageMaker.
Available now on the Macintosh with a PC version due by early June, it represents a major upgrade from previous releases and attempts to satisfy many of the demands made by its users — Aldus claim an installed base of around 150,000 worldwide.
Because much of the product is already familiar to readers this review will concentrate, so far as is possible, on the upgrades and the reasons behind them rather than the existing features.
It is worth noting that although the product is only just released commercially I have been using an ‘engineering’ version on the PC for some two months while the actual review tests were done on a genuine US release version.
The differences between the US and UK versions are subtle.
Obviously the spelling of words such as color has been corrected, both on-screen and in the manual, but other changes such as default paper sizes and hyphenation dictionaries have also been modified.
Aldus Europe has spent nearly a year, and a not inconsiderable amount of money, setting up a multilingual production facility to create all the European language editions of their products.
This has reduced the lag between the US and the UK to around a month with the stated goal of eliminating it completely by the end of the year for both English and the primary European languages.
(Note: it was something of a surprise, given the above, to find that the first batch of UK product still had the American manuals…)
The new release of PageMaker has addressed itself to four main areas in which users felt the product was lacking; long documents, repetitive formats, graphics and colour, as well as adding additional features such as text export and enhanced file import facilities.
The relative worth of each of these is dependent upon both the user's aspirations and the sort of document that he or she is going to produce.
A classic example of wasted power is found in Ventura's ability to generate an index automatically.
A classic power feature, often touted by its supporters, that will be used by a mere handful of people.
Where Aldus have had to be careful is in avoiding building-in power features which would, for the average user, totally unbalance the product.
Probably the single most raised criticism of PageMaker in its earlier versions was that it did not automatically flow text from column to column or page to page.
Aldus's standard reply was that no paste-up artist did it automatically but, with Version 3.0, they have succumbed to the demands and Autoflow is an option when text files are being imported.
Interestingly, this and all the additional ‘power features’ of 3.0 must be selected by the user, they are not default options when you install the package.
This, by the way, is the first Macintosh package we have met where it has to be installed by a loader program.
The reason is simple, the program is now bigger than 800K and won't fit on a single disk!
There is also a bug in the installation routine for the UK version.
At the point where the program is trying to set up the tutorial files it reports that it is unable to find ‘Festina Text’ and skips the entire operation.
The rest of the install proceeds but the tutorial files must then be copied across manually.
How anyone can have failed to miss this is utterly beyond me but, apparently, they did.
Once the Autoflow option is invoked, the text is poured onto the page and flows from column to column until the page is full.
At this point a new blank page is generated according to the layout defined on the corresponding master page and the text then flows into that, and so on.
The text flow can be interrupted at any time by clicking the mouse or the flow method can be altered to semi-automatic or back to manual by clicking in conjunction with the Command or Shift keys.
Semi-automatic completes the current column and then pauses with the text icon still on the screen while manual completes the column and stops.
The speed of flow is impressive, far faster than any human could achieve either with traditional methods or using earlier versions of PageMaker and so the feature is a genuinely worthwhile addition to the product.
The fact that direct competitors such as Ready, Set, Go! and XPress already had it is now of historical rather than current interest.
The second area in which Aldus have improved the handling of long documents is in the implementation of style sheets.
These are created in conjunction with a skeleton layout for whatever document you wish to produce and consist of a number of tags.
For example, the Heading tag might be defined as Times Roman 24pt on 26pt Bold Centred Unjustified.
Additional items such as colour, indentation and tabs can also be attached to the tag.
A collection of these tags makes up a style sheet and, together with the skeleton document, are saved as a template.
There are two way of using the tagging system.
The simplest, but least efficient, is to load raw ASCII text into the template and then go through the document highlighting the text areas and applying the tag.
While this is fine for short items it misses out the real benefits of stylesheets.
To make best use of them, the tag names are embedded into the text file which is then placed into the template.
Now the tags automatically adopt the defined styles.
There are two points worth noting; the default setting is not to read tags, something that the user needs to remember, and, so far, it seems that you cannot mix tags within a paragraph.
The stylesheet system used by Microsoft Word is fully supported by PageMaker 3.0, within the limits of both programs, so fully styled word processor files can be imported and will reproduce accordingly.
Once the tagged text has been placed it is possible to alter the tag's definition in the stylesheet and have all the occurrences of that tag change.
There are, however, limits to the amount that can be achieved.
There is no implementation of a line, column or page breaking tag so there is almost inevitably some additional manual positioning to be done.
Now is there any capability to add simple graphic elements such as a reversal block, a box or even a rule automatically to elements of text.
Whilst Ventura's tags support all these features and more, those provided with Version 3.0 of PageMaker are simpler and, as a direct result, likely to get more use.
From a practical point of view, the introduction of tags saved half a day on the production of a 24 page newsletter compared to using the previous version of PageMaker.
One incidental problem often faced with PageMaker is that most of the final editing gets done ‘on the page’.
This means that the original word processor text file gets behind in the alterations.
Macintosh PageMaker supported text export from Version 2.0 but this has now been added to the PC version for 3.0 (although this feature crashes our engineering version).
The output formats supported by the standard Version 3.0 package are Microsoft Word, WriteNow and ASCII on the Macintosh, Word 4.0, DCA and ASCII on the PC.
In the case of Word on both systems the export includes such portions of the stylesheet as are supported by the word processor.
Additional support for PC-based packages is provided by the Macintosh version; WordPerfect, Wordstar, XyWrite and DCA while both versions support a system of installable filters for both import and export.
As well as co-operating with software houses, Aldus will be introducing a range of filters itself together with a programmers kit that allows special versions to be generated by the user—given that he or she can write programs in C.
Aldus have added extra support for non-PostScript printers such as those which offer PCL support.
As well as a soft-font installer utility, PageMaker 3.0 for the PC now comes with the basic Bitstream font library as standard.
This consists of the font compiler, Fontware, and three outlines; Dutch, Swiss and Courier.
The first two are better known as Times and Helvetica…
The outlines are scaled to produce bitmapped fonts at the required sizes, Fontware produces type at up to 128 point, together with matched screen fonts.
The fonts are claimed to exactly match the standard Adobe ones which means that proofing could be done on a low-cost PCL printer with typeset output produced on a Linotronic.
This trick will only work if the spacing values for the fonts, the metrics, match exactly which, in Bitstream's case, they seem to.
The third area in which major improvements have been made to PageMaker is that of its ability to handle graphics.
Whilst running text round graphics has always been possible, although labour intensive, Version 3.0 provides one of the neatest systems yet implemented on any package.
When a graphics element is placed on a page there is now an option to set text wraparound.
As with all the new enhancements this is not the default, it must be selected.
Several options exist; the text can jump over the graphic, flow round it as a regular shape or, under user control, flow around irregular objects.
The latter is obviously the interesting one and it uses a very different method to competitive programs.
When a graphic is places it has eight handles positioned at the corners and centres of each side for re-sizing and general manipulation.
If regular flow has been selected the user has the option of setting the amount of stand-off between the graphic and the text.
This puts a second frame round the graphics, spaced away from the handles by the desired amount.
The clever part is that this frame can be manipulated to make it into an irregular shape as required to match the text to the graphic.
Additional handles can be added to the second frame simply by clicking on it with the mouse and these are then dragged to re-shape the boundary.
For a complicated shape this may take a few minutes but it is much more controlled than some of the automatic methods.
As a user tip, it is worth doing this manipulation off the page otherwise the text is continually trying to re-format itself.
Further improvements in graphics handling include the ability to manipulate both TIFF and paint images after they have been placed in a publication.
Whilst the facilities are simple, it's certainly not trying to compete with Letraset's ImageStudio, they are enough to get you out of a hole.
The basic controls offered are the ability to adjust the lightness and contrast levels, add either a dot or line screen and adjust the screen angle.
Whilst the output from a LaserWriter or similar PostScript page printer is barely acceptable the image control facility is extremely useful if you are going to a Linotronic typesetter for final output.
The main addition for graphics in PageMaker 3.0, though, is in the area of colour support.
Just as a stylesheet is set up for text so it is possible to create a basic colour palette using either the HLS (Hue, Lightness, Saturation), CMYB (Cyan, Magenta, Yellow, Black) or RGB (Red, Blue, Green) models.
Once the required colour has been mixed it is then stored in the palette for use at any time.
Any area of text, a graphic, lines or areas of tint can then be coloured.
Obviously, the best visualisation will be achieved with a colour monitor but one is not essential.
The bonus of working this way is that, when the document is printed, colour separations are automatically created which can be used to make printing plates.
On a 300dpi page printer spot colour separations, ie solid colour, is possible but to get the best results for full colour work then a typesetter is required.
Colour proofing can be done on either the QMS ColorScript PostScript printer or the HP PaintJet which is supported by the PC version through Windows.
While these major upgrades to PageMaker, there are numerous smaller changes which make it easier to use.
There are also, sadly, some which are not so beneficial.
On the PC version, which now runs under Windows 2.03 or Windows 386, there have been some changes to the keyboard shortcuts that, for anyone used to the previous version, are extremely strange.
On the positive side, we now have two extra zoom sizes for page display; 400% and clipboard, the latter allows you to find all those things that you hid on the clipboard and forgot about.
Also provided, and not before time, are independent horizontal and vertical rules which means that keeping track of the number of lines of copy on a page is extremely easy, you simply set the vertical ruler scale to be the same as the leading.
Whilst these are small adjustments, Aldus have changed their tack on two other fronts as well.
Previously, ie pre-Version 3.0, there were two sets of pre-defined pages or templates sold under the Portfolio banner.
Version 3.0 comes with 19 templates as standard which is a very nice touch.
These are in addition to the normal tutorial files supplied and it is in the area of training that the second change has been made.
Last year Aldus released a training system called PageMaker Classroom which consisted of a video, doctored working version of PageMaker, course material and a load of other goodies for £550.
This year's offering is called PageMaker college and comprises an extended version of the video, a 10-site-licensed copy of PageMaker (doctored, of course), all the training materials, workbooks etc for just £175.
This is cheap enough for a user to want to buy one rather than go on a commercial training course.
Overall, PageMaker 3.0 is a substantial improvement on it's previous versions and, unlike many upgrades, it has kept firmly to its original concepts.
None of the new features take away control from the user or make it harder or more complex to use, a strategy which some other vendors would do well to emulate.
Indeed, when first turned on, the current user might wonder where the additional features actually were, so closely have Aldus stuck to the previous version's user interface.
The only real grumbles are that the tagging system doesn't go far enough, a column and page breaking tag is essential, and that the keyboard shortcuts for the PC version seem to have been changed from the earlier version.
Of course there are things that we would have liked to have seen such as multi-chapter documents and greater typeface and leading control but then there wouldn't have been anything to put in Version 4.0, would there!
Box-out: Ventura versus PageMaker
Many claims have been made by observers of the desktop publishing market that PageMaker 3.0 was going to be Aldus's answer to Ventura.
In the event, the Ventura users are probably wondering what all the fuss is about.
On the most trivial of levels it could be claimed that Version 3.0 had caught up with Ventura because it supported stylesheets and graphics wraparound.
Certainly, both products now have these features but that doesn't make them necessarily any more similar.
Ventura is, and will probably always be, document oriented.
That means that it knows about things like sections and chapters, tables of contents, indexes and anchored text and graphics.
Features like embedded lines and boxes within tags, section and chapter numbering and constant update of source text files are absolute requirements for such a product.
What this means, of course, is that the user gives up a certain amount of control over the layout and the actual construction of the document.
For simple, repetitive styles such as memos, proposals, price lists and books this is a small price to pay given that productivity is improved.
It also demands that someone is skilled enough to set up the stylesheets in the first place unless you want to stick with the standard set provided by Xerox.
PageMaker, on the other hand, is still page oriented.
That's not to say that it cannot create long documents, far from it, just that equal emphasis is given to each page by the program.
The user is still firmly in control of what goes where at every stage of the document's creation and the program has lost none of that intuitive feel.
The changes that have been made simply automate the paste-up process to a greater degree, even the stylesheet/tagging system is unobtrusive and operates exactly the way that a traditional art studio would expect.
Anyone who has had any experience at all of dealing with typeset material or the creation of pages should still find PageMaker the more logical choice, whatever the document.
Those that need the automated processing of Ventura still need it, over and above any of the new facilities incorporated in PageMaker Version 3.0.
The upgrade hasn't changed the relative positioning of the two products at all, merely expanded the range of documents for which users might consider PageMaker suitable.
Certainly my use of PageMaker will now increase, although at the expense of products such as Ready, Set, Go! rather than Ventura.
Shortly after the introduction of Illustrator 88, Adobe produced a volume of professional clip art called ‘Collector's Edition I’.
This extremely useful two-disk set comprised border patterns, symbols and, perhaps most useful of all, two complete generic fonts that could be manipulated.
Indeed, there have been many occasions when the pcak has been a virtual life-saver in providing component parts for logotypes and so on.
As with many successful products there was always the possibility of a sequel and Collector's Edition II duly appeared earlier this year.
Subtitled ‘Patterns and Textures’, it somehow lacks the immediate impact of its predecessor in that whilst its contents are produced to an equal if not higher standard, the nine disks contain a stunning range of patterns and textures, they are really only of use to the professional illustrator.
Further, unlike the earlier Edition, these will only work if you have Illustrator 88—not the older Illustrator, nor FreeHand, just Illustrator 88.
If your profession involves architecture, cartography or professional illustration in either the technical or science field then this will be £165 very well spent indeed.
Even for a commercial artist, many of the patterns and textures will provide the basis for shading and tonal work or even complete illustrations.
However, if you are merely a dabbler in the drawings game then having access to the full US Geological Survey topographic patterns, architectural and other standards may well be of little significance.
The fact that the collection takes up some 8M of disk space may also be regarded as something of a stumbling block…
Using the patterns is relatively simple, provided you already have Illustrator 88.
Once the required pattern library is opened then any shape may be painted with the pattern—just as with any other pre-defined colour or pattern.
The real power comes in the fact that these patterns can be manipulated and customised as required.
All the originals are locked to prevent accident but the elements can be ungrouped and manipulated to create new designs or, given a colour system, you can try adjusting the colours of the elements and backgrounds — often ending up with an entirely new feel.
As is normal with Adobe products the manual is complete and well produced.
It also seems to provide a rather better description of how to create and modify patterns that the original Illustrator 88 manual—or perhaps that's just because the subject is being tackled in context rather than as an academic exercise.
Overall, a must for the professional who already uses Illustrator 88 but of merely passing interest for the rest of us.
Personally, I hope that the next Edition returns to the rather more universally useful format of the first.
Macintosh and PC in Harmony
The amount of dis-information about the compatibility between PCs and Macintoshes is really quite staggering, on the face of it you would think that they were unable to speak at all.
Reality, as is often the case, turns out to be quite a different story with multiple packages being equally well supported on both sides of the hardware fence.
So far as the desktop publisher is concerned there are many packages that can share data without any form of translation being required as well as a few that need some gentle tweaking.
There are, of course, cases where the user has to resort to good old ASCII, the lingua franca of all computer systems but even here there are tricks that can be employed to make the process a little easier.
Let's begin by looking at how to connect the Macintosh and the PC together in the first place.
The simplest, and cheapest, method is to get hold of a couple of free (public domain), cheap (shareware) or full price communications packages and a bit of wire to hook the two systems together with.
On the Macintosh Plus, the system we use, there's a strange mini-DIN connector but this is easily changed to a conventional 9-pin connector with an adapter lead.
At the other end of the lead you'll need either a 25-pin or a 9-pin connector depending on your make and model of PC (or any other computer, come to that) to attach to the serial port.
The tricky bit is the connections between them, Figure 1 gives the correct information for those who want to tackle the actual soldering, but those of a faint-hearted disposition can always buy a ready-made lead.
Once connected, the art of serial communications can be made easier by selecting decent software.
There are two main types; those that just communicate and those that are capable of translating the data formats at the same time.
In the first category the leading product is, in our opinion, Vicom.
This is available in Macintosh, PC and Atari formats, the latter pair running under the GEM environment.
Regardless of the system the program runs on, it presents a standard user interface of icons and drop-down menus which makes it very simple to use.
Once the communications parameters have been set up the whole process is very simple and, so far as is possible, completely error-free.
The only drawback is that the files must either have a common format, in which case you can use the X-modem transfer method, or be in ASCII.
Really sophisticated users may like to invest in the ultimate communications link between the two systems, a local area network.
Effectively this means using AppleTalk with one of the proprietary PC interface cards and then running either TOPS or, for a full-blown system, AppleShare.
In either case files can be pulled off the PC or Macintosh simply by selecting them from the user interface.
Whilst this is a fast and relatively painless process, the files will require handling in exactly the same way as if they had been transferred across a simple serial link.
The second type of communications package are those which both transfer and, where appropriate, translate as they do so.
It's quite magical to watch a Wordstar text file being converted directly into MacWrite without any interference from the user.
Without doubt our favourite package in this category has to be MacLink or its upgraded version, MacLink Plus.
For the past two years it has allowed our PCs and Macintoshes to share data in a wide range of formats without any hassle at all.
Possibly its most endearing feature is that all the control is executed from the Macintosh, the PC can be connected locally or over a telephone line with modems and, apart from being started up, needs no attention.
MacLink also has a role to play in the translation of information once it has been transferred by other communications systems; simple serial links, modem or Email based file transfer or the third main method for getting files between Macintoshes and PCs, disk exchange.
While the Macintosh and the PC have mutually exclusive disk formats, even the new 3.5″ PC disks are totally incompatible, there are a number of products which allow PC disks to be read or written from a Macintosh.
The most obvious of these is Apple's PC 5.25″ drive, a standard 360K disk that connects to a card mounted internally on the SE or Macintosh II.
The other, and more flexible, option is the DaynaFile.
This connects to the SCSI port on a Macintosh Plus, SE or II and can be fitted with up to two drives.
These can be either 3.5″ or 5.25″ and in any of the four storage densities; 720K, 1.44M (for the 3.5″) and 360K or 1.2M (for the 5.25″).
In an environment where the data can be coming from ATs, PCs or portables the DaynaFile is obviously going to be the better solution and it has the added benefit of being portable between systems which is not true for the Apple unit.
Apple's drive does, however, come with Apple File Exchange.
This is a conversion routine that turns PC data into Macintosh format, or vice versa.
Unlike MacLink, it can be user programmed for peculiar data formats which can be useful for connecting to systems like the Amstrad PCW.
This software is available separately and could, therefore, be used with any of the file transfer systems.
In the majority of cases, the user will not want to mess about converting data from one format to another.
It delays the process and, no matter how good the system, is always prone to quirks.
The better way to approach the situation is to ensure that the application software on both the PC and the Macintosh produce compatible files.
In the word processor world there are only two immediate options; Microsoft Word and WordPerfect Corporation's WordPerfect.
The former is a stable product and file transfers work perfectly so long as the user isn't too feature hungry.
As a general rule, it's better to leave all the heavy formatting to the page makeup system.
WordPerfect, on the other hand, is still in beta format on the Macintosh and although the version we tested worked fine with its PC counterpart, there was no page makeup system on the Macintosh that understood its formats.
PageMaker is supposed to have this capability in Version 3.0, due to be released at the end of April.
There are two remaining options.
The first is to strip out all the formatting on the source system and, if possible, replace them with generic codes;[B]for bold on,[b]for bold off, etc.
The resulting ASCII file can then be transferred over any of the links, Email included, and re-formatted at the target system.
This process takes time but does ensure that everything gets across.
An alternative, where the PC is the source, is to use one of the proprietary conversion routines to change the file into either Word or WordPerfect format before sending it to the Macintosh.
In the reverse direction a similar process is required, except that here the Macintosh architecture looks after most of the conversion for you; Word reads MacWrite files automatically, for example.
Life for the graphics user, is not so simple.
Whilst many of the PC-based packages can accept MacPaint files, the reverse connection is rarely possible.
The only exceptions are TIFF files and EPS files.
The first are generated by scanners and need careful handling, the accompanying bitmap for display purposes may not reproduce properly although the image will print correctly—this is caused by the difference in screen resolutions between the two systems.
The closest match between the two systems is when the PC is running Hercules monochrome graphics and, certainly with Illustrator, the screen does display the correct image.
Encapsulated PostScript files (EPS) are also readily portable between the two systems although, at the moment, the traffic is pretty much one-way, Macintosh to PC, unless you are saving PC PageMaker files in EPS format.
Because EPS files are stored with an accompanying bitmap they must be transferred in binary format and, owing to the screen problems, may only appear as a grey rectangle on the PC.
Once again, they do print correctly.
At the top of the tree are the page makeup programs themselves.
The only common product is PageMaker and, from version 2.0a on the Macintosh and 1.0a on the PC, these will exchange files quite happily.
There are restrictions and caveats, though.
TIFF files must be transferred separately and Macintosh PICT (object) or large bitmap files may fail also.
It is also worth checking the text itself as the change of display may have forced some unexpected re-composition.
This is not generally a problem but, as with all uncertainties, hits home on the occasions that you forget to check!
The best advice is to transfer page formats between the system and re-lay the text and graphics when they get there.
That way you'll have no surprises.
On a parallel track, the business world is well catered for with several compatible products on the two systems.
Lotus 1–2–3, the current business standard for spreadsheets, has a counterpart in Jazz on the Macintosh while Microsoft's Excel is available on both systems.
Files in either WKS or SLK format can be transferred between the systems with ease and, in the case of the Macintosh, products like Cricket Graph can be used to enhance the graphing capabilities of the packages.
Indeed, it is often worth transferring PC data into the Macintosh simply to gain access to these facilities.
For the data base user, however, life is less rosy.
The common language here is ‘ASCII, comma-delimited’ which simply means that the data fields in each record have commas stuck between them and are sent out as a long line of text with a carriage return indicating the end of the record.
For safety's sake it is always best to also enclose the fields in quotation marks as this gets round the problem of commas both in text fields and as thousands separators in numbers.
While the Macintosh and PC both have a number of data base programs in common; Ashton Tate's dBASE and Blyth Omnis/Crystal being the best supported, the software houses don't seem to have kept the products quite as similar as they might have done.
Data is easily transferred but, sometimes, the underlying data base structure needs a little tweaking in order to function at its best.
It is perhaps unfair but definitely wise to say that even direct counterparts on Macintosh and PC do not necessarily transfer all their formats from one system to another.
If there is a choice to be made it must be to stick to identical vendor's product on both systems and to follow their recommendations with regard to data transfer.
However, readers can take some comfort from the fact that for 18 months we have produced every word of a 16 page newsletter on a PC in WordPerfect, yet done all the page makeup on a Macintosh.
Communications can certainly solve most of the problems of apparently incompatible systems, given a little effort.
Macintosh versus IBM for the desktop publisher
One of the stranger points about desktop publishing is that the hardware you select to act as the basis of your system is, to a greater or lesser degree, irrelevant.
If this statement seems a little bizarre then consider the following argument.
The majority of potential users of desktop publishing systems have a definite idea of what they want to do with the system; publish a newsletter, produce catalogues, spruce up company reports, etc.
The documents that they want to produce will, therefore, determine the software that they will select; most people, for example, would choose Ventura if they are after long, regularly structured documents as opposed to PageMaker with the reverse being true for free-form material.
The choice of package, in turn, will determine what hardware platform is going to be most appropriate.
While this argument holds true in an ideal world users are often subject to other considerations such as previously installed hardware, purchasing restrictions and a million and one other trivia of which that perennial bugbear ‘compatibility’ is possibly the most emotive.
The two machines most affected by this issue are the PC and Macintosh so it seems appropriate to examine the pros and cons in some detail.
It may also be appropriate to explain that we have been using both systems, side by side, for over two years with files being transferred between them throughout that time.
So unusual was this setup that during its early days we even had dealers contacting us to discover how it was being done!
The most obvious difference between the PC and the Macintosh is the architecture.
The PC and its descendants are designed around the Intel 8088/86/286 family of processors and use a bus system to provide additional facilities such as graphics.
The Macintosh, on the other hand, uses the Motorola 68000 and was designed as a closed architecture.
The fundamental difference between them is that the PC was designed as a text and number processing system and, despite upgrades, this is still the case while the Macintosh was designed to handle graphics in exactly the same way as text.
While the PC's strategy means that the user can mix and match additional items like displays, mice and printers it has the immediate disadvantage of requiring many separate manufacturers to maintain the compatibility.
The results have, sometimes, been less than spectacular.
The problem is compounded further by the fact that software houses are unable to predict what precise configuration is going to be present and so they are forced to provide numerous drivers for peripherals such as displays and printers.
Apple's Macintosh, on the other hand, was designed to be a closed system with a rigidly defined hardware and software core that all developers could take advantage of.
This took the form of a central set of routines which looked after all the I/O functions, graphics and peripherals and was intended to remove any need for users to add extra items.
In terms of packaging this meant that the Macintosh came complete with no requirement to bolt cards into the box or work out how to drive unfamiliar peripherals.
This closed architecture does have its drawbacks as it becomes hard, if not impossible, to expand the system outside the manufacturer's original specification.
Setting aside the physical hardware, in terms of power a Macintosh performs roughly the same as a PC/AT, there are other fundamental differences between the two systems.
The first and most obvious is the way in which they work.
The PC is blessed, or cursed, with the MS-DOS operating system where commands have to be entered at the keyboard to perform any of even the most basic functions.
While command line interpreters do have a certain fascination and instill a tremendous discipline on the user they could hardly be described as state of the art.
The Macintosh changed that approach by following the experimental work carried out by Xerox which indicated that pictorial or icon-based user interfaces were easier to learn and use.
The use of a mouse with its linked screen pointer to select programs, copy disks and carry out any of a thousand functions is now part and parcel of everyday computer life.
And, because all this capability was part of the Macintosh operating system it was available to any software developer so almost every package that appears for the system works the same way.
It wasn't long before the PC world started to follow this example and graphical environments began to appear; GEM and Windows being the dominant pair.
However, in the PC world, these need extra processing power that would otherwise be available for the application and only really come into their own with the PC/AT or even the ‘386 models.
Despite Apple's success with the interface concept it doesn't look as though PC's will come as standard with similar facilities until OS/2's Presentation Manager finally appears — probably early next year.
Because of its graphical interface the Macintosh has always had a superb display system, an effect heightened by the use of a small (9″) monitor.
While this is more than adequate for word processing and so on it does tend to be restrictive when considering A4 or even A3 pages.
One of the main reasons that the display looks so good is that it has been configured to use typographic faces as opposed to conventional typewriter-like text and this advantage has been further heightened by using typographic measurements throughout, each dot on the screen corresponds to 1 point.
In the world of the PC, on the other hand, there are now no less than six official display standards; MDA, CGA, EGA, PGA, VGA and Hercules plus a host of derivatives.
None uses a typographic foundation which makes displaying high quality text something of a problem.
This is further compounded by the belief that large screens will solve all problems—they don't.
The bigger the display the larger the amount of memory required for graphics but, paradoxically, the smaller text will appear if the software hasn't been designed to cope.
Anyone doubting this should look at the size of the GEM menus on a 19″ monitor!
As has been pointed out already, the use of a standard interface means that packages will all work in the same basic way.
Take, for example, a desktop publishing package and a spreadsheet for the Macintosh.
Quite apart from the fact that they are bound to be different something approaching 60% of the basic functions will be identical; loading, saving, printing, editing, type selection, etc.
This simply isn't found in the PC world where packages are often unique and uniformity is not always maintained within a single company's product line.
As an indication of just how easy it can be to start using a Macintosh from scratch we have recently installed a network system running PageMaker, MacWrite and MacDraw on a previously PC-only site.
Quite apart from the fact that the hardware was working within one hour of delivery we found that the basic functions of each of the packages had been picked up in less than a day.
On a PC system at the same site we would expect to provide a minimum of one day's training for a basic word processing package…
So, if we accept that the Macintosh and the PC were designed differently, work differently and treat the user differently which is going to be the best—at least so far as desktop publishing is concerned?
In the case where there are no computers installed and the user is coming at the problem with no previous experience there is really only one answer.
Macintosh.
Quite apart from all the points outlined above there is one over-riding benefit and that is the compatibility of information.
The vast majority of Macintosh programs obey the rules and, therefore, allow information to be passed between them.
Word processor packages can accept drawings, bitmaps, spreadsheet data and so on.
Similarly, desktop publishing packages can take text from a whole range of word processors, graphics packages and other sources.
In the PC market such data portability is rare and even operating under Windows or GEM doesn't solve all the problems.
If there are already computers installed then the answer is not quite so easy.
While the Macintosh still possess all the benefits it seems, to a casual observer, to be an incompatible system.
Up until the introduction of the Macintosh SE and II systems there was little getting away from the fact that the two systems were fundamentally incompatible.
Most PC software didn't have a Macintosh counterpart and even if it did users had to work the magic of the asynchronous communications link to get data back and forth.
Some enlightened products did allow a fairly easy route to this, MacLink being a case in point, but life wasn't simple.
With the SE and II came a greater respect for the Macintosh as an alternate system—partially spurred on by Apple's own PC drive which can read and write IBM format disks, partially by a new wave of software.
Life is now easier than before; PageMaker files, for example, can be transferred between systems while many PC packages understand file formats from the Macintosh, Illustrator EPS format being one.
If the environment in which you work is predominantly PCs which are used for word processing then there is little if any problem in using Macintoshs as desktop publishing systems.
Data can be collected over the AppleTalk network (arguably the best local area network for small groups of PCs) or through one or other of the 5.25″ disk interfaces.
Many Macintosh packages now have direct PC counterparts, or vice versa, with prominent examples being Microsoft Word and Excel, WordPerfect, dBase and Lotus 1 2 3.
Introduction of the new machines with a more relaxed attitude toward third party hardware has meant that adding large screens in no longer a problem although the prices are still higher than a corresponding PC-based device.
Indeed, it is the area of pricing which may settle the question of which to buy.
Apple's new LaserWriter II NT is the best value for money yet launched (if you can get one) while both SE and II costs have fallen since their introduction.
Macintosh software is also generally cheaper than its PC counterpart; both Word and WordPerfect are over £400 for the PC yet less than £300 for the Macintosh.
Sadly, the Macintosh is still slightly more expensive than an equivalent PC system—especially when it has to be made PC compatible by adding AppleTalk or extras like the PC disk drive.
Against this must be set the benefit of working with a consistent software interface, having better compatibility of data between programs and a simpler user interface.
In the final analysis it has to be said that the Macintosh is a better system for desktop publishing than the PC on both technical and user grounds.
Yet many people don't actually want desktop publishing in the Macintosh sense, they want better quality word processors which can integrate text and graphics.
Once again, Macintosh wins.
Even in the realms of technical and long document publishing the Macintosh is catching up with PC-based systems; Interleaf Publisher usually needs a PC/RT or a Sun workstation yet it runs just fine on a Macintosh II.
Perhaps the only reasons for buying a PC publishing system as opposed to a Macintosh one are for Ventura, which has no Macintosh equivalent (yet) or because your company will only buy PCs.
If you are in the latter category, we can only sympathise.
Plotters
The ability to create printed copies of diagrams that appear on a computer screen is an essential requirement of many serious users.
Engineers, scientists, technical artists and businessmen all need accurate diagrams and charts that conventional printers are just not capable of producing.
The only device that can create these images is a plotter and, until recently, these have been prohibitively expensive for the home computer user.
In the main the need for a plotter is governed by the type of output being generated by the computer.
An engineer or draughtsman will need accurate drawings of equipment and installations, a businessman might want charts and graphs showing sales figures.
Producing these on conventional printers is a very laborious process and the results will only be in black and white.
The only other low-cost option is to take a colour photograph of the screen and whilst this might suffice for business charts it certainly won't be accurate enough for a designer or architect.
Plotters work in an entirely different way to printers, they draw lines between two points rather than creating their output from pre-formed characters or patterns of dots.
The basic principle behind all the various systems is that of the x, y co-ordinate.
Just as a graph can be plotted by defining the co-ordinates through which the line must pass so any shape can be broken down into a series of co-ordinates.
To be able to join these co-ordinates together in order to recreate the shape there must be some form of movement and so the pen is fixed to a travelling gantry that can move in the × axis (left and right) while the pen moves along the gantry in the y axis (up and down).
The traditional type of plotter is known as a ‘flat bed’ plotter because the paper is fixed to a flat plate with the gantry travelling over the top but the disadvantage is that the plotter must be at least as big as the piece of paper.
The mechanism that captured the attention of the micro industry when it first appeared in the Sharp CE-150 printer was the four pen printer/plotter.
Its bigger brothers, Tandy's CGP-115 and the Oric MCP-40, have helped bring colour plotting to the home computer user.
Like all good ideas the system is amazingly simple in concept.
A roll of paper is pulled through the mechanism by a spiked roller.
The paper is moved both backwards and forwards in very precise steps while a pen carrier holding four miniature ballpoint pens moves across the surface from left to right and vice versa.
To create the output, which can be text or graphical, the pen carrier is rotated until the correct colour is in position and then the pen is pressed against the paper.
Horizontal lines are created by the pen moving while the paper is stationary, vertical lines use the movement of the paper with the pen fixed in place.
Combinations of the two movements produce diagonals and curves.
The quality of the printing is very high although the restricted paper width makes it unsuitable for wordprocessing and other serious uses.
One method of reducing the size is to adopt a large-scale version of the four-pen plotter idea where the paper moves in one axis and the pen moves in the other.
Examples of this are the Strobe 100 and the Hewlett Packard Sweetlips plotters.
The movement of the paper must be as precisely controlled as the motion of the gantry in the flat bed type and this is achieved by using a stepper motor.
A stepper motor is a very special type of motor that only rotates by a fraction of a turn for each pulse of power that is applied.
Mainly found in disk drives, where they control the positioning of the head on the surface of the disk, they are ideally suited to moving pens in precise steps across the bed of a plotter.
Connecting a plotter to a computer is generally just the same as connecting a printer, at least in terms of the interface.
Plotters are generally available with either serial (RS232) or parallel (Centronics or IEEE 488) interface which can be connected to the port normally used by a printer.
The programming is often a little more complicated in that instead of just sending the results of a program to be printed information about the way the results are to be presented must be sent.
This is generally done in much the same way as a diagram would be built up on the screen.
Because of the complicated way in which plotters build up their output they are usually ‘intelligent’.
All this means is that they have built-in microprocessors which convert the characters and instructions sent from the computer into a series of co-ordinates which the plotter then draws.
Many of the more sophisticated plotters also allow complicated shapes such as circles and curves to be drawn by simply supplying the starting points—the plotter does the rest.
The labelling of graphs and diagrams and the colouring-in of pie charts and bar graphs are often automatic processes, making the programming much simpler.
Many plotters come complete with software that allows them to be used directly from within a program, rather like a paper copy of the screen.
If this type of program is not provided the user will have to work out how to necessary routines to translate screen information into the appropriate codes to drive the plotter.
Some plotters don't feature built-in character sets so even the codes for the letters and numbers will have to be created but at least this does allow customised characters to be designed and used.
Once a shape has been generated, however, it can be plotted at any position and in any orientation or size so a library of shapes can be built up for repeated use.
Routines to plot circles and curves and shade in sections of graphs are often very useful, especially in the field of business graphics and these may also have to be created.
However, the principles of creating a drawing from co-ordinates on the screen are just the same as those required to create the shape on paper so the programming is usually simple enough.
PageMaker User Group
The PageMaker User Group (now universally known as PMUG) was established in the spring of 1989 as a result of a direct request from Aldus to a group of independent users to see if it would be possible to establish such an organisation.
For reasons which are none to clear there had been little, if any, pressure on Aldus from the existing users to form such a group and it was felt that a need was emerging for a secondary level of support for the program.
From the beginning it was decided that the Group should be entirely independent of Aldus.
Following a mailing by Aldus to all registered users of the product an initial public meeting was held in London where over 100 potential members braved the pouring rain to confirm their support for the User Group.
A Committee was elected and the basic aims of the Group laid down.
The underlying objective of the PMUG is to encourage the free flow of information between users so that everyone could get the best out of PageMaker.
Membership is open to any user of PageMaker and costs –30 per year.
Benefits from membership currently include six issues of a newsletter per year, six public meetings per year, a technical hotline service and a computerised register that allows members with specific problems to be matched with similarly equipped individuals who may be able to help with specific issues.
At the first public meeting, held in June 1989, the members were able to meet Paul Brainerd, the founder of Aldus and the man who coined the phrase ‘Desktop Publishing’.
Much lively discussion took place about the future development of the product, so highlighting another vital role that the Group has to play in providing feedback to Aldus in order that the product can be developed in accordance with the needs of the users.
The Group is also planning an annual conference and exhibition of related hardware and software and also intends to establish a full electronic bulletin board service allowing on-line problem solving.
Further planned activities include regular design seminars which will be marketed both within the group and externally to other PageMaker users and member-only weekend tutorials.
The PMUG is making its presence known to users of the program through number of channels.
Each copy of the program carries a READ.ME file that includes information about how to contact the group, many of our committee members are actively involved in writing articles for the computer press and we also regularly take stand space at major events such as the EP Show and the Desktop Publishing exhibition.
The six meetings, the bi-monthly newsletter and access to the technical database will be free of charge to all registered members.
A telephone hotline service will also be available that will put you in touch with other members who have the same set up as yourself so that you can discuss any problems you have encountered.
In this way it may be possible to resolve difficulties more easily.
The PageMaker User Group is committed to increasing the overall level of knowledge about the program so that its use will be improved.
Members can, therefore, get the maximum benefit from their use of the program by having direct access to this pool of information and expertise.
Presentation Graphics Hardware
Desktop publishing is dead, or so the marketing men would have us all believe.
This year, and presumably next, we have a new treat in store, Desktop Presentations.
Perhaps what's even more remarkable about this supposedly ‘new’ market is that it isn't new at all!
There have been presentation graphics programs around for several years now in the PC marketplace; programs such as Harvard Graphics, Lotus Freelance, Daverelle, Genigraphics and 35mm Express, all merrily turning out graphs, charts and text for use as presentation aids.
What has boosted the market in recent months, however, is a vast influx of software in the Macintosh marketplace backed up by a considerable marketing campaign by Apple in alliance with some of the biggest names in the business like Kodak, 3M and Tektronix.
Apple, following its success in the desktop publishing market, was out to capture a new niche before anyone became aware that it probably wasn't really a niche at all but a fairly well established business.
The introduction of some pretty slick software has been paralleled by several new hardware devices; film recorders, LCD display tablets and colour printers being the most important, at prices significantly less than before.
In theory, and Apple's market research tended to back this up, the availability of this new, low-cost hardware together with the new all-singing, all-dancing software would create a massive explosion in the use of presentation graphics by the business community.
To date this explosion hasn't been that much more than a damp November 5th squib, although it has undoubtedly increased the awareness of the business community that there is rather more to making a presentation than a hand-written flipchart.
One of the main problems facing anyone trying to sell this shiny new toy is that most British presentations are conducted with much less in the way of presentation aids than their American counterparts.
(The secret of a good presentation still lies in the message you are getting across rather than the props that you use to help you.)
Whilst the 35mm slide is undoubtedly king in that country we happily muddle along with an OHP or a flipchart.
Most of the figures that have been given for the projected growth of the presentation graphics market in this country, and Europe as a whole, seem to be based on the assumption that there will be a significant change towards the use of 35mm slides.
However, the availability of software to create these is only part of the story.
One of the major problems that presentation graphics has faced is that 35mm slides cost a lot of money.
In London a computer generated slide containing just text will cost anywhere between £25 and £65 depending on the amount of effort that the agency put into it.
Slick graphics slides can cost a whole lot more.
While the costs do fall outside the London area the average price of a text slide is still in the order of £15 to £25.
And, given that an average presentation may require 20 to 30 of these, that represents a substantial investment.
A stack of OHP foils, on the other hand, can be run off on your laser printer for virtually nothing and have a number of significant advantages.
First and foremost is that almost every facility has an OHP projector whereas not all have slide projectors.
Secondly, it's very easy to amend and edit an OHP foil and, finally, they can be copied and distributed to the audience — something that is near impossible with 35mm slides or projected video technologies.
It could be claimed that the lack of colour can be a major drawback of OHP foils but even this argument is beginning to fail.
Colour inkjet printers are widely available, plotters are exceptionally good at generating colour graphs and diagrams while the thermal transfer printers such as Matrix's TT220 or Mitsubishi's G650 are falling rapidly in price.
To understand the potential market for presentation graphics hardware it is worth taking a look at the various ways in which information is currently being produced.
There are two main methods by which material is prepared for presentation work; artwork and electronic.
Of the two the former is still the most common and often the most cost effective.
Indeed, as we will see later, it still has a significant role to play even when the latest presentation graphics software is being used to generate the information.
Conventional artwork for presentation graphics will be made up using typesetting, instant lettering or any of the other methods that allow text and graphics to be mixed on a page.
The resulting image is then either transferred to an OHP foil by photocopying or photographed using a rostrum camera to make a 35mm slide.
The same artwork could, of course, be created electronically and much more cheaply using a presentation graphics program or desktop publishing software.
Electronic generation of presentation graphics has, until quite recently, been a very expensive process.
Dedicated hardware, usually based around the IBM PC or one of its compatibles, comprising high resolution screens, graphics tablets and film recorders has provided a limited range of typefaces, sizes and effects.
However, the advantages of being able to store and retrieve information, merge scanned graphics and logos and apply numerous special graphics effects has allowed bureaux to charge a premium for this sort of service.
With a hardware cost of around £35,000 for a single workstation and a film recorder the majority of the potential users were quite happy to employ a bureau rather than do it all themselves.
However, for several years now there have been low cost cameras like Polaroid's Palette that provided a quick and effective alternative for those who either needed total confidentiality or were simply rather less fussy about the quality.
Indeed, there was a period about three years ago when it looked as though even 35mm slides might have found a match with the introduction of devices like the VideoShow system which project the image on the computer's screen directly onto a conventional viewing screen.
The ability to manipulate the data in real time, the guarantee of complete confidentiality and the various special ‘presentation’ effects were sufficient to persuade many companies that this was the way forward.
Live video projection does indeed have its place but the quality of image generated on a computer screen will never be as good as that of a 35mm slide.
The introduction of the laser printer and the advent of desktop publishing brought about a resurgence of the OHP foil and also began a minor revolution in the production of 35mm slides.
If the artwork for a slide is prepared on an A4 sheet it is, roughly, 400% of the final size that will be captured on the slide.
Reducing a 300dpi image this much effectively makes it 1,200dpi and laser printed artwork is then more than adequate.
There is also the added bonus of a large range of typefaces and the ability to mix graphics with the text.
Although the laser printed sheet is only in black and white the rostrum camera operator can add the colours optically and generate a very high quality slide for around half what it would have cost to produce using a ‘conventional’ electronic system.
(Part of the reason for this, other than the high initial cost of the hardware, is that film recorders take quite an appreciable time to image the slide whereas a rostrum camera works as fast as the operator can change the artwork.)
At this point we are in the position that the market had reached just before Apple got interested.
The traditional system suppliers such as VBS with their Beacon system and Genigraphics were few and far between while Matrix, now part of Agfa, was the dominant supplier of medium-priced film recorders.
At this point the market began to bulge with new and lower priced devices such as the ImageMaker with its idiosyncratic optical font wheel, the Montage FR1 and the promised but rarely seen Mirus — a company in which Apple holds a 20% stake.
Matrix retaliated to some extent with their PCR/SlideWriter and more recently with the even cheaper ProColor but overall there is now much more of a market to choose from.
At the same time another technology emerged which, for small groups at least, added a new dimension to the OHP.
Developed as a result of all the efforts being poured into the LCD screens for portable computers, the LCD tablet allows anything on the computer's screen to be projected via an overhead projector onto a conventional screen.
As LCD technology has evolved so these displays have increased in resolution with VGA now being possible — even in simulated colour.
Although their primary use is in the training market their simplicity and small size makes them ideal as a travelling presentation unit.
Coupled to a portable computer and running one of the new generation presentation graphics programs they make a powerful presentation aid for all but the biggest of occasions.
Until Apple began its marketing initiative there were only two options available; pay someone else to do all of the job for you or do it all yourself.
The first involves a high cost each time you need to build a presentation but no overhead in equipment or skilled staff while ine the second case is exactly the reverse is true.
With the emergence of low-cost presentation graphics packages for both the Macintosh and the PC, and the latter has also been experiencing something of a resurgence, another fundamental change in the market has been occurring.
The third major change in the market has been the emergence, just as with the desktop publishing bureaux, of a number of imaging centres that can take files from any number of different programs and produce 35mm slides for around £5 each.
Such imaging centres have always been a part of the American scene, another reason why they are so much more advanced in their presentations technology than we are, but until very recently the only major European one was in Brussels.
Agfa has just launched a network of nine bureau round the country and there are perhaps a further dozen individual set-ups currently operating, many as part of an existing desktop publishing bureau and so capable of providing assistance with the overall design of the presentation.
Be warned, however, that while outputting slides is relatively cheap skilled operators are often charged out at up £50 per hour!
With slides at £5 each it would seem to be hard to justify buying one's own film recorder unless you were dealing with confidential material.
However, with recorders down to less than £8,000 it doesn't take much arithmetic to work out that a company turning over 2,000 slides a year will come close to being better off with its own camera.
(If you doubt the maths do remember that slides have to be processed at around £3.00 per roll and then mounted at around 20p per slide.)
At least, on the face of it, it will be cheaper to buy your own camera than to use a bureau.
The main problem is that while the software can generate the presentaion very quickly the slides themselves do take time to image, it's not like taking a conventional photograph.
A film recorder works by taking three exposures of the image which is built up inside the box on a small high resolution monochrome CRT.
The composite colour image is generated by exposing through red, green and blue filters with the corresponding parts of the image being displayed.
This process takes time and even on Matrix's top-of-the-range QCR camera a typical 4,000 line resolution text-only slide will take around 3 to 4 minutes.
On the cheaper, and slower, PCR or SlideWriter recorders the process can run to 12 or 15 minutes.
Add in some fancy graduated tint backgrounds or some a scanned logo and you'll really see the time tick by.
At this point you realise that you either need one computer to generate the images and a second to handle the transfer of these to the film recorder or you buy a bulk film pack (which at over £6,000 costs as much again as the PCR/SlideWriter!) and run the imaging process overnight.
Relying on a small bureau with perhaps a single film recorder is, as Murphy's Law always points out, a somewhat foolish activity.
Using such a bureau as a back-up to your in-house facility is obviously a possibility — except that he's bound to be busy when you need him!
The other significant problem that is currently dogging the presentation graphics market is that film recorders come with a paucity of typefaces.
The basic LaserWriter set of Times, Helvetica, Symbol and Courier are supported by most of the new generation devices designed to be driven from a Macintosh and some even offer the LaserWriter Plus set.
However, they are not PostScript typefaces and the quality is sometimes a little less than you have grown used to on the laser printer.
Some suppliers are beginning to develop additional faces but the obvious way forward is to create a PostScript film recorder.
Agfa have done just this with a genuine Adobe PostScript RIP for their Matrix range although, at £12,000, it's not a cheap upgrade.
Montage and Mirus have both been promising their versions of PostScript for many months and there is even a version of Freedom of the Press, a software PostScript interpreter, that will drive Matrix and Montage film recorders.
Eventually the price of such devices will fall and PostScript recorders will become the norm — just as they have with typesetting.
However, if your company requires that all its slides are set in Univers or Franklin Gothic you'll be hard pushed to find a film recorder that will oblige.
Artwork and a rostrum camera will be more flexible and almost certainly cheaper, especially if you work at 300dpi.
One possible alternative that seems to allow you to mix the new software with the best of the old hardware is Visual Business Systems' Output Manager.
This effectively allows any presentation graphics program on the Macintosh to talk to the professional film recorders such as the QCR and beyond by converting the PICT files generated on the Macintosh into the native language of the film recorder.
It even seems to be capable of converting the fonts across by rasterising them and taking them across as a bitmap that the film recorder will image as a graphic.
VBS used to give Output Manager away with their somewhat quirky VB No5 program but now seem to be spending more time developing the Output Manager rather than No5!
The final twist to the whole presentation graphics story must be the current upsurge in interest in Desktop Video.
Hardly had the dust begun to settle in the wake of presentation graphics we are due to be swamped by the ability to mix live and recorded video directly into the middle of computer generated presentations.
Interestingly, while the rest of the world was watching John Sculley announce the new Macintoshes last week the UK audience actually had a sneak preview of this with the Douglas Adams/Hitchikers Guide sequence.
Of course the text looks pretty rough around the edges at 72dpi and the technology costs an small fortune but it's certainly enough to turn a few heads.
Personally, I doubt that any of the current technologies will seriously challenge a good presentation made with a few well-designed 35mm slides.
The fact that we create the artwork electronically is almost irrelevant — it's the words that really count.
The ability to produce program listings or print out text must come very high on any Spectrum owners list of priorities if they are to progress beyond just playing other people's games.
With many micros standard interfaces are provided to allow a wide choice of printing systems to be attached.
An interface, in computer jargon, is simply a means of connecting the computer to the world outside its box—in this instance we are concerned with connecting printers but it could equally be a cassette recorder, joystick or another computer that we wished to connect.
With the ZX Spectrum, as with earlier Sinclair models, no such standard interface is supplied reducing the available choice to a handful of units.
Although the printer interface provided on the Spectrum is a parallel one it doesn't conform to the industry standard for such connections, often called Centronics after the firm who invented it, just as the internal character codes used by the Spectrum fail to conform to the Internationally accepted ASCII codes.
These problems can be resolved in several ways, however, and certainly shouldn't present a barrier to any user determined to get letter quality output from his word processing package.
The simplest solution to the problem is to obtain a special interface unit which converts the Spectrum edge connector signals into ones that a conventional printer can understand.
There are many commercially available interface units that allow the ZX Spectrum to be connected to printers of one type or another.
In the main these convert the signals provided on the expansion connector into the industry standard Centronics parallel interface although some do offer serial as an alternative.
Each character generated by the Spectrum requires one byte of storage space, each byte being made up of eight bits.
In order to transfer each character all eight bits must be sent from the computer to the printer.
With a parallel interface all eight can be sent together with one bit going down each of the eight wires.
A serial interface, on the other hand, must send the bits down its single wire one after the other.
In both the serial and parallel interface some extra wires are needed to provide control over the sending of the information.
These extra wires are generally known as the handshake connections and the method with which they control the flow of information is called the protocol.
There are two stages to this conversion; that of altering the electrical characteristics of the output from the ZX Spectrum and that of converting the character codes from Sinclair's own internal format to true ASCII.
Almost all the interfaces will be supplied with software drivers of one sort or another and in general they all work by intercepting the ZX Spectrum's printer routine vector.
This the location in memory that stores the address of the routine that controls data being sent to the printer.
By changing this address to that of the new driver all the data is re-routed through the interface.
On its way each of the character passes through a code conversion routine.
While the normal alphanumeric codes closely follow the standard ASCII set all the control codes, pre-defined graphics and BASIC tokens must be intercepted.
In the case of the tokens these are converted into strings of ASCII letters before being listed.
Because many of the currently available printers use sequences of control codes to change character fonts or to select graphics, provision must also be made to allow these to be sent without being trapped.
Basic interfaces will provide the driver software on cassette which must be loaded into the Spectrum before it is used while the more sophisticated offerings contain all the necessary software in ROM inside the interface itself.
For the Spectrum owner who is either using or considering the purchase of a Microdrive system an interface unit may be unnecessary as the Microdrive interface itself is supplied with a serial interface which can be used to drive a printer.
The alternative to some form of conversion system is to purchase a printer which has been modified to operate directly with the Spectrum, just as Sinclair's own ZX Printer does.
These are generally either thermal or electrostatic units which tend to offer a cheaper solution than buying an interface and a good quality matrix printer but the results obtained tend to be less professional.
Printers are generally broken into two main categories; impact and non-impact.
Each group is broken down into many different variants depending on the particular way in which the image is transferred onto the paper; daisy wheel, ink jet, thermal transfer and so on.
Impact printers are the largest group and consist of three main sub categories; dot matrix, daisy wheel and ink jet and, apart from the latter which actually fires its ink these operate by pressing something hard through a ribbon in order to leave an impression on the sheet of paper.
The characters to be printed are sent from the computer along either a parallel (Centronics) or serial (RS232/V24) interface.
Because the characters can be transmitted much faster than they can be printed they are stored, in the printer, in a block of memory known as a buffer.
This will hold at least one or more complete lines of text and sometimes as much as 16K.
When the printer is ready to output the text stored in the buffer it is read out, one character at a time and its ASCII code used as the address of a location in a character generator ROM.
This contains the pattern of dots that, when printed on paper, will make up the actual character.
It make no difference at all, electronically speaking, whether the line is printed from left to right or from right to left and most modern printers are capable of bi-directional printing.
With a daisy wheel printer the process is slightly different in that the ROM holds information relating to the position of the character on the spokes of the wheel.
The character itself is made from either metal, the best quality, or plastic and is hammered through the ribbon leaving a complete impression on the paper.
Printers which create the whole character in one strike rather than from individual dots are sometimes called ‘character printers’.
Although the daisy wheel system is fairly universal there are variations such as the thimble as used in the NEC Spinwriter series.
Here the wheel is mounted horizontally rather than vertically and the spokes are bent up at the ends to form a cup shape.
Regardless of the methods used, however, the quality of print is superb and is referred to as ‘letter’ or ‘correspondence’quality indicating that it is indistinguishable from that produced by a professional office typewriter.
The largest potential upset to the dominance of the matrix printer as a low-cost output device is, however, likely to come from an even more esoteric system.
Imagine microscopic drops of ink being fired towards a sheet of paper in a defined and very carefully controlled pattern.
Already well established in the industrial and commercial marketplaces these devices are beginning to make an appearance in the home market.
The system works by pumping liquid ink from a reservoir to the tip of a very fine jet.
Here minute droplets are charged to very high voltage before being ejected.
The jet is commonly made of a piezo-electric material and this shapes the droplets by very high frequency vibrations.
As the droplet leaves the jet it is held in position by an electric field which further propels it towards the paper.
The sheet of paper is not stretched over a rubber roller or platen as it would be with an impact printer but a sheet of metal.
This is charged to the opposite potential to that held by the droplet and attracts the ink into the paper.
Very little mess occurs, about the worst that can happen is that the jet gets clogged causing the ink drops to get oversized or the reservoir is removed without being capped.
The quality of printout depends mainly on the type of paper used, the more absorbent it is the more the ink soaks in and the image blurs.
At their best ink-jet printers can produce an output quality several times better than that of the average matrix printer.
The latest application of the ink-jet principle is that of colour printing.
As well as printing in black these device also contain reservoirs of red, blue and yellow inks.
These colours may be unfamiliar to those used to working with graphics on a TV screen but they are the painter's equivalent to red, green and blue as all other colours can be made by mixing them together.
Unlike the colour printing achieved from multi-ribbon matrix printers the results are really excellent.
The penalty for this is not, somewhat surprisingly, the price but the fact that the paper used has to be slightly absorbent so the printout is of average quality.
An interesting variation on the liquid ink-jet printer, is the ‘Dry Ink’ system based on the principle of spark erosion.
Normally printers of this type are classified as non-impact but this version actually deposits carbon rather than burn away a layer of silvering.
The printer has several advantages over conventional printers; it is almost silent, the printhead is very light and so powerful motors are not needed and almost any kind of paper can be used.
Its drawbacks are that the printing speed is low, the head only prints one dot of each character as it passes across the paper, and the ‘ink’ does tend to smudge.
Non-impact printers obtain their name from the fact that they don't hammer needles or shaped pieces of metal through a ribbon in order to leave their mark on a piece of paper.
Two main types exist; thermal and electrostatic although there are other categories such as the laser — although this can hardly be classified as low-cost!
The thermal printer works in much the same way as an impact matrix printer in that instead of a column of needles in the printing head it has a column of heating elements.
As each dot is required the respective element is rapidly heated and the minute area of paper under the element changes colour.
The contrast between the dots and the background is good enough for most uses but hardly rates as high quality, the most endearing feature about these devices is their almost total silence.
In contrast, the electrostatic mechanism is moderately noisy and initially failed to gain any real support.
That was until Sir Clive Sinclair adopted the system for the ZX Printer, a dedicated peripheral for the ZX 81 and ZX Spectrum.
The principle is that a single-wire printing head is dragged across a specially coated paper.
For every dot that needed to build up a character a spark is generated by the printer which burns away the thin silver coating revealing the black backing paper.
Sinclair improved the system by using two heads on a continuous belt but it still takes four passes of each head to create a row of characters.
Electronically both types of printer operate in much the same way as a conventional impact matrix printer with the pattern of dots being taken from a ROM.
The quality of the printing depends on the number of dots that are used to create each character; typical values range from 8 rows of 8 dots to the, so called, Near Letter Quality of 24 rows of 17 dots.
The low cost thermal and electrostatic printing systems generally produce an 8 by 8 matrix printout which, while clearly legible, doesn't give true descenders on lower case letters like ‘y’ and ‘g’and cannot support high resolution graphics.
The main drawback with both types is that they use special paper which can be expensive and is only available in rolls which can make storage difficult as the printer doesn't produce separate pages.
In the case of the thermal printer it is essential to get the correct grade of paper otherwise the image does not develop properly.
Electrostatic paper is even more delicate and if handled with damp hands the image will blur as the silver coating dissolves.
In both cases the best way to ensure a good, long-lasting image is to take a photocopy.
Setting up an in-house electronic publishing operation takes rather more effort than most potential users seem to realise.
It certainly isn't simply a case of just reading up on the reviews, playing around with a couple of the likely programs and then buying a system or two and expecting peace, harmony and perfect publications to be the end result!
The potential for disaster lurks very close behind the bright shiny facade waiting to pounce on the unwary and relieve them of substantial sums of money.
Perhaps the best way to explain how an electronic publishing system implementation should be organised is to walk through the various processes one by one.
If you have already started down the route on your own and missed out some (or all) of the steps you will begin to realise what remedial action you need to take to put everything back on course.
For those who have yet to take the plunge I hope the following will act as a series of checkpoints that you can apply to your own, unique situation.
Unique, because every system is different both in terms of hardware and software needs and the skills of the staff who are going to use it.
The publications you produce may well fit into a set of identifiable categories; brochures, newsletters, flyers, books, manuals and so on but it's how you produce them that's important.
The starting point of the process is an evaluation of what documents your organisation produces, how it currently produces them and in what quantities.
This publications audit will often turn up other interesting facts that you might have been unaware of like two departments doing exactly the same thing through different outside agencies or short runs being hammered out on page printers when they could have been more effectively produced on a photocopier or by a print shop.
The process should also give you some idea of what your company spends on printing, or at least producing, documents—it will probably be around 8–10% of your turnover, assuming that your company isn't actually in the publishing business in the first place.
Your next step is to perform a software and hardware audit.
What computer systems do you use, what software runs on them and what files are created that you will need to bring into your documents?
It is worth remembering the apparently obvious at this point—electronic publishing is not going to work unless your information is in an electronic form!
So, if you aren't even at the word processing stage yet it may well be better to get this technology in place first before you try to tackle the wider issues of electronic publishing.
It is also worthwhile spending time at this point examining the things that you know you can do but don't bother with.
For example, a company makes consistent use of spreadsheets to keep costs under control and to monitor its performance against those of its competitors.
The spreadsheet program can produce graphics and you would like to put these graphics into your electronic publishing system.
Unfortunately you find that no-one has ever bothered to produce the graphics before because they take too long to print out on the current office printer!
What do you tackle first, the spreadsheet graphics or the electronic publishing system?
Or you might want to put photographs into your brochures but have never considered it possible before because they are only photocopied.
The third and final stage that you have to go through before you can even begin to decide what electronic publishing system (or systems) will be suitable is that of discovering the skills that your staff possess.
If you already operate a conventional publications production system then you will have little problem in converting those existing skills onto the new technology.
If, however, you are starting from scratch then you have to consider who will be trained to operate the electronic publishing systems.
Expecting a word processor operator to pick up the elements of design, typography and layout skills by simply going on a two-day course is just not realistic.
The basic skills can be learned but it generally take three to six months before the lessons have really taken hold.
Even then you may consider relying on outside designers to create the masters while your operators simply fill in the gaps.
Accepting that you will need to provide either training or re-training for your existing staff means that you will remember to budget for it in the overall cost of the system.
The number of companies who fail to build in any kind of allowance for training is astonishing.
Electronic publishing isn't like word processing, it's not that easy to ‘pick it up as you go along’ —at least not if you want professional results.
You will also have to allow for the time lag between installation and productive use which will probably be months rather than weeks or days.
During this period the system will have to be backed-up either by your previous in-house production methods or by external agencies.
Calculations for the break-even point of the system will also have to be deferred until the new system can be seen to be at least as productive as the old.
Another important aspect of the training and staffing of the system will be its method of control and management.
If you currently rely on several word processor operators to generate material that is then ‘published’ it might occur to you to simply have each word processor operator trained up on the electronic publishing system.
However, it may well be worth considering taking one of the existing operators and using them to provide all the formatting.
This will keep the production flow much simpler and also ensure that all the documents are consistently produced.
The larger the organisation, the more suitable the dedicated electronic publishing unit concept becomes.
The only problem is managing it as, if electronic publishing is the first involvement that your company has had with publishing, it is unlikely that the existing management will have experience of copyflow, editing, and other essential management checkpoints that help ensure the quality of the documents you produce.
It is only now that the attention can be turned onto the actual hardware and software that will be required.
Indeed, the attention to hardware is much less important even at this stage than might be imagined.
The real key to the success of an electronic publishing system is its software.
From the earlier document audit you will know what you want to produce, you also know what software you currently use and the skills available to you.
These can now be matched against the various product on the market to see which provides a viable solution.
When you come to evaluate the software always ensure that you test its capabilities by having it produce real examples of the work that you will be doing.
This actually tests two things, the capabilities of the software itself and those of the dealer trying to sell it to you.
The software may be wonderful but if the dealer doesn't know how to make it work properly how is he going to train your staff and provide support for them?
Ensuring compatibility of data between the systems that you currently have and the proposed electronic publishing software is much more important that worrying about the hardware that it runs on.
If, for example, your company uses PCs extensively but the obvious choice in software happens only to run on a Unix workstation then so long as the files can be transported between the two systems there is no penalty in selecting an ‘alien’ hardware platform.
Indeed, the penalty would be in sacrificing the potential benefits by selecting something that almost did the job but happened to run on a PC.
The level of sophistication that you require from the system will be governed by many factors which the groundwork that you did in terms of the document audit should have revealed.
It is important, however, to ensure that you have left as many doors open as possible in terms of future requirements.
Take, for example, a small company producing fitted kitchen units.
Initially they only need to keep track of customers, write letters and run a spreadsheet.
They would be perfectly well served by one of the many word processing packages that supports page printers such as the HP LaserJet and can incorporate simple graphics; WordPerfect 5.0, Samna's Ami and Windows Word being typical examples.
The company grows and instead of being able to produce its leaflets on its own printer needs to use a local copy shop.
The next stage in the development is to use a page makeup package to create more sophisticated documents—still using the word processor to create the text and the page printer to produce masters.
Now the firm brings in a designer to improve their image and as a result better fonts and more variation are required so the printer is either upgraded to or replaced by a PostScript device.
The final stage in the development is to have the documents typeset which, inevitably means taking PostScript files to a bureau and then onto a professional printer for bulk reproduction.
Along the way nothing has been lost from the original system and there were no closed doors to the logical upgrade path.
Once the decision as to which piece, or pieces, of software will meet your requirements has been taken, together with the selection of the necessary hardware, the implementation phase of the project can begin.
In an ideal situation the staff to be trained will be taught externally on an identical system to the one being installed.
The training will take place in parallel with the installation and they will return to work ready, and able, to operate the new system.
Life, of course, is far from ideal and it is more than likely that the training will take place in-house on the system once it has been installed.
During this period it is essential that all the staff's normal duties are covered for them, nothing is more likely to prevent successful training than constant telephone interruptions and the need for the staff to get back to their normal work.
Once the training is over the real learning process begins.
The first jobs through the system should be paralleled through the current process as well to provide at least a degree of insurance against total disaster.
It is unwise, however, to let either of the two sides think that their work is non-urgent!
During this initial period it is also more than likely that your staff will need access to some form of support line service.
Any good training service should provide this, either as part of the standard training package or through the dealership's normal help desk service.
As time goes on the need for such support will, obviously, diminish—it's more than likely that your staff will become more conversant with the product than the person who either sold or trained them on it.
Support calls are now more likely to be directed to the software manufacturer or one of the independent organisations such as a User Group.
Here, at least, the level of knowledge should be up to answering more detailed questions.
After some three months have passed it is often wise to conduct a full review of the new systems and to discover how far they have progressed.
Perhaps now is the time to run down the older methods and, if this is not the case, maybe some additional training is required.
This review process needs to be carried out on a fairly regular basis, perhaps every six months, and it should include looking at the current state of the market to see if there are any new developments that can be applied.
Electronic publishing software is upgraded, on average, every 18 months and decisions need to be taken about how, and when, to carry out these and what training to provide.
One thing that regular reviews also reveal is the range of new publications that the system is being asked to produce.
These are often documents that were never included in the original audit—perhaps never existed until someone saw the potential of the new system and decided to exploit it.
A classic example in this area is forms.
They can be created with many of the electronic publishing packages but are often better produced by a dedicated forms program.
The review will provide evidence to support buying such a dedicated program or whether to carry on using the existing system.
It would be possible, at this point, to smugly say that that's all there is to successfully implementing an electronic publishing system.
Of course, it isn't—and no set of general purpose guidelines is ever likely to meet all the diverse requirements of the market.
However, if the advice you've just read triggered off even one thought along the lines of ‘Oh, I must remember that’ then it has served its purpose by breaking the myth that all there is to electronic publishing is a piece of software and that anyone can use it.
Installing an electronic publishing system can bring substantial benefits but it can equally bring headaches that would have been avoided by some simple preliminary investigations.
Indeed, there are people who simply don't need an electronic publishing system at all—a high-end word processor may be all that they actually require
During the past four years, and it really has only been with us for that long, desktop publishing has managed to get itself a fairly bad name among the professional graphics community.
And not without good reason.
Indeed, it would probably be true to say that more sub-standard typography has been produced by desktop publishing software during its short lifespan that by traditional methods in the whole of this century!
And yet, the technology really does have much to offer the professional graphic artist, compositor or printer if he or she can afford the time to sweep aside some of the hype that surrounds it.
In reality, what desktop publishing has provided is a new, cheaper tool for the professional to use as and when it is appropriate.
Just as with the introduction of any new technology; be it digital typesetting, offset litho printing, Spray Mount adhesive or even a new range of inks there will be those who approve and those who disapprove.
Unfortunately, for the traditional printing and graphic arts industries, the desktop publishing ‘revolution’ has taken place largely outside their control and has placed the capability to generate complex artwork directly in the hands of anyone with access to a computer and around £1,000 or less for the necessary software.
No longer can there be a neat and tidy debate in the pages of august journals such as this as to the benefits, or otherwise, of the new product.
This time it has all gone public.
What is even worse is that desktop publishing delivers to the mass market at a ridiculously low price the technology that traditional electronic publishing system suppliers have been promising us for years—the ability to mix text and graphics freely on a page.
Just the fact that this can be achieved at less than £10,000 for a complete system is rather likely to upset anyone who has invested hundreds of thousands in ‘Third Wave’ systems and discovers that, for a tenth the cost they could actually achieve rather more.
Indeed, much of the backlash against desktop publishing has come from these quarters rather than being based on serious evaluation of the technology and its strengths and weaknesses.
And let there be no doubt about it, desktop publishing has significant weaknesses—but then so do most infant technologies.
The good news here is that because the suppliers have to sell large numbers of a low-cost product to recover development costs and so fund the next round of products—despite what Atex claim when they make their conference pitches—these companies have a distinct interest in making the products better, cheaper and faster.
It has been claimed, and I'm not in a position to disprove it, that there are more software engineers working on composition software at Aldus than at Atex…
So, where did it all begin?
The actual term ‘desktop publishing’ was coined by Paul Brainerd, the founder of Aldus, to describe what he was trying to achieve with the, then, newly created PageMaker program.
If there's one thing that is clear about desktop publishing it is that it is NOT publishing, a fact that often seems to escape those who sell it.
A more accurate description might be desktop composition or desktop page layout—but these don't have quite the same ring to them.
In reality there was already primitive, and in some cases quite sophisticated, desktop publishing software being developed at and around the same time as Aldus emerged with PageMaker for the Apple Macintosh.
Programs such as Studio Software's DO-IT and Software Publishing's Harvard Professional Publisher (now long defunct and actually licensed from Bestinfo of SuperPage and Wave4 fame) were emerging for the PC while the Macintosh was also being targeted by Manhattan Graphics with Ready, Set, Go!(now distributed by Letraset) and Boston Publishing Systems with the now defunct MacPublisher.
The thing that made Aldus's product take off was undoubtedly the special relationship between Apple (who heavily promoted it as a way to sell their LaserWriter page printer), Adobe (who wanted to make a market for PostScript) and Aldus themselves—the so-called Triple-A Alliance.
In reality, and with the benefit of 20/20 hindsight, the early versions of PageMaker (and the others) were rather less than perfect.
However, the one thing that instantly distinguished PageMaker from the rest was the fact that it had been designed to work in the same way as a traditional paste-up table.
This meant that the product was incredibly easy to learn and, most important of all, left all the control in the hands of the user.
PageMaker is still, incredibly, the only desktop publishing program to have been developed by a team experienced in graphics arts, printing and publishing—all the rest were written by programmers seeking to emulate such an environment.
It is here that the problems really began.
Given a low-cost product which can do so much so quickly it was a inevitable that its use would begin to spread from the professional graphics market—for which it was predominantly designed—to the office market.
Here the ‘cut and paste’ method of working was just as easy to use and so the program's sales began to mushroom.
The graphics industry, which was quietly waiting for its traditional suppliers to deliver their promises, suddenly found itself inundated by pseudo-typeset documents output at 300 dots per inch and was, rightly, unimpressed.
Desktop publishing is, on the evidence presented, rubbish—they said.
Unfortunately, few of them actually ever bothered to try it for themselves—they just relied on the evidence presented.
The reason for all this appallingly produced material is obvious.
It is totally unreasonable to expect a typist to become a typographer overnight or a secretary to turn into a layout artist or a marketing executive to become a designer.
Yet, according to much of the advertising used to promote and sell these products, that's exactly what should happen.
Of course, compared to what they had been producing with a typewriter and some rub-down lettering, the desktop publishing system was producing wonderful material—it just didn't conform to any of the professional standards.
The missing element was, and still is, training.
Some three years on from that initial burst of enthusiasm and the corresponding outcry from the professional market much has changed.
Today's desktop publishing software is as good as, if not better than, any Third Wave composition system ever was.
It is cheaper, faster, easier both to learn and use and can, given the right operator skills, produce superior results.
The typesetter vendors have endorsed it wholeheartedly, there is now not a single major typesetter vendor not supporting PostScript or one of its emulations, and many of the traditional vendors are actively incorporating elements of the technology in their Fourth Wave offerings.
At the lower end of the market much has also happened.
The software houses have realised that the skills are not present, nor are they likely to be, and have compensated for this by providing either sample templates with the programs or even cut-down versions that only allow text to be entered into a pre-defined design.
Word processing programs are now no longer limited to the world of the monospaced character, real typefaces are provided as a matter of course together with accurate document previews.
To relieve the unskilled operator problem much of the decision making is now handled by the program rather than the user; Ventura being a classic example where the stylesheet is created by a professional and then all the user needs to do is to pour text into the file to create a fully formatted document.
Whilst all the furore has been taking place about the quality, or otherwise, of desktop publishing many professional graphics, printing and publishing houses have been making up their own minds as to its usefulness.
Probably the most famous, if short-lived, desktop publishing operation was Eddy Shah's Post which combined Talbot's NewsWrite editorial front end with Aldus PageMaker at the back to create a national daily newspaper.
The fact that the system cost around £300,000 as compared to a traditional suppliers offer of £2.5 million and only took three months to design, install, train and make fully operational reflects well on the technology—even though the paper itself failed.
Other national newspapers, the Independent and the forthcoming Sunday Correspondent, also make significant use of desktop publishing capability for producing their magazine sections and these and many other titles use the technology for creating graphics and illustrative material.
On the magazine publishing front it is hard to find publishers who are not investigating or actively using the technology.
IPC Magazines is undoubtedly at the top of the list with its ‘across the board’ implementation plans; several titles are already wholly or partly created in this way.
Smaller, more specialist publishers such as Rhinegold who produce Classical Music and other similar arts titles are now not just creating all their pages with desktop publishing technology, Ventura in their case, but are also using 600dpi page printers instead of typesetting equipment.
The purist might just spot the difference with the aid of a magnifying glass but the average reader is totally unaware of the change.
Indeed the ex-editor of Classical Music contacted the publisher to ask why they had reverted to Times as the body copy typeface, he had changed it from Times to ITC Clearface, and was duly surprised to find that the reason was to do with the fact that the title was being produced on a desktop publishing system.
This, rather neatly, brings us to another of the major problems that besets the desktop publishing market; fonts and their presentation.
Until last year one of the biggest complaints made by graphics professional was the paucity of PostScript typefaces, or at least proper ones from the likes of Adobe and Linotype.
With the signing late last year of Monotype, Compugraphic and AM Varityper together with the more recent additions of Scangraphic and Autologic there is little if any cause for complaint to be made.
What is worrying, and it is a problem that looks set to get worse rather than better, is that there is now a proliferation of font formats.
Take, as an example, a typesetting house with a traditionally front-ended Linotronic 300 imagesetter and a respectable font library.
They decide to add a PostScript RIP and find, to their dismay, that they have to buy the fonts all over again.
Whilst this may have been commonplace in the old days as vendors moved from technology to technology there is little need for it now, as Monotype are adequately demonstrating.
What is even worse, however, is that as the two fonts may have been prepared from different masters there could be subtle variations between them—even though they are notionally the same typeface.
Again, Monotype appear to have a lead in this area as they are coding all their fonts from a single digital master, regardless of the final output format.
as if the problems of font matching within a single typesetter vendor's equipment weren't potentially bad enough we now face the problem of a whole host of methods for getting the fonts displayed on the screen of the desktop publishing system.
Adobe has Display PostScript, currently endorsed by IBM, DEC, Next and Scitex, while Apple has just announced its own proprietary system called Royal.
Among the traditional vendors we have Sun's Folio F3 format, which actually looks to be a serious contender for the industry standard, and then there is Compugraphic's Intellifont which is also being used by Hewlett-Packard, not to mention Bitstream and the as-yet-undecided font format for Microsoft's Presentation Manager.
The potential for font mismatching has now been raised many times.
Take, for example, a desktop publishing system based on an Apple Macintosh.
It could use Apple's bitmapped fonts, Apple's Royal fonts, Adobe's Type Manager PostScript fonts, Bitstream's fonts, Berthold's fonts, etc, etc, etc.
The user prepares a document using Berthold fonts and sends it to a bureau for output on an imagesetter which just happens to be running Hell-Xenotron's Bridgit.
The result?
Well, we'll leave you to guess what it looked like.
We all complained bitterly when it looked as though Adobe was restricting the development of PostScript and keeping the market to itself.
Twelve months on and we are beginning to wish that we had left things the way they were!
One of the things that never ceases to amaze me about any technology is that once you have it you always expect it to do more.
The development of colour desktop publishing is a classic example of this in action.
Because the computers on which most desktop publishing software runs are capable of displaying colour it seems logical to the software developer that they should introduce colour into their desktop publishing programs.
Whilst they can probably get away with spot colour separations, and indeed many of them produce excellent spot separated material, the world now seems to expect that process colour separation will follow just as easily.
Some vendors are promising that they will provide it on their own, others such as Quark are linking to specific vendors (Scitex in this case) while still others such as Aldus are merely providing an open interface to anyone who cares to take their files on board.
Of all the approaches the latter is likely to succeed the best as they are leaving all the clever stuff to those in the know.
Colour publishing on the desktop is possible and can be demonstrated.
As to whether it will be a viable alternative to the likes of Hell, Scitex and Crosfield or will simply provide these companies with the base material in electronic form is an answer that is some years away yet.
If there are lessons that can be drawn from the past four years then they are probably the following.
First, it is unreasonable to expect an untrained, unskilled operator to be able to create professional results from a desktop publishing system.
Second, given the availability of a trained and skilled operator there is nothing that a good desktop publishing system cannot achieve in monochrome or spot colour publishing that was not possible by traditional methods.
However, the results are achieved by one person in a single, continuous operation rather than by several skilled people performing disparate tasks.
Third, given a trained and skilled operator the productivity gains and composition power of a desktop publishing system eclipse anything that is available from traditional vendor of Third Wave technology.
Fourth, desktop publishing systems are getting better faster than comparable systems from traditional vendors.
On average each desktop publishing software vendor produces a new and improved version of the software every eighteen months at an incremental cost of perhaps 20% of the original cost-effectively free in real terms.
The hardware platforms on which this software runs are also improving at a similar rate and, as they are not proprietary, it is possible for the user to upgrade at will rather than when the developer demands.
Fifth, the problem of fonts and output matching will become as big a problem for the desktop publishing market as it ever was for the traditional sector and potentially more confusing for the user than ever before.
Sixth, given all the facts there is no logical reason why a professional graphics house, typesetter or printer producing conventional documents should not be capable of making the decision to change to desktop publishing technology from traditional.
However, there are many areas such as complex tabulated material, scientific equations and formulae and the use of non-latin alphabets where desktop publishing has yet to make any sort of impact at all.
Seventh, if anyone tries to sell you colour desktop publishing decline politely on the grounds that being a test-bed for new technology is not the business that you wish to become involved in.
Eighth, don't expect to get any sort of sensible answers from a company who sells computers which happen to be capable of being used for desktop publishing.
As professionals, talk to other professionals.
Finally, remember that you had to put a considerable amount of effort into learning the skills that you have today.
Don't expect to be able to pick up desktop publishing skills in an instant.
You will find it much easier than the untrained but there is still much to learn.
Although programs such as PageMaker and Ventura continue to steal the headlines as being the driving force behind desktop publishing there is a whole raft of alternative products that operate at a much lower level.
Whilst these may be significantly cheaper in terms of cost and so written off as mere toys they are often far more capable of producing simple documents than they are given credit for.
And, because they are designed to operate at a lower cost level they tend not to make demands for expensive peripherals such as PostScript devices or even simpler page printers such as Epsons and Okis that emulate the Hewlett-Packard LaserJet.
The idea of producing quality documents from a 24-pin dot matrix printer may seem strange but it is possible providing the user doesn't try to emulate the capabilities of a more expensive systems.
After all, some dot matrix printers can actually produce a greater number of dots per inch than a page printer, it's just that they are bigger dots and tend to overlap.
The problem, then, is often not one of capability but output clarity and good typography demands that the image be clear.
It doesn't matter so much if the document is to be a one-off, although it obviously helps fairly significantly if the material can actually be read.
Beware of small point sizes and avoid the mistake of thinking that 10 characters per inch means the same thing as 10 point, it doesn't!
Also try to avoid italic and underlined type, there are too few dots to allow these to work properly.
The real problems arise, though, when you are creating a master document that is to be reproduced in bulk by either photocopying or traditional printing.
And, at 10 minutes per page for a 24-pin dot matrix printer it's likely that anything over one copy is going to be treated in this way.
Unless the original is crisp and clear the copies will lose definition, the smaller or more delicate the typeface, the worse the problem.
Paradoxically, in some cases photocopies look better than the original because they help smooth out the jagged edges of curves and fill in the gaps between the dots to make the letters look more solid.
Simple documents such as a two-column parish newsletter or a flyer promoting a new sandwich bar or a college concert simply don't demand the same degree of overall quality and items such as these are readily produced by programs such as Timeworks, GEM Desktop Publisher and Finesse.
Even lower on the scale of things, come programs like Newsroom Pro and Fontasy.
Of the five mentioned perhaps Timeworks represents the best compromise between price, features and quality of output and it even comes in a ‘Lite’ version for the really cost conscious.
Perhaps it should come as no surprise that a sister product to the established First Word Plus should rate so highly, both were developed by GST, when you consider that word processing under a graphical environment such as GEM is almost the same as simple desktop publishing.
Indeed, the link between word processors like First Word Plus and desktop publishing is strengthening all the time while stand-alone products become more and more limited.
In the Windows environment there is currently little real competition apart from Windows Write although Samna's Ami looks to be a strong challenger with its extended handling of fonts.
And it is with fonts that the low cost desktop publishing system really does have problems.
The simple fact is that, even with a very good 24-pin matrix printer, it is very hard to reproduce typographic fonts.
After all, matrix printers were designed to handle typefaces for word processing, not desktop publishing.
There are ways around the problem, though.
Any Windows-based package can image its PostScript screen fonts onto a matrix printer and so produce a realistic ‘proof’ of what the document would look like it were to be output through a page printer or typesetter.
Alternatively, for those with a little more money in the bank, something like a Hewlett-Packard DeskJet will produce what appears to be page printer quality at around half the price.
Based on an extension of their proven inkjet printing technology, the DeskJet looks, to the software at least, like a LaserJet.
Quite apart from the quality aspect, this also means that it can make use of the enormous range of fonts that are available for LaserJet printers.
So far as desktop publishing goes the dominant range here is supplied by Bitstream, indeed most packages seem to provide the basic Dutch (Times) and Swiss (Helvetica) faces free of charge.
The penalty is that you have to decide what sizes you want and prepare them in advance, a process that can take quite a time and uses up a considerable amount of disk space.
However, once done, the fonts are of excellent quality and can significantly improve a document provided they are used sensibly.
The problem is that, should you ever want to upgrade to PostScript, they don't exactly match the fonts supplied by other vendors such as Adobe or Linotype.
It is hardly surprising that, given the cost of PostScript devices, people have actively sought out alternatives.
Currently on the market are two programs that allow, or so they claim, any printing device to emulate a real PostScript printer.
First, and best known, is GoScript while more recently Freedom of the Press has also been making a few headlines.
Both allow programs to pretend that they are connected to a PostScript printer and so offer the user a wider range of typefaces, GoScript comes with emulators for both the basic four-font and extended eleven-font sets.
However, they are very, very slow in operation and, whilst interesting novelties, are difficult to take seriously.
It is likely that this will change as LaserGo, the authors of GoScript, are due to introduce a special card which will contain its own processor and memory capable of running the program.
In theory, at least, this will relieve the tremendous burden that is placed on the micro to both run the desktop publishing program and control the printer.
Perhaps the best example of the problems that this approach can cause is the Atari desktop publishing system.
Undoubtedly low-cost and based on a quite remarkable piece of British software, Fleet Street Publisher (Note: do not confuse with the awful Fleet Street Editor) it even includes a page printer.
Sadly, it relies on the power of the Atari computer to process all the fonts and images that Fleet Street Publisher produces and, as a result, runs like a snail.
Whilst desktop publishing at the low-end of the market may appear to be a careful juggling match between cost and quality of output, as indeed it is, the real determining factor about the suitability of the products is whether they actually provide some benefit that could not be achieved by other means.
For example, a good word processor may well be able to produce multiple columns of text on the page but totally unable to integrate a simple drawing into the document.
Or, alternatively, it may not be possible to have a heading across more than one column of the text.
These are features that simple word processors were never designed to incorporate but which low-end desktop publishing packages find simple.
Similarly, few word processing packages can accurately hyphenate and justify text that is proportionally spaced as they were only ever designed to handle monospaced characters.
Here, if you want something looking even halfway decent you'll have to turn once more to the desktop publishing program.
However, the times are changing rapidly and more powerful word processing programs such as WordPerfect 5.0 can perform all these tasks and more.
Whilst they may seem expensive compared to the desktop publishing programs they can still work out cheaper because they include the word processing functions that few, if any, of the low-cost packages have built in.
The cost of the low-end word processor and desktop publishing program combined may well be more than the cost of a good word processor that can do many of the same functions.
And, no matter how good the programs, the final quality depends on the choice of printing device.
As I have already indicated in the main text of this article, there are real users of high resolution page printers.
A classic example of these is Rhinegold Publishing, a London-based specialist publishing house producing a range of arts-oriented magazines and journals.
Although they were quick on the uptake of word processing systems, the company has one computer per staff member, they were still ‘double keying’ the majority of their text although portions were being supplied to the typesetters on disk.
Indeed, as Tony Gamble, the company's Publisher and Managing Director, indicated to this year's Electronic Publishing Conference the main reason they hadn't looked at desktop publishing was because they were professional publishers and felt that the technology was unlikely to be suitable for them.
A chance meeting with Dr Kathy Lang at a database user group and the subsequent investigation of Ventura led Tony Gamble to make the decision to give it a try.
What was equally obvious, however, was that unless a high resolution output device could be found to produce pages from the system the company would still be firmly locked into a typesetting bureau for output.
Just such a device was available in the shape of AM Varityper's VT600, a PostScript 600dpi plain paper page printer, although it was only through reading a year's worth of back copies of the Desktop Publisher newsletter that Tony Gamble ever found out about it.
As a result the company now runs several page makeup stations equipped with Ventura 2.0 and owns two VT600 printers.
That the system has been a success is not in doubt.
The fortnightly Classical Music title was the first to be converted and all the company's other titles, including their reference books and directories, have followed suit.
In addition, all new publications are designed for creation on the system — a subtle distinction from being designed on the system.
In terms of cost effectiveness, a single Ventura/VT600 installation applied to Classical Music should have paid for itself in eight months—costed against the savings in typesetting.
However, as Tony Gamble points out, once the system is in you can do anything on it and, instead of being a ‘cost per page’ its operation simply becomes another overhead.
An example of this effectively ‘free’ typesetting capability is given by their recently launched weekly job opportunity sheet which, had it had to have been typeset, would not have been financially viable.
Perhaps the greatest tribute to the system's aesthetic capabilities was provided by the ex-editor of Classical Music who, some weeks after the changeover from traditional to electronic, asked Tony Gamble why they had changed back from ITC Clearface to the original Times.
Clearly an editor who knew his typography but one who never spotted that the publication was no longer being pasted together by hand—let alone produced at a mere 600 dots per inch.
It is perhaps somewhat strange, given the proven commercial success of the VT600, that very little effort is made to market it in this country.
Whilst it has been installed at a number of specialist publishers, such as Rhinegold, and more than a few local and regional newspapers, AM has never made much of an effort to actually sell the device on its merits to either the corporate market or the publishing community.
Limited, until recently, to an A4 sheet and with some initial problems in terms of RIP reliability it may have been but the output quality is more than adequate for a wide range of documents.
Perhaps AM was worried that it might take some of the momentum away from their PostScript imagesetter but then they hardly seem to be setting the world alight with that either.
On the ‘beefed-up’ engine front we have Genicom making more of the speed advantage than their increased resolution while Agfa are hardly making any noise at all about either of their 400dpi devices — although they may feel the same anxiety pangs as AM Varityper given that they also own Compugraphic.
Indeed, both these companies target the corporate market far more than the professional publishing sector which, while entirely understandable, means that a great many potential users simply never hear about the products.
Of the remainder, IBM has only ever marketed its 600dpi product through the traditional channels (it's appearance at last year's IPEX was something of an aberration while neither Printware or LaserMaster have sufficient of a foothold in the market to splash large sums of money on a marketing campaign.
So, for the moment, if you want a higher resolution page printer it really is a case of going to find it rather than having it thrust at you.
However, given Linotype's apparent dedication to the market with a promised 600dpi device and moves by other vendors to develop the same market it doesn't look as though the current players have too long to wait before they have some real competition.
And, as all marketing people know, it's not always the first into the market that succeeds—more often than not it's the one that shouts the loudest
For any computer, from the humblest home micro to the biggest mainframe, to be usable it must be equipped with a man/machine interface.
Put simply this means that it must have some means of accepting information from the user, normally a keyboard, and giving results back, traditionally a screen of some kind.
While the physical interface, in one form or another, is supplied as a matter of course the user is still forced to communicate with the system by means of a very artificial language.
Commands such as RUN, LOAD and SAVE may be meaningful to the operating system but they certainly aren't ‘natural’.
The natural communication system for humans is speech, not typing messages on keyboards and watching messages on television screens.
If the computer could be made to reply vocally and, perhaps, understand spoken commands; even if the utterances were phrased in the same way as those given through keyboard and screen, the computer would be easier to use.
Before any computer system can generate or understand spoken words the complex waveforms that make up speech must be turned into a digital form that the computer can cope with.
In total contrast to the problems facing speech recognition, which will be looked at in a moment, the task of electronically generating speech has pretty much been mastered.
When we talk we produce sounds of three distinctly different types.
The first is the ‘voiced’ or vowel-type sound; oo, ar, ee, etc.
These are produced by the vocal cords in the throat vibrating and the frequency of this vibration determines the vowel sound we hear.
The second major type of sound is the ‘fricative’ or unvoiced sound and examples of this are; ss, sh, t and ff.
Here the air from the lungs rushes past the vocal cords and the frequency of the sound is controlled by the positioning of the lips and tongue.
The third sound type is silence or, to be more precise, the gaps that occur within words like six and eight.
To electronically generate speech-like sounds we can use one of two methods.
The first, and until recently the most common, is that of synthesis by rule.
If we carefully analyse the frequencies contained within speech it is possible to devise a system of rules that allows us to create any given sound from its basic frequencies.
For example, the word too could be defined as so many milliseconds of the t frequency followed immediately by the oo frequency.
These individual ‘building blocks’ are called phonemes, or in some instances allophones, and by using them in various combinations any word can be constructed.
The characteristics of the original speaker tend to be lost when speech is generated in this way but the words themselves can be clearly understood.
Because the rules for the generation of the various phonemes are built into the equipment itself the user is usually able to give the system a list of the phonemes which are then spoken.
With a little practice it is possible to generate complete sentences instantly by simply calling up a string of stored phonemes.
The second method for generating speech relies on the fact that the human ear and brain are very good at filling in gaps.
For example, the speech we hear over a telephone line is perfectly understandable.
Yet the quality, the range of frequencies we can detect, is only a fifth of that which we would expect from a reasonable Hi-Fi system.
The reason we can understand what we are hearing is because our brain can fill in the gaps.
With the reduction in cost of computer memory it is now possible to convert speech into digital information which is then compressed many hundreds of times and stored in a ROM.
To cause any of the stored words to be spoken we get the computer to recover the digital information and convert it back into sound.
Because the original speaker's words are stored the personal characteristics remain, even the accent is readily detectable in some cases.
The uses for speech synthesis are so varied that it is almost impossible to list them.
To start with it can replace taped announcements at railway stations, airports, etc.
In America it is widely used on the telephone system to inform callers of wrongly dialled numbers, engaged or withdrawn services and all the other announcements that would otherwise need constant human attention.
Speech synthesis units are being incorporated into cars like the Maestro as part of the standard instrumentation.
As well as being something of a sales ploy the synthesiser does provide warnings that the driver can hear and act on without having to take his or her eyes off the road.
In the home computer market speech synthesis is generally used to enhance games; scores are read out and warnings of enemy attack can be given verbally leaving the player free to concentrate on the tactics of the game.
Finally, on the educational scene there are devices like the Texas Instruments Speak and Spell which recites a word that must then be spelt correctly and foreign language dictionaries that pronounce the words.
A number of add-on units are available for the Spectrum which, almost without exception, use the allophone method of synthesis.
Although this is by far the most flexible way of tackling the problem, the results depend on the quality of the software and the ability of the user to code English sentences into phonetic strings.
The commonest chip used in allophone synthesisers is the General Instruments device and so, in theory at least, all the available synthesisers should be capable of the same output quality given equal skill in coding.
The alternative method, as epitomised by the National Semiconductor Digitalker chip, is that of stored compressed speech.
Here the quality of output is assured but the user is strictly limited in the number of available words.
Tricks can, however, be played with this system to increase the vocabulary by joining bits of words together.
Speech recognition, on the other hand, as featured in science fiction and typified by the HAL computer in 2001—A Space Odyssey is unlikely to appear for many years yet, if ever.
The prime reason for this non-appearance is that, in English at least, many words can sound the same but have meanings dependant on the context that they appear in.
The processing power needed to solve this problem is simply not available at a reasonable price, or in a compact enough form.
There are systems in research laboratories which approach this goal but increasing the number of speakers who can be recognised reduces the number of words that can be accepted at any one time.
Typically a multi-speaker recognition system, the only sort that is going to be acceptable to users, will allow between 20 and 30 words to be recognised at a time with a success rate of around 85 to 90%.
Speech recognition is usually tackled in one of two ways.
The obvious way is to simply feed all the speech through an analogue to digital converter and use the computer to perform all the hard work.
Unfortunately this method has a number of drawbacks, notably the time taken to perform the analysis.
For speech recognition to be of any real use, however, the computer must seem to ‘understand’ the speech as fast as another human, the number crunching approach rarely achieves this.
The second method is to use pre-processing.
Rather than analyse speech mathematically it is possible to do much of the work electronically.
What is then delivered to the computer is already processed information about the frequency content, pitch, energy and so on.
Because all this electronic processing is done at the same time, the original speech signal is fed to all the circuits, the analysis is almost instantaneous.
Once information about frequency content, pitch, energy, etc has been extracted from the speech input, regardless of the method, the actual recognition is performed by comparing the current set of figures against a number of possibilities stored in the computer.
The words that are to be recognised are spoken into the system one at a time and the resulting information is stored as a ‘library’.
Ideally this will be a continuous process with the library being updated by every new speaker.
To recognise a spoken word the computer must match the pattern of information from the input with one or more of the models stored in the current library.
In many cases a number of possible matches will be found as parts of other words will match the input pattern.
At the end of the search one word should stand out as being more perfectly matched than any of the other possibilities and this is the one which the computer will ‘recognise’.
As most of the time taken is used up in searching through the various models the speed of the system will be a trade-off between the range of speakers it can understand and the number of words in the vocabulary.
Certainly there are commercially available recognition units which can be plugged into home computers but they are very unsophisticated.
Systems like ‘Big Ears’ use much of the computer's processing power to recognise just a few words spoken by one person.
What is needed before speech recognition can become really useful is an ability to recognise words spoken by any person, regardless of dialect or accent.
The limiting factor, at this stage, is the amount of memory available to hold the models, one possibility is that of using a video disk to hold a ‘standard’ set of models.
It is getting harder by the day to isolate the various segments of the electronic publishing industry into neat little compartments.
Whilst TechDoc is certainly one of the older and more established of these compartments it is undergoing rapid change as the vendors break away from the dedicated hardware platforms of their recent past.
Not only is there change in the hardware but the revolution in the low-cost market, desktop publishing if you will, has spurred the customer to demand more in terms of typography and flexibility, not to mention compatibility.
There are, to my mind, a number of specific functions that a TechDoc system must provide if it is to be considered a member of the fraternity.
These requirements exclude virtually all the current desktop publishing products for reasons that will become immediately obvious.
However, it should not be assumed that these low-cost alternatives cannot deliver the same, sometimes better, results when used in conjunction with other software.
The whole essence of a TechDoc system is that it is an integrated product which allows a single individual to complete all the tasks necessary to create the final document.
Within a single environment it should provide, at the very least, word processing, graphics and composition facilities and, ideally, operate in a consistent manner across all three.
Additional, and often standard, features will include charting, graphing, tables generation and last, but by no means least, the capability to handle mathematical or scientific material.
Whilst all these functions can be provided in a batch environment the real breakthrough came when WYSIWYG arrived.
Now the author can see what the document will look like as soon as the text is typed.
However, again unlike many desktop publishing systems, the main difference in the TechDoc world is that the format of the finished product is entirely separate from the content.
The application of previously defined style or property sheets to large amounts of text allows it to be rapidly converted from one form into another, merely by adjusting the rules written into the style sheet.
This may be a simple change of typeface or emphasis or a complete restructuring of the document from single to multiple column.
The more advanced desktop publishing packages have begun to pick up on this requirement but few can manage either the length or the revision information that the typical TechDoc user needs.
Indeed, it is in the provision of revision management that most TechDoc software fails.
This, it seems, is the last stronghold of mainframe publishing where, essentially, the document is regarded as a data base and every change made to that information is recorded.
For the worlds of high technology engineering such as aerospace and defence this sort of control is not only important, it is virtually mandatory.
Only now, however are these sorts of controls becoming available on workstation-based products.
It is interesting to note that the quality of document composition has, until very recently, been pretty average with systems only possessing basic Hroutines and little control over page breaks and control over what, if anything, can ripple over from page to page.
Some systems still rely on a batch pagination method while others, like Interleaf, do the whole thing on the fly.
A happy medium is one which re-calculates the pages in real time but can suppress the display if required to avoid the annoyance of a constantly changing display.
However, the most interesting systems from a technology point of view are those that are migrating off the engineering workstation and onto the personal computer.
In this area we have Frame Technology's FrameMaker which already runs on the Sun 386i and will shortly appear on the Next and Macintosh II platforms.
Agfa's implementation of Omnipage, Agfa Press, also runs on this platform and supports a wide range of PC and Macintosh applications as well as the more conventional workstation ones.
Interleaf is also active with PC and Macintosh versions of its Technical Publishing Software and NBI has the recently launched Legend product which is only available on PCs but is slated to move onto the Macintosh soon.
The other emerging trend is to provide PC-based systems which can either contribute to or make actual use of the documents produced on the main system.
Both Interleaf and Frame Technology have PC-based software which allows documents to be viewed and this process is an active rather than passive one.
By building Hypertext capabilities into the documents it is possible to select areas of a drawing, for example, and have the relevant text displayed or vice versa .
In the case of both Interleaf and Xerox's Documenter the companies have also recognised the importance of being able to accept textual or graphic information from other sources and this is something that we would expect to see other vendors follow suit on.
But, perhaps, the biggest single difference between the work of the TechDoc system and the more insidious desktop publishing package is that the former are designed to be used in conjunction with other systems.
The ability to link systems on either a local or wide area network has always been taken for granted in the world of engineering workstations.
Users of desktop publishing systems looking to provide the same interconnectivity generally find that, at best, the software will only recognise the network as a path for transferring files and, more usually, that it simply won't work at all .
Even Xerox's Ventura, which is the closest thing yet to TechDoc in a desktop publishing package, is only just beginning to tackle the problem of networking.
The question of which system to choose is a vexed one.
Perhaps it would be better to look at those which other vendors have selected and market as their own under OEM agreements.
Here the obvious winner is Interleaf who's Workstation Publishing Software is marketed by IBM, DEC, Apollo and Siemens while the Technical Publishing Software product is also handled Kodak under the KEEPS badge.
as if that weren't enough, IBM also markets a reduced feature version of the TPS product, Interleaf Publisher for its range of 80386 computers.
A Macintosh version of Publisher also exists but this is marketed by Interleaf itself.
Frame Technology also seems to be rapidly building on its growing acceptance with Next, Hewlett-Packard and Hell-Xenotron all adopting it as an OEM product.
The only other vendors to show any real OEM activity are Omnipage and Xyvision.
The former struck deals with AT, Computervision and Hewlett-Packard.
However, the first two arrangements have failed to materialise and the company is now effectively part of Agfa who introduced the product under its own Agfa Press label at the end of November.
Xyvision have sold source code rights of their Integrated Publishing System to Linotype who launched the Series 3000 at this year's Electronic Publishing Show.
We would expect Linotype to develop the product along the lines of their traditional high quality typography business and there is no guarantee that the product will remain compatible with its original version.
There are other interesting systems, too.
Xerox's Documenter, essentially a single 6085 workstation running ViewPoint with a dedicated page printer, has recently been brought back into the fold through the introduction of a low-cost local area network.
This is rather ironic given that Documenter was created by taking the XPS701 system and extracting a single workstation as a stand-alone product…
If it has one significant advantage, other than its relatively low cost, it is in its ability to grow back into the complete XPS system should the user ever require such capabilities.
Another potentially exiting product is NBI's Legend.
This is probably the only PC-based software package that comes close to emulating the integrated environment of a workstation.
It includes, apart from the composition elements, a full-feature word processor, graphics and network awareness.
At the moment it is still a new and unproven product but it could well represent the next generation of TechDoc software, at least so far as the corporate publisher is concerned.
A similar product is Advent's 3B2.
This is even less proven that NBI's and, unlike Legend which uses Microsoft's Windows as the basis for its integration, provides its own environment.
Perhaps it is safe to say that the minimum requirements must be that the product runs on standard platforms while allowing data created within other environments to be imported and incorporated.
Ideally, the product should also run on a range of platforms so that the user is not tied to a single source of hardware.
Finally, of course, it is important that the product actually achieves both what you set out to do and while being capable of expansion to meet future requirements.
Unlike the desktop publishing market where the capabilities of both the product and the platform are clearly stated, the world of TechDoc is much less defined.
The cost of making a mistake, however, is likely to be many times greater
It isn't often that you hear a genuine story of a tail wagging the dog but spreadsheets and personal computers are just such a case.
The tail, in this case a program called VisiCalc developed by Dan Bricklin and Bob Frankston, was directly responsible for the sale of many thousands of Apple II computers, one of the first desktop micros.
The reason for this quiet revolution was simple, the combination of hardware and software provided a management tool that had never been available before whilst being sorely needed in a world of ever increasing financial pressures.
Describing the operation of a spreadsheet is never easy.
Each user does things in their own particular way and it is because of this flexibility that the spreadsheet program has achieved such widespread success.
Imagine you are going to calculate the running costs of a car, a whole fleet of cars if you wish.
Using any of the traditional methods of cost analysis you will need a substantial quantity of paper, a good financial calculator, a ruler for drawing up the forms and a quiet corner to get on with it.
Once the tables have been calculated, however, you find that the insurance rates have changed, petrol has gone down and tax thresholds are due to be altered in the coming budget.
Your only option, pre-spreadsheet, is to do it all again!
With a spreadsheet you can alter values, constants or the formulae relating them at will and the entire sheet will reflect these changes, instantly.
Effectively the spreadsheet consists of a large, anywhere from 65,000 cells to 2 million or more, sheet of squared paper.
You can type any kind of information into a cell; text, actual values, formulae relating to constants or other cells and so on.
Any individual cell or group of cells can be related to any other cell, just as in your hand created version, yet with a speed and flexibility that can, at first, be hard to believe.
An often-used phrase in spreadsheet circles is ‘What if?’ and, if you've ever wondered what would happen to your profits on a certain operation if your costs went up by 5%, you should know only too well the problems in working it out by hand.
Once a spreadsheet model is established such questions can be answered in a few seconds.
It would be wise to note at this point that there can be pitfalls.
One major American corporation became so enthralled by the spell of its spreadsheet model that it lost touch with reality and some $80M disappeared!
Not, I hasten to add, through fraud but through an error in part of the model.
Fortunately there are ways of checking models and a number of programs, called auditors, exist which look for anomalies in the equations used.
It is rarely, if ever, the fault of the software that these errors creep in.
A simple mis-keying of a complex formula can produce errors that are hard to spot but which subtly change the balance and so disrupt the model's accuracy.
Whilst VisiCalc has all but disappeared from the scene it once set there are a host of new and vigorous contenders for the crown.
Prime amongst them for the IBM PC and its compatibles are 123 from Lotus Development, Multiplan from Microsoft, Smart from Innovative Software and Supercalc from Sorcim.
For the Apple Macintosh the runaway winner appears to be Microsoft's Excel as Lotus have been unable to repeat their success with 123 in Jazz.
A feature of growing importance in the software world is integration.
Some packages offer spreadsheet, data base and word processing facilities in a single program; Lotus's Symphony and Ashton Tate's Framework being typical examples.
Much emphasis is placed on the ease with which data can be passed from one program to another, information from the customer data base can be used to update a spreadsheet model for instance.
The price the user pays for this approach is not just financial, programs of this type require large amounts of memory and hard disk systems to operate properly.
A much better approach is modular software where a number of packages from a single supplier all share a common data format allowing information to be transferred easily but without requiring vast amounts of memory.
Examples of this approach are typified by the Smart system from Innovative Software, Open Access from SPI and Xchange from Psion.
Of equal, if not greater, importance is the ability to read spreadhseet models produced by other packages.
In an ideal environment all the people within a single organisation would use the same software but as the ideal is seldom achieved it is worth checking to see if a package can at least handle the industry standard DIF (Data Interchange Format) file format.
An ability to understand Lotus WKS format is also valuable simply because more people use 123 than anything else!
A spreadsheet program doesn't replace the traditional accounts package as a means of keeping track of where a business spends its money but it be a powerful tool for preparing analyses or projections.
Most of the current generation of spreadsheets provide a facility for creating graphs and charts based on the information held in the model.
Typically these will include bar charts, pie charts and line graphs although numerous other types can be prepared.
In an integrated software system the spreadsheets capabilities can also be applied to information stored in a data base, indeed some packages, Lotus 123 for example, treat data bases exactly like a spreadsheet.
Keeping things simple is often the best bet, an investment of both time and effort is required to learn anything new, so diving in at the deep end with one of the full-blown integrated packages may cause more disruption than it's worth.
Far better to invest in a simpler program and find out just what it can do for your business.
After all, the facilities are basically the same regardless of the price and the additional features may be of no real use at all.
Many of the older packages were written in the days when memory was a pricey commodity and only allow small models to be created.
This too can be a blessing in disguise as those inevitable mistakes are easier to spot when the model is smaller
It may come as something of a shock to discover that up to 10% of your company's turnover is actually being diverted to running a second business.
A business that you may never have considered yourself involved in; publishing.
If we define publishing as the production of information in a printed form you may begin to realise just what I mean; price lists, company reports, catalogues, advertisements, newsletters, memos, the list gets longer the more you think about it.
Just because the distribution of this information may be restricted to your own staff or a close circle of customers doesn't mean that you shouldn't pay attention to its style or presentation, far from it.
But, until recently, to produce a professional looking result meant employing professionals to look after the work for you.
Over the last two years, however, it can hardly have escaped your notice that a new software application called desktop publishing has begun to appear on the scene.
This, according to the glossy advertising material and high-tech television commercials, could solve all your company's presentation problems.
The reality of the situation is a little different!
Whilst desktop publishing software has the power to manipulate text and graphics created using conventional business software it is, thankfully, totally incapable of controlling the presentation and style without some degree of human intervention.
Somewhere in the process, hopefully at the beginning, the design rules that will be followed have to be established, either as a written specification or electronically in the form of a style sheet or template.
Surely the whole point of desktop publishing, I hear you cry, is to reduce our dependence on skilled people outside the company.
That is true but unless you invest in the time to capture those skills, either by training your own staff or by hiring an external designer to show you how it's done, it is almost inevitable that the quality of your published material will go down, not up.
A fact that one or two companies have learned to their cost.
Desktop publishing systems offer business the chance to reduce their dependence on external agencies such as design houses, PR companies and advertising agencies.
They certainly don't, at today's level of sophistication, eliminate that dependence.
Nor, as is often believed, do they remove the need for traditional print technology.
The ink on paper process is still essential if you intend to produce quantities rather than single copies.
Just as the introduction of word processing made it easier for people to produce and maintain large documents so desktop publishing makes it easier for those same people to produce professional looking publications.
However, where word processing is a simply more efficient form of typing and requires no great understanding of design or layout, desktop publishing demands that these things be understood.
Ignoring that difference could be one of the worst mistakes you make
