The Flight From Mind
Howard Robinson
There is an account of the mind-body problem which could, with some oversimplification, be described as the currently fashionable one.
According to this account, the mind-body distinction as we know it was invented by Descartes.
He it was who conceived the idea of identifying mind with consciousness and of claiming that consciousness and its contents are radically different sods of things from bodies and their properties.
The mind is a sort of arena in which private objects are viewed: all our experience is, ultimately, confined to this arena.
Descartes, so the story goes, reached this conception because, unlike his predecessors, the Aristotelians, he was obsessed by epistemological questions — that is, questions about what we can know and how we can know it.
He thought that the only things of which we could be really certain were things of which we were directly aware, that is, things in our own minds.
The empiricists, although they may not have taken up Descartes' idea that the mind is an immaterial substance, followed him in treating the contents of mind as objects private and internal to the individual and different from physical objects.
This conception of the mind is now almost universally regarded as disastrously wrong, for two reasons: first, because it creates a dualism of mind and body and second, because it is held to create insuperable sceptical problems.
The dualism is deemed disastrous because it prevents us from having a unified conception of the world built around the natural sciences, and because it leaves the relationship between the mental and the physical an insoluble mystery.
The scepticism follows because if we are confined in experience to the contents of our own minds alone, it would seem to be impossible that we should ever come to know anything about — or even come intelligibly to think about — things outside our own minds.
The programme of many modern philosophers, therefore, has been to develop a conception of man and his mind which either disposes of or downgrades the inner, private arena, making the function of mind essentially a part of the public and physical world.
Once this is achieved — and this, it is held, can be done by some sort of physicalist theory of mind with strong behaviourist elements — then most of the insoluble problems of early modern philosophy disappear.
I want to defend a radically different picture, which takes a much  broader historical perspective.
This alternative picture involves denying that there is a coherent materialist alternative to the Cartesian ‘private theatre’ view of the mind; but it also involves placing the attack on the Cartesian picture in a wider context.
From the point of view of those who have a high doctrine of the mind, the Cartesian developments of the seventeenth century were ambiguous.
The concentration on the subjective nature of experience made clear the logical privacy, and hence non-physicality, of sense experience in a way in which it was never made clear within the classical and scholastic traditions.
The earlier traditions had focused not on experience as the key element in mind, but on intellect and thought; it was this that made mind special and different from anything physical.
As I shall explain in the next section, this earlier privileging of intellect was intimately connected with resistance to nominalism, and, in the seventeenth century nominalism triumphed.
The emphasis on the mentality and immateriality of sense experience was associated with the denial that there was anything special about intellect.
Even whilst developing the modern immaterialist notion of consciousness, the eighteenth-century empiricists and others were attacking the dignity of intellect and assimilating it to sensory activity by treating thoughts as mere images.
As well as being a defence of mind, therefore, the early modern philosophy, through its nominalism, was also an attack on it.
And, in certain important respects, the general form of this attack is preserved in contemporary physicalist theories.
Like the physicalist attacks on the privacy of subjective experience, these attacks on intellect are self-defeating, in that they end up denying the very realities they are trying to explain.
What I hope to show is that the attacks on the reality and irreducibility of both subjective experience and thought leave one with no contentful conception of the world.
The flight from mind in respect either of its intellectual or sensational aspects would be disastrous, but the currently fashionable flight from both leaves us with no world at all.
In the Phaedo , Socrates praises Anaxagoras for saying that the world must be explained by reference to mind, and then criticizes him for not acting on the principle that he recommends.
Most pre-Socratic philosophy had been a form of primitive natural science, explaining everything in terms of the physical elements.
By contrast, the metaphysical question of what the preconditions are for the world's being accessible to thought was uppermost for Plato and Aristotle.
This is explained via the role of form in the world.
The important thing about form, in either the Platonic or  Aristotelian senses, is that forms are the sort of things that can be thought, or apprehended intellectually.
There is, in common sense, something close to a paradox which generates the problem of universals.
This problem dominated philosophy from Plato until the seventeenth century.
On the one hand, it is natural to think of the world outside mind as consisting solely of particulars: the only things that could be general would be ideas.
But if ideas are to fit the world there must be something which answers to that generality.
According to Plato, that generality is found in a pure way in the Forms, and derivatively in particular physical objects because they participate imperfectly in the Forms.
For Aristotle, forms are in objects and are themselves particular, though they are by their nature potentially universal, becoming actually so when they are apprehended by the intellect.
The disturbing thought that motivates both theories is that, if the world is to be intelligible, it must be mind-like, in the sense that generality — the feature of thought, concepts and meanings — must in some way, run through the world itself.
A world that was,per impossibile , purely particular, in the sense of not allowing forms or universals to be an essential component or determinant of it, would have nothing which intellect could grasp.
The reason for this is straightforward.
Human thought is something essentially expressible in language, and language is possible only if there are predicates as well as names.
But predicates are essentially general.
Consider the sentence ‘John is tall’.
For this sentence to express something, ‘John’ must refer to a unique individual, but ‘tall’must express a feature that is general, that is, that many different things might possess.
If this were not so, and all statements simply joined names that referred to individuals, nothing would be said about those individuals.
But if a statement such as‘John is tall’ is to be true, then the predicate ‘is tall’must latch on to the world, just as ‘John’does.
So there has to be something in the world answering to the general predicate, just as there is something answering to the name.
This thought casts the world in a profoundly different light from common sense in its materialistic moment; and much of metaphysics can be seen as a response to it.
Aristotle was the first to try to naturalize the veins of generality that must structure any intelligible world, by saying that forms in things were individuals, not universals.
The controversy surrounding the interpretation of Aristotle's conception of form is unending, but, on all interpretations, his objective is to give forms as great an affinity with particulars as is possible, consistent with their retaining a sort of generality which is, so to speak, released in the intellect when they are thought.
Something that was not form, but was only matter, could not become general in this way and could not answer to the generality of  the concepts with which we think.
The naturalistic instinct has been to claim that mind somehow creates generality in a sense stronger than that which Aristotle allows; it does not merely release generality from its potential state in matter, but fabricates it.
The mind puts together certain things and deems them to be of the same kind.
The medium in which the mind fabricates generality is language.
This vision lies behind nominalism, which claims that it is the mind's capacity for creating general words that creates the illusion of generality in the world itself.
But the problem of generality has two locations.
The first, about which I have mainly been talking so far, is the generality, or potential for generality, of things in the world.
The reductive instinct is to explain this by reference to the generalizing capacity of the mind.
This leaves generality as a real capacity of the mind.
Philosophers have often been content to assign to the mind features that they are unwilling to ascribe to the physical world.
Most empiricists, for example, have been prepared to do this with secondary qualities, such as colours, sounds and smells, which, they believe, science could not allow to the external world.
In so doing, they claim that it is not just secondary qualities that are confined to the mind, but, with them, the whole vivid force of the world-as-we-perceive-it,-what some philosophers call the manifest image of the world — which is intrinsically bound up with the secondary qualities.
David Hume went further, transferring causal power from the world of objects to the mind, making of it a tendency of the mind to pass from the thing we call ‘the cause’ to the one we call ‘the effect’.
But someone committed to a thorough-going naturalism is no more prepared to allow to the mind mysterious properties than he is prepared to allow them to matter: for the thorough-going naturalist, after all, mind is no more than a manifestation of matter.
The nominalist impulse, therefore, which originates from the attempt to make generality in the world a creation of mind — thus allowing the extra-mental world to consist only of particulars — eventually leads to trying to explain the powers of the mind entirely in terms of the work of particulars.
This move from nominalism about the extra-mental to nominalism about mental acts can be seen in the development from Descartes to Locke and Berkeley, or, perhaps, in the contrast between such continental rationalists as Descartes, Malebranche and Leibnitz on the one hand, and British philosophers from Bacon and Hobbes on the other.
Descartes believed firmly that universals were formed in the mind and that ideas possessed ‘objective’ and ‘formal’reality; that is, that it was an irreducible feature of ideas that they were able to be about a class of objects.
Descartes is true to his radical dualism: everything that is a mark of mind is withdrawn into the mind, leaving the external world in atomistic darkness.
But mind remains truly special.
The materialist Hobbes, by contrast, denies that universality is really found even in the mind:
This word universal is never the name of anything existent in nature,nor of any idea or phantasm found in the mind [my italics], but always the name of some word or name; so that when a living creature, a stone, a spirit , or any other thing, is said to be universal , it is not to be understood that any man, stone etc., ever was or can be universal, but only that the words, living creature, stone, etc., are universal names , that is, names common to many things; and the conceptions answering them in the mind are the images and phantasms of several living creatures or other things.
(Concerning Body , Molesworth's English Works of Thomas Hobbes , vol. 1, p. 74; my italics)
But, by a tragic irony, it is not a materialist who most influentially encapsulated nominalism about the mind; it was the idealist Bishop Berkeley.
Hume described Berkeley's attack on abstract ideas as ‘the most important development of late in the republic of letters’.
The purport of that attack was to prove that generality could never be an intrinsic property of a mental content.
Berkeley's reason for thinking this was that he believed mental contents to be mental images, and there cannot be a general image.
It never seemed to occur to him that a general idea might be an entirely different sort of thing from an image.
Ideas, according to Berkeley, are particulars whose significance is explained by saying that they stand for the things they represent.
This naturally prompts the question what it is for one purely particular object to stand for another.
Specifiedly general objects, such as forms and universals, by their very nature stand for the many things which are instances of them: a single particular may be in a variety of relations — most obviously causal, spatial or temporal -to others, but the nature of a ‘standing for’ relation is obscure.
At first sight this might not seem to be a serious problem; one thing stands for others if it is used or taken as representing them.
But this only restates the problem.
Using or taking as representing is a mental act, and it presupposes that the mind has the power of seeing generality in things, by seeing the class (or form) in the particular.
It is exactly this power that the nominalist is trying to analyse and explain.
If one is to avoid this simple circularity, then  one must explain standing for in terms of some natural relation between particulars.
Berkeley's theory gave rise to the development of modern externalist theories of mental content.
By ‘externalist’ in this context I mean any theory which denies that a mental episode has any meaning-content intrinsically, and affirms that its content consists in some external relation to other things.
The first expression of this was associationist psychology.
At its simplest, associationism is the theory that a mental content has the meaning it does because of the things that tend to follow, or precede, it into the mind.
So the word ‘red’ means red because thought of the word tends to be succeeded by a mental image of the colour, or vice versa .
This can be expressed in Hume's terms of the tendency of the mind to pass from one to the other, but one must be careful how one interprets such a tendency.
It is tempting to think of it as a felt tendency, so that one is somehow aware of where the mind is going.
This will not do, for it is no different from saying that when one experiences ‘red’ one thinks or conceives of the colour, whereas the point of the theory was to explain what such thinking, or conceiving, is.
It is similarly tempting to think of the colour image as hovering in the background, somehow anticipated by the mind; but this is a metaphor, for the image either is or is not in consciousness.
And, contrary to Hume's contention, being very dimly in consciousness is not the same as being thought of.
The tendency of the mind to move from one thing to another has to consist in the straightforward fact that one thing usually follows, or is caused by, the other; the tendency or association cannot be thought of as some experienced feature of the situation without reviving the original situation of having an unanalysed conception of the mind's ability to reach out and apprehend things.
So the meaning of a sign consists in the bare fact that it stands in an external causal relation to that which we say it signifies.
From the point of view of the experiencing subject, the meaningfulness is not something of which he is conscious; all he experiences is, first the word ‘red’, then a mental image: there is nothing that could count as his internally and introspectably associating them which does not reintroduce the mysterious generality of thought.
It does not help the associationist to press the concept of resemblance to his aid.
It might seem that it would, because it might seem very natural to think that one red thing or image might be taken as standing for red things in general because of its natural resemblance to the other members of the class, this constituting the most fundamental sort of association.
But resemblance cannot explain how a thinker could experience one object as standing for another; for how could the fact that a particular  datum is similar to other things mean anything to a thinker unless he experienced it as being like many others — that is, unless he grasped it, not just as a particular but as an instance of a kind?
But this is the very ability for which we are trying to account.
If we are to abide by a pure nominalism or particularism, we are forced into externalism, and this is vicious.
It is vicious because, as I have just argued, the external relation that constitutes the meaning of the mental content is not something that the subject himself can apprehend: it can only be constructed from a third-person perspective.
The reality of meaning therefore, would only be accessible to some idealized third person who was able to observe the relation between the particulars.
But there never could be such an observer — at least not if his thought-processes were to be analysed in the same way as ours — because his thoughts about the relations of the particulars would themselves be just a succession of particulars whose relations, which give them meaning, were not directly accessible to him.
Associationism is long dead as a theory of thought, but externalism remains as a feature of most of its naturalistic successors, because, by virtue of their naturalism, they can find no space for intrinsic generality of mental contents.
The problem for the associationalist is exactly mirrored in those theories of thought and mind inspired by computers and artificial intelligence.
The human mind — which, from this viewpoint, is the brain — is said to work on the same plan as a computer, with operations being carried out on physical symbols.
The question is, ‘what gives these symbols meaning?’
The answer is that, as with associationism, their meaning comes from their relations to things external to themselves.
Their relations to one another determine the syntax (that is, the grammar) of the language they constitute, and their causal relations to the external world determine their semantics (that is , what they are about or refer to).
These causal relations are essential to what they mean: without semantics a language is an uninterpreted formal language.
But if we think of the conscious subject as located within, or identical to, the brain, then external relations are beyond his gaze.
John Searle has compared the computational view of mind to an Englishman who has no understanding of Chinese processing Chinese symbols according to rules which correspond to the grammar of Chinese: what he deals with may be meaningful Chinese sentences, but he is none the wiser.
Only an idealized observer could see both the inner processing and the causal relations of the symbols to outside objects that give them meaning: no one could actually be that idealized observer, because each observer is confined to operating on the symbols that are within  his computational machinery, and this excludes their external causal relations.
There is a tendency of protagonists of the computational theory of mind to boast that they are restoring the Aristotelian emphasis on cognition and thought, and unseating Descartes' modernist emphasis on consciousness.
One such protagonist has recently gone so far as to claim that Aristotle's Phantasmata — the mental images that are involved in most or all mental activities — are identical with the symbols on which computational procedures are carried out.
This approach sees classical and ultra-modern theories as constituting a sound tradition from which the Cartesian emphasis on consciousness constitutes an unfortunate aberration.
I have tried to sketch in outline why I think this to be wrong.
Far from being of a piece with classical theories, computational theories share with early modern ones the nominalism that made them oblivious of what was important in the classical tradition: namely the irreducibility of thought and universals.
The problem that consciousness sets for the materialist is well known.
Imagine a scientist in the distant future who knows everything about the mechanism and neurology of vision, but who is blind from birth.
That there is something he does not know is shown by the fact that if he were to gain his sight, he would come to know something that he previously had not known.
This might be characterized as ‘what it is like to see’ or ‘what things look like’or, most especially, ‘what colours are like’(that is, what they look like — there is no difference in their case).
No amount of unsighted knowledge of neuronal activity or light wave-lengths could amount to this.
The same point can be made in a slightly different way.
Call our blind super-scientist ‘BS’ and an ordinary sighted subject ‘V’.
BS is supposed to have complete scientific knowledge of V and his physical environment when V sees: yet BS does not know what it is like for V to see, what colours look like, etcetera.
As BS knows everything relevant about the physical state of affairs, the things that he does not know about are not physical states of affairs.
Since these states of affairs are of the essence of human perceptual consciousness and, therefore, of the human mind, it must follow that there are non-physical states of affairs essential to the human mind.
So a materialist theory of the mind is false.
The most primitive physicalist response to this argument is to  deny the claim that there is anything about the mind that BS does not know.
All that BS lacks is an ability to respond directly to stimuli of certain sorts: V knows no more than BS, he can simply do something BS cannot.
BS is like a man who knows all about swimming, even to the point of being able to train the Olympic team, but who cannot swim himself, and V is the man with the normal talent for swimming.
I think that it would be true to say that, nowadays, most materialists want to avoid theories that are as nakedly behaviouristic as this, and want to accommodate the common-sense intuition that something inner and introspectible is missing in the blind or deaf, for example, in addition to their lost capacity to respond.
On the other hand, materialists seem to be prevented by their materialism from allowing that there is any relevant fact that BS does not know.
The way that most materialists try to reconcile their flight from behaviourism with their materialist world picture is to say that when V sees something, and BS observes V's brain, BS knows everything about V's mental states that V himself knows, but that he knows about it in a different way .
It is this difference of way which constitutes the difference of ‘feel’ in their experience.
This reply sounds very plausible, until one reflects on it; and then a serious difficulty emerges.
For a physicalist, a mode of access is just a physical process, so any mode of access V enjoys should, if physicalism be true, be available to BS.
Differentiating modes of access seems relevant only because of the covert assumption that different ways of knowing feel different — that is, what it is like to have those experiences is different.
But this brings us back to the initial problem, which was precisely to explain how materialism could accommodate such a ‘feel’.
We cannot, therefore, leave it as an irreducible fact about different physical processes that they ‘feel’ different.
In fact, the ‘mode of access’ argument is ambiguous.
It might be interpreted as saying that V has a mode of access to his own brain different from any modes of access to V's brain available to BS; or that V has a different mode of access to the external world, and that this constitutes the difference between him and BS.
It is impossible to deny that V has a different mode of access to the external world from BS, for V can see and BS cannot.
But the question is how this constitutes a subjective difference.
One can then choose to say either that it constitutes the difference by virtue of having a particular internal ‘feel’ associated with it, or that it is itself the difference,simpliciter .
The former simply reinstates the problem of the inner ‘feel’.
Within the ‘mode of knowledge’ framework, the ‘feel’will be explained by the special mode of access to one's own  brain.
That this will not do is what I have just argued.
The second response, that the difference consists solely and simply in a mode of knowledge of the external world, without invoking any internal and introspectible ‘feel’, requires one to explain perceptual experiences with different modes of access without reference to a subjective component.
As far as I can see, the only way to do this is to adopt a behaviouristic approach to this knowledge and characterize it as an ability to discriminate visual objects.
To take this road is to resort to what I earlier described as the ‘most primitive physicalist response’ to the problem, which involves denying that there is anything about the nature of experience that BS does not know.
Michael Tye, in his recent book The Metaphysics of Mind (Cambridge, 1989), has a way of dealing with the difficulty which, if it worked, would solve the materialist's problem.
He combines the view that what it is like to see, for example colour is something BS would come to know on gaining his sight, with the view that what it is like to see, for example, colour is not a further fact in addition to the physical facts about the brain (p. 146f).
So it is something further, without being a further fact .
At first sight this looks like an uninteresting stipulation about how to use the word ‘fact’— uninteresting because the anti-materialist could as well state his case using some such term as ‘feature’ or ‘aspect’, and it is difficult to see how, once having allowed that there is something called ‘what it is like to see’which one only learns by seeing, one could refuse to describe this as a feature or aspect of mental life.
(Tye does compare this learning to learning to balance a pencil on your nose, but if that comparison is made to do any work, Tye's theory will simply be a behaviouristic one, and he usually seems to want it to be more than this.)
Tye, however, does have an argument for his conclusion that what is extra is not ‘really’ something extra.
I think the argument is that if we call the nature of the experience ‘R’, and if we concede the materialist claim that R is a brain state, then in knowing the brain state the blind scientist knows R, though not what R is like.
Because BS knows all the facts about the brain state, and the experience just is the brain state, then what the experience is like must be something other than a fact about the experience.
The argument transposes, however.
Since merely knowing the brain state does not reveal what the experience is like, and since what the experience is like , if it is a reality at all(which Tye does not dispute), must be a fact about the experience (or a feature or aspect of the experience, which will do just as well), it follows that the experience is not a brain state.
There is one well-known materialist account of different modes of knowledge that might seem to be useful here in preserving the  ‘mode of knowledge’ approach against the need for the more drastic behaviouristic alternative.
Physicalists of the 1950s and 1960s were worried by the following problem.
Experiences, they argued, are identical with brain states; but when someone is conscious of his experiences he is not conscious of his brain as such: it takes modern science to tell us that consciousness is a state of the brain.
They therefore concluded that in consciousness itself we are aware of the brain topic-neutrally ; that is, not as the brain, but in some way that is neutral about the nature of the object of our consciousness.
Thus, one might characterize one's grasp on the experience of seeming to see a red object as something is going on in me (I don't know what it is) which is like what goes on when a red object is acting on my eyes ; or…like what goes on in me to make me behave in a red-object-appropriate way .
It takes science to come along and tell us that what is going on under these circumstances is a brain process, let alone to tell us which brain process it is.
All consciousness does in its own right is to tell us that it is something internal which fulfils a certain role.
But even if treating our awareness of our own mental states as topic-neutral plausibly explains why we are not aware of our brains as such when we are aware of our mental states, it does not explain why knowing fully about the brain does not include knowledge of the nature of experience.
Topic-neutral knowledge is weaker than, and hence is entailed by, full knowledge, though it does not entail it.
So, if the blind scientist BS knows that V is in brain state B and that B is the state usually brought about by experience of a red object, then he knows that V is in some state or other of the sort usually brought about by red objects.
So, if he abstracts from his knowledge of what the brain state actually is, he can form the same conception of experience as that had by the subject of the experience.
In brief, topic neutrality was invoked to explain why, within the materialist scheme, consciousness of our mental states is not sufficient for knowledge of them as brain states: what it cannot do is explain why knowledge of brain states is not sufficient for knowledge of their nature as conscious states.
A rather similar, and equally mistaken, line of thought which might appeal is as follows.
It might be thought that the subject's apprehension of his own brain is more immediate and more holistic than any external knowledge, however complete, and that this explains the experiential difference between the two kinds of knowledge.
The scientist has essentially separate pieces of information, whereas the subject has a sort of Gestalt .
Once again, this explanation shows a failure to grasp the radicalness of the physicalist perspective.
A Gestalt is a mode of perception of a  group of objects — say of the dots in a printed picture — so that they are seen as one thing.
It would make no sense to say that the dots in the picture had a Gestalt of themselves, but to apply this model to the brain and experience would be just like that; for, if the experience just is a state of the brain, then there is no way in which the character of the experience can be explained as the result of some perspective on the brain.
Nor, more abstractedly, could it be the result of a perspective on the informational content of the brain; for, in either case, the perspective would have to be the occurrence of some further brain or informational state and to both of these the scientist has complete access, and the problem reoccurs.
If what I said above is correct, failure of the ‘mode of access’ argument forces the materialist to deny that BS lacks any knowledge and to adopt a behaviourist theory.
When a behaviourist approach is employed, it is not applied only to perception, but to all cognitive states.
Remembering that philosophers of the seventeenth and eighteenth century had already assimilated thought to perception, this is not surprising.
But this historical reason is not the only one, for, if the project is to develop a materialist theory of the mind in general, thought requires a materialist analysis as much as perception.
It is in its form as a general theory of cognition that the behaviouristic approach is most clearly refutable, but from the general refutation we can refute its application to perception.
The behaviourist theory of knowledge says that for someone, S, to know or believe that some proposition p is true is for S to be disposed to behave in some way which is supposed to be appropriate to the world's being as p says.
The problem with any general behaviouristic account of knowledge is that it is impossible to make sense of any behavioural description without being able to make sense independently of statements about how the world is.
So, for example, it is impossible to make sense of a statement that S is disposed to behave in a certain way unless one already understands the concepts required to understand the content of the relevant behaviour.
As this content will involve the movement of bodies through space and time in relation to other bodies, an understanding of ‘behaviour’ presupposes a general grasp on the layout and nature of the physical world.
The experimental context in which the behavioural understanding of cognition developed involved such a presupposition: we understand the rat's or the pigeon's behavioural repertoire because we see it in the context of a physical layout that we take as given.
If I had no grasp on the shape of the maze, that is, at least its basic spatial properties, I could  not understand any ascription of behaviour to the rat.
This leads to problems when I try to conceive of my own knowing, believing or thinking in behaviourist terms.
I cannot think of my own knowledge of the physical world in terms of my dispositions to behave, but only as my dispositions,construed as operating in the world of which 
I conceive without reference to my dispositions.
I cannot understand my conception of the world in terms of, or reduce it to, some account of my dispositions, as it seems plausible one might for the rat's (or any third person's) conception of the world and its dispositions.
In my case at least, therefore, thought, belief or knowledge concerning the world cannot be analysed simply in terms of dispositions to behave.
There are two responses that defenders of the behavioural approach might make to this argument.
First, an objector might try to press the fashionable distaste for the first-person perspective and say that the fact that I cannot apply the theory to myself shows nothing except that one should not approach the philosophy of mind via the first person.
A philosophical theory is essentially a reflection on a practice, and the first-person perspective expresses engagement in the practice: to apply the theory first-personally is to confuse levels.
This is a spurious argument.
A philosophical account gives the necessary and sufficient conditions (at least in outline form) for the application of a concept, and it should, therefore, apply in principle to anything that is a case of that concept.
If it really is the case that all I am doing when I have beliefs about the world is to have dispositions to behave, then it ought to make sense for me to think of my believing in those terms.
But no such general reduction can be carried out.
There cannot be a genuine perspective from which a true analysis does not apply.
The behaviourist's second line of defence is to distinguish between knowing and what is known, and say that the behavioural reduction applies only to the former.
So when S knows that p, it is his knowing that is his disposition, not what he knows .
This line of defence is no better than the first.
The dispositional analysis is meant to cover the whole of the relevant mental state, not just part of it, and that mental state must include its content, otherwise what is thought will not be the content of the psychological act of my thinking.
There is no way that the content of my thought can both be something that the subject really thinks, apprehends or is conscious of, and yet fall outside the scope of an analysis of the act of thinking.
All behaviouristic theories of cognition are viciously third-personal, where that expression signifies, first, that they cannot be applied to the first-person perspective and, second that our ability to apply them to the third person really rests on our bringing to bear  first-person knowledge: as with rats in mazes, where my plain and unreduced apprehension of the rat's environment enables me to see its grasp of that environment in terms of its behaviour within it.
Our general topic of discussion is perceptual consciousness and the problem that it constitutes for physicalism.
In showing that cognition as a whole cannot be treated behaviouristically, I have not thereby shown that a behaviouristic treatment of sense-experience is false.
So perhaps my overkill misses the target: perhaps the behaviourist analysis of perception is sound, even though a general behaviourism is not, and what BS lacks is not knowledge of the nature of certain mental states, but only the ability to respond spontaneously to visual stimuli, that is, to respond as a result of actually seeing them.
Reflection on the nature of the argument against behaviourism in general, however, reveals that the argument refutes the behaviourist treatment of perception in particular .
That argument showed that knowledge of the external world cannot be reduced to behavioural dispositions, for the very idea of a disposition functions only in the context of an unreduced grasp on the physical world.
But there is nowhere else that we might get our conception of the physical world from, other than perception.
It is the content specifically of sense-perception that must be taken non-reductively, if the contrast required by our concept of disposition is to be maintained.
Some philosophers might suspect that I have not considered the behaviouristic theories in their most sophisticated form.
Would it not make a difference if one identified experience, not with some disposition to overt behaviour, but with the ‘behaviour’ of the brain as it ‘discriminates’the various sorts of stimuli within the nervous system?
This is a version of the supposedly post -behaviourist theory called ‘functionalism’, which treats mental states as responding to other internal and mental states as well as to external stimuli.
The first thing to notice about functionalism is that it does not fare any better than behaviourism in providing an account of what it is that V knows and BS does not, for BS could know all about V's functional or covertly behavioural states; so there is no lack of knowledge that his deficit could consist in.
It can reside only in his inability to do certain things spontaneously.
The situation would be different from this only if the internal discriminations carried with them some experiential ‘feel’ that was not to be identified with some physical process of which BS could know.
But this is just what the physicalist cannot allow.
The second and more important point is that the general argument against behaviouristic theories does take in functionalism and is not merely directed against traditional behaviourism: it works against any theory  that analyses one's conception of the world simply in terms of the way one functions — that is,behaves — in the world.
The addition of internal discriminations within the nervous system adds nothing relevant to this, unless the internal discriminations really possessed semantic properties, so that they somehow contained in themselves a real description of the world.
But it is accepted by physicalists of all kinds that the meaning or semantic value of internal states must be analysed in terms of their causal relations to stimulus and response, just as it is for the behaviourist's dispositions, and is not something they possess in their own right, or of themselves.
I have considered the flight from mind in two major aspects: first in the flight from the generality of form and universality, both in the world and thought; second, in the flight from consciousness.
There has not been space to say much about the flight from generality in the world outside mind, but I have tried to show how the attempts to flee generality within the mind and to abandon or reduce consciousness must both fail.
I promised at the outset, however, to show that reductive treatment of these features of the mind leads to an incoherent conception of the world, quite independently of the inadequacies of the reductions themselves: that is, even if the reduction of consciousness and thought were not independently flawed, the picture of the world that emerges is incoherent.
The physicist's picture of the world is extremely formal.
I mean by this not merely that it can be represented mathematically, but that, such is its concern with the quantitative aspects of reality that it consigns all the qualitative content in our conception of the world to the realm of conscious experience.
Science tells us about the structural and relational properties of objects, while consciousness tells us what they are qualitatively like .
This qualitativeness — the ‘manifest image of the world’— is irreducibly connected with what experience is subjectively like, and it is part of what is lost if consciousness is analysed away or otherwise abandoned.
It is not surprising, therefore, to observe a tendency amongst materialists to treat all properties as if they were purely relational.
The historical progression that has led to this can, at the price of great oversimplification, be seen as follows.
Aristotelian physics was not essentially mathematical.
The physical world is composed of the elements, earth, fire, air and water which are characterized by the  qualities hotness, coldness, dryness and wetness.
These qualities are perceptible but the nature of their interactions is never talked of as if they could be quantified.
In contrast, the atomistic physics which was revived in the seventeenth century concentrated on quantifiable properties.
Secondary qualities, such as colour and hardness, were confined to the senses, and were marginalized.
When this picture was fully developed, even space was represented not as being qualitatively the way it is in vision, but as a structural isomorph of visual and tactile space.
By this point, every knowable quality was confined to the mind.
But the modern behaviourist and functionalist analyses of mind treat mental states as mere powers to produce behaviour: that is, they abolish the intrinsic qualitative content of mental states, replacing it by causal, hence relational, properties.
We have then reached the absurd position that nothing in the world possesses a knowable intrinsic or qualitative nature, for all properties are essentially relational.
This predicament arises out of the demise of consciousness, when only consciousness, understood in a traditional way, can bring us face to face with, and hence give us any grasp on, the qualitative, as opposed to relational, properties.
So the flight from consciousness is the flight from any grasp on the intrinsic nature of any properties — not merely, as with Russell, of properties in the external world, but also of the features in our experience.
This is not merely a very bare conception of the world, but argument supports intuition in pronouncing it an incoherent one.
It reduces language to an uninterpreted formal system.
All we know about As, for example, is that they have relation to R to Bs, relation R' to Cs, relation R'' to Ds, etc; and similarly for our understanding of Bs, Cs and Ds, and the variety of Rs.
What any of these things is like in itself, even the qualitative nature of the spatial medium of the relations, remains unknown.
It is not surprising that reductive treatment of consciousness should have this effect.
In consciousness alone is it possible to confront at least some empirical properties and apprehend them directly, and if consciousness is analysed in terms of some purely non-mental notion this grasp is lost; just as, in the analysis of thought, if the irreducible generality of thought is analysed away, our ability to think and refer is wished away with it.
If, as I have argued, thought and consciousness irreducibly escape the net of physicalist interpretation, and if, as I have suggested, the  external world must possess the mind-like property of generality if it is to be conceivable, then we can see that Socrates' assertion in the Phaedo , that the world must be explained by reference to mind, was essentially correct.
In metaphysics, the understanding of everything begins with mind, not with natural science, and modern philosophy's flight from mind is a flight from reality.
Bibliography
Berkeley's attack on abstract ideas is to be found in the introduction to his Principles of Human Knowledge , of which there are many editions.
The best discussion of the problem of universals is D. A. Armstrong,A Theory of Universals, vol.
I (Cambridge University Press, 1978).
The best statement of materialism is also by Armstrong,A Materialist Theory of the Mind (London: Routledge &Kegan Paul, 1968).
A lucid introduction to contemporary theories of mind -mainly materialist — is P. M. Churchland,Matter and Consciousness (Cambridge University Press, 2nd edn, 1988).
There is an attack on a variety of materialist positions in Howard Robinson,Matter and Sense (Cambridge University Press, 1982).
‘In the Beginning Was the Dead’; Mental Development and the Philosophy of Mind
James Russell
'TIS wit, ‘In the beginning was the Word.’
I pause, to wonder what is here inferred.
The Word I cannot set supremely high:
A new translation I will try.
I read, if by the spirit I am taught,
This sense.: ‘In the beginning was the Thought.’
This opening I need to weigh again,
Or sense may suffer from a hasty pen.
Does Thought create, and work, and rule the hour?
'TWERE best: ‘In the beginning was the Power.’
Yet, while the pen is urged with willing fingers,
I sense of doubt and hesitancy lingers.
The spirit comes to guide me in my need,
I write, ‘In the beginning was the Deed.’
Goethe,Faust I, 1224–37 (tr.
Philip Wayne)
It would seem that, for the foreseeable future at least, we are stuck with the ‘mind-body problem’.
How anything physical — a brain -should be able to support a mental life is beyond the reach not only of our science but of our imagination.
There is, of course, a school of thought which says that a bit of straight thinking, a kind of conceptual analysis-cum-psychotherapy, will sweep this puzzlement away.
I do not take this view, but I do think that there are certain deep assumptions about how the mind-body problem should be addressed which increase its difficulty.
These two assumptions are: that our main questions should be about how individual mental states relate to individual neural events; and that we should view the mind primarily as something which represents reality.
I want to look at the consequences of replacing these assumptions by two others: that we should concentrate on how mind might develop out of matter; and  that we should view the mind primarily as something which enables action .
My first task will be to say why the focus upon mental representation has muddied the waters.
This will lead on to a discussion of an action-based theory of mentality, the theory developed by the Swiss developmental psychologist and philosopher Jean Piaget, and then to some discussion of mental development itself.
By the end of it all the mind-body problem will loom large — but this may be because we are now a little closer to it.
Thinking and representing: the representational theory of mind
It would seem to be a truism that the mind is a representing device.
What else could it be?
Evolution must surely have seen to it that a good proportion of our thoughts are true of the world, and so in some simple sense the mind must perform computations which record the world and direct our behaviour appropriately.
This does not mean that the mind just responds to information in the way in which a thermostat, for instance, transduces information about temperature and performs switching operations.
We act upon reality as we represent it to ourselves, not as it physically is.
Thus, Oedipus married Jocasta and knew he did; he also married his mother and did not know he did.
His representation of Jocasta was, as are all representations, incomplete; and his behaviour was driven by this representation of the woman not by some physical fact about the world.
This is one of the things that philosophers mean when they say that our mental representations are ‘opaque’: thoughts are (necessarily partial) representations of reality and therefore we can have one thought about a referent without having any access to another (‘lover’ /‘mother’).
Considerations such as these would seem to lead inevitably towards what is often called a ‘representational theory of the mind’.
So what can we say about these ‘representations’?
Doesn't the term suggest something like ‘mental pictures’?
Much of our thinking would seem to have a more-or-less pictorial character, after all.
There are, though, a host of reasons for resisting any kind of equation between mental representations and mental pictures; and all of these derive from one fundamental reason.
Any mental picture will require interpretation, and this interpretation will be another mental operation, which, on the view that thinking is having mental pictures, will be another picture, which itself will require interpretation, and so on and so on.
This may look like an easy knock-down argument  against a silly theory which nobody has ever seriously held: but what is true of mental pictures would seem to be true of any kind of mental representing process which encodes sensations in some determinate form.
In other words, the argument works equally against the view that we think in a kind of mental language, that mental sentences rather than mental pictures are the stuff of thought.
Sentences and words also require interpretation — indeed they would seem to require this more obviously than pictures — and so we're back on the circle of infinite regress.
This was the kind of dilemma which the American philosopher Jerry Fodor faced up to in his important book The Language of Thought .
Very roughly, Fodor argued that this kind of blanket objection to representational theories of mind does not work against the mental-sentence kind of theory for the simple reason that we know just what it would be like for a system to work on the mental-sentence principle.
Digital computers work on this principle.
Computers have a machine-code into which instructions on the program are translated, a code which is a kind of computational ‘bottom line’— a language that does not require a further interpretive step because it comes complete with its own interpretation.
It drives the machine; with the ‘interpretation’ being the action, or output, of the machine.
We can have, then, an analogy between the natural languages that we think in (English, Swahili…) and the programming language, on the one hand, and the machine code and our ‘language of thought’, on the other hand.
So long as we adopt a broadly ‘functionalist’ philosophy of mind — in which mental states are defined in terms of their causal relations to sensory inputs, motor outputs and to one another— this ‘computational theory of the mind’is a very satisfying general account of the mind-body relationship.
It implies, of course, that as long as they have the right kind of causal relations, other machines, apart from brains, can possess mentality; and it also implies that the study of artificial intelligence and computational modelling is the royal road to understanding mentality.
The Language of Thought , is, for my money, the major text of the ‘cognitive science’ movement.
I would say that there are two major problems with the mental-sentence thesis which both lead — one ultimately, the other directly — to the kind of developmental questions I shall be raising shortly.
The first problem arises once we admit that in order for a ‘system’(I shall use this neutral term) to think, its thoughts must have reference : that is to say, they must refer to things regarded by the system as existing and enduring independently of itself.
In short, thinking implies something that we can call ‘a theory of the  external world’.
Now the machine-code analogy works well only so long as we forget that all a computer program has to do is run .
The machine does not need to know anything: it has to perform a task.
(For the functionalist, I should interject, knowledge is decomposable into tasks.)
Robot arms driven by digital computers can carry out instructions to, say, ‘put a pyramid on the big block’ even if successful completion of the instructions means first removing a small block from the big one.
This is a very sophisticated procedure, but only in the most metaphorical sense would we want to say that the computer has a theory of the external world.
(John Searle, the Reith Lecturer in 1984, built up a critique of computational psychology around considerations such as these.)
Well how do I know that this computer does not have a theory of the external world?
I have no argument, an objector would say, just a prejudice.
Well, I think that there is an argument of sorts for saying that a computer of the kind described does not have a theory of the external world, does not have mental states which refer, and does not therefore have thoughts in any significant sense.
There is representation in a language but no knowledge, and therefore no thought in the human sense.
We should attend to the fact that knowledge of the external world means representing a lot of facts at once, so many facts that we lose hold of the idea of ‘representation’.
The computer which can move blocks around to instructions represents, in contrast, a few facts and does what it can with them.
I will try to illustrate this by example.
I am thinking about my spectacles lying on the desk before me as I write.
Maybe the thought is ‘They need cleaning’.
In fact, it doesn't matter what the thought is, what predicate I ascribe to them, just that they are the object of some kind of thought.
To put it simply: I can never have just one thought about the spectacles, and if it could be truly said that I was only able to entertain, say, two or ten thoughts about them — if my thinking consisted of discrete, countable thoughts — then they would not be thoughts at all.
For example, the thought ‘They are on my left’ does not ‘succeed’as a thought unless I can also have other thoughts such as ‘If I move to my left they will move to my right’, ‘They are substantial’(that is , not a chimera), ‘They are reachable/not reachable’, ‘They are supported by something’, ‘A large opaque object coming between me and them would render them invisible to me’…
Any of us could fill this chapter with similar thoughts.
And these are just thoughts about the spectacles qua physical objects of a certain size and weight.
If we also consider thoughts about them qua spectacles , then we would say that I have not succeeded in thinking about them unless I am thinking  about artefacts, thinking about items that can be worn on the nose, that aid vision, that are more-or-less breakable, that did not exist a thousand years ago, that this pair existed yesterday but did not exist in 1983, and so on.
Moreover, these potential thoughts do not just lie there like strands of spaghetti on a plate: each must have a certain kind of relation to the others.
Thoughts about how the spectacles would appear to me if I moved towards them leftwards must be related in the correct way to thoughts about how they would look if I moved above them to the right; thoughts about their being artefacts must be related to thoughts about their not existing before a certain time or not coming into existence in the kitchen as the kettle boils.
The phrase ‘the holism of the mental ’ is used in a number of ways; but I hope the reader now understands what I intend by it.
One thought succeeds only because of the relations that it has to innumerable other potential thoughts.
But isn't there something artificial in my references to bunches of individual thoughts?
Certainly, the idea that when I look at my spectacles and think ‘So that's where I put them’ I am having thousands of other little thoughts at the same time is a silly idea, and some would say that the doctrine of the holism of the mental is just a silly idea.
But this silliness does not derive from what I claimed about what it means to have successful thoughts: it derives from our habit of regarding individual thoughts as if they were like sentences.
It looks silly from the perspective of our so-called ‘folk psychology’ of thinking.
For, paradoxically enough, it is the ‘language of thought’ thesis which is closer to the layman's intuitions about thinking.
We have a way of talking, and thus a way of thinking, about thoughts as if they were sentences in the head; and it is worth noting that Fodor (for example in Psychosemantics ) regards folk psychology as providing a rough but reliable account of mental life and behaviour.
The doctrine of holism, by contrast, challenges our folk psychology of thought (see Note 1).
How, then, might a supporter of the mental sentence view try to deal with the holism of the mental?
Well, he might say that one mental sentence is, as it were, ‘upfront’(for example ‘The spectacles are broken!’), but that this sentence has a network of connections to other sentences in the mental architecture (‘They are made of glass,’‘They were purchased’, ‘They are not unique’).
This kind of view is, in fact, quite a familiar one in artificial intelligence-influenced cognitive modelling.
But really it is just a reductio ad absurdum of the mental sentence view.
Each of the ‘sentences’ in the network only has meaning in terms of its relations to other sentences, and each of these sentences only has meaning in relation to others, and so on.
In  which case they have no independent meaning or function at all.
To put the point another way: proponents of the mental-sentence view — being functionalists — typically see the meaning of mental sentences (or mental ‘states’) in terms of their causal role vis-à-vis other such sentences.
But how can a sentence have a causal role in relation to other sentences if the second sentence's causal role is defined in terms of its relation to the first sentence?
Where does the meaning come in?
It can only come in as some kind of ‘emergent property’ of all these causal interactions.
Well if that is the case, then this is just another way of expressing the holism of the mental.
Now for the second difficulty with the mental-sentence view, taking this view, remember, as the most sophisticated expression to date of the representational theory of the mind.
It is about the possibility of learning .
I don't mean learning facts like ‘Lemur is the capital of Peru’ or that ‘St Tracy is the patron saint of the dormer window’(we can learn things that are false: learning is not mere information pick-up), but acquiring concepts such as what is to count as a ‘chair’, that weight is conserved through transformations of shape, that the earth is a heavenly body circling a larger heavenly body.
It is self-evident that learning something entails a prior capacity to learn it.
How are we going to understand this ‘prior capacity’ on the mental-sentence view?
There is only one way: in terms of symbolic representations of the predicates, as in ‘X is a chair and only if it is a portable seat for one person’.
This means that a child acquiring language who does not yet know what chair means but will acquire the knowledge must already have represented in his ‘language of thought’ a predicate of the kind ‘is a portable seat for one’.
Or to put it another way: on the representational theory of mind, all learning is the testing of hypotheses which are already represented in the mind in some form (for instance as sentences).
This means, in turn, that the initial state of the learner must be as a possessor of vast battalions of hypotheses which are selected out as the child bumps up against the physical world and the human conceptual system.
This is a way of thinking derived from Chomsky (and ultimately from Plato), and it is one with which Fodor is quite happy.
He writes — perhaps pour épater les empiricistes —that ‘all concepts are innate’.
But this is a fairly repugnant conclusion to most of us.
Do we really want to say that all we ever learn we knew before — even if we are saying this in some technical ‘computational’ sense?
How about a more modest version of the argument which says that only certain ‘primitive’ concepts are innate (about three-dimensionality, causal relations, etcetera), and that the more sophisticated concepts develop  out of these through the time-honoured processes of differentiating finer concepts from global ones and integrating the results into complex, structured concepts.
This is not much help because (a) later-developing concepts must still on the representational theory of the mind be present in these primitive concepts (there are no merely potential competences such as my potential but non-existing competence to know Portuguese); and (b) how and where do we draw the line between the primitive concepts and the developed ones?
Predictably, perhaps, I regard this argument not as a demonstration that the acquisition of new concepts is impossible, but as another reductio ad absurdum of the representational theory of the mind.
The holism of the mental should make us suspicious, I have argued, of the mental-sentence view.
Well, if a thesis that it is difficult to make sense of allows a conclusion that is repugnant, then the rational course would seem to be to take this as another reason for distrusting the thesis: not as a reason for admitting the repugnant conclusion.
Methodological dualism
The reader cannot have failed to notice that J. A. Fodor is fast emerging here as the bête noire , in that he both presents the strongest case for the representational theory of the mind and champions the conclusion which flows from it about the impossibility of concept-learning.
Well, now I want to introduce another of Fodor's theses which, for my money, is as correct as the other two are false.
Fodor has written in The Modularity of Mind that the consequence of accepting the representational theory of mind in cognitive psychology is a kind of ‘methodological solipsism’(that is, we deal with representations, not the with relations between organisms and real objects out there).
I like to think of this next Fodorian thesis as a kind of ‘methodological dualism ’.
Recall that at the beginning of this piece I briefly discussed what the representational theory of the mind has got right: that thoughts are not simple responses, reactions or reverberations to environmental stimulation — contrasting this with the case of the thermostat which automatically switches on and off at pre-set temperatures.
Thinking involves taking perspectives on reality, rather as drawing does.
Let us now consider the class of mental processes which are not perspective-takings of this kind, which are , in some sense, directly caused by proximal stimuli.
A reflex would be the paradigm case here.
To take Fodor's nice example, imagine that you are chatting to an old friend.
That this person should harbour aggressive feelings  towards you is unimaginable, but then suddenly, she goes to poke you in the eye — and you blink .
The blinking was a reflex which could equally well have been set off by a puff of wind or a flash of light.
The causal chain between stimulus and response had a kind of inevitability, an independence from processes which we would normally regard as mental: it by-passed our knowledge of the friend's personality, history, and basic assumptions about human motivation, the orderliness of conduct, and so forth.
Now if the reflexive processes were not autonomous in just this way, if they were determined ‘top down’ by our thoughts then we would not have blinked.
This much is not controversial.
But Fodor goes on to argue that much of what can be said about reflexes can also be said about processes which we would normally regard as ‘cognitive’ rather than‘neurological’or ‘behavioural’: the parsing of heard sentences, for example .
There is something reflexive rather than rational, automatic rather than deliberative, circumscribed and autonomous rather than holistic about parsing a sentence such as‘She met John before Mary arrived at the airport’ in the way we do (with the pronoun she not referring to Mary but to some other female).
We have, as it were, no choice but to parse sentences in a particular way.
Believing sentences and slotting the information that they convey into our knowledge base (for instance, what we used to think about the referent of she ) is another story.
That is, it is open to us to deliberate about the light that this fact throws on the person's character; but deliberation is not open to us when it comes to parsing the sentence.
From facts such as this, Fodor argues that the parsing mechanism constitutes one independent cognitive module among others, which can be studied in terms of representations that are built from the raw input of the speech stream ‘bottom up’.
We can ignore the influence of higher-level systems.
There are a large number of psycholinguists who would say that Fodor is overstating his case here and that parsing is indeed canalized by so-called ‘real world knowledge’.
However even these workers opt for something that they call ‘interactionism’, in which there is a clearly modular, autonomous element which can be studied in isolation from the knowledge systems.
Vision is a better example of a modular processing system.
Not only does seeing a chair as a three-dimensional object have this character, but so does seeing one line as longer in the Mulier-Lyer illusion (in which two lines of equal length look unequal when differently slanting lines are drawn at the tips) despite our knowing that the two lines are really the same length.
Visual illusions are an excellent illustration, in fact, of the division between a  specialized and autonomous mechanism for seeing and the cognitive system which determines whether we should believe what we see, as Helmholtz pointed out over a century ago.
We can disbelieve the evidences of our senses, we can suspend disbelief, as well as believing the world is such-and-such with no sensory evidence at all.
So, to introduce Fodor's terminology, the mechanisms for delivering up packaged information about the world (a parsed sentence, a representation of a three-dimensional object…) he calls the input systems .
What I have been referring to vaguely as the knowledge system, Fodor calls the central systems .
Unsurprisingly, Fodor characterizes the central systems as holistic — though he prefers the term ‘global’.
But somewhat surprisingly (given that the representational theory of the mind is supposed to be a theory of thinking, not of how we handle inputs) he concludes that a psychology of the central systems is beyond our reach: the more global a mental process is the less we are likely to understand about it.
This is what I mean, then, by ‘methodological dualism’.
I think we should see this pessimism as a direct result of adopting the representational theory of the mind.
The last thing that a representational theorist really wants to have to explain is the global nature of thinking; and I suppose we can regard Fodor's pessimism as an implicit kind of owning up to this.
But when we turn to the input systems there would seem to be no choice but to use the language of ‘representations’.
Psychologists of vision, for example, have to think in terms of levels of representation that the nervous system computes and not to do so would be to render unintelligible the processes that occur between the transducing of light-rays into electrical impulses at the retina and the cortex recording the object as (say) a rigid cylinder rotating at such and such a distance from the viewing point.
The alternatives would be to theorize exclusively in terms of neuronal processes (impossibly fine-grained) or in terms of drawing inferences from ‘cues’(inappropriately rational).
In the first case we need a level ‘above’ physiology and in the second we need a level ‘below’reasoning.
Much the same can be said about sentence parsing.
Although, as I mentioned before, rival groups of psycholinguists dispute the question of whether, when, and how the central systems exert a top-down influence upon the parsing processes, contemporary psycholinguistics proceeds on the assumption that levels of linguistic representation (phoneme, morpheme, noun phrase, clause, etcetera) are ‘psychologically real’ in the sense of referring to processes in the nervous system which take a certain time, which happen in a particular order, and which have determinate causal relations  to similar processes.
Why?
Because these representations refer to computational achievements within systems which are by definition (Fodor's definition)not holistic .
The same kind of representational language could be used to refer to the working of a television set or indeed a thermostat.
In short, a representational theory of the input systems would seem to be a necessity, whereas a representational theory of the central systems would seem to be a non-starter.
This is not just a point I am making in passing.
The input/central distinction is something on which I shall be heavily reliant when I come to my positive thesis.
This is now due.
Constructivism and development
The constructivist theory of mind regards thinking on an analogy with action; just as the representation theory takes an analogy with drawing and writing.
Moreover, to the same extent that the representational theory is non-developmental (recall the Fodor's argument against learning), the constructivist theory is developmental.
I would not say that the developmental view is a consequence of the thoughtaction analogy exactly, because there could be constructivist theories that do not mention development.
It is certain, though, that the constructivism that has received the most attention in psychology and philosophy has been the developmental theory of Jean Piaget.
Although, as I say, constructivism and the developmental view are separable, constructivism invites a developmental perspective on thinking in the following sense.
On the representational theory nothing can be prior to a mental representation — the bedrock of thought is representational.
On the constructivist view, by contrast, actions exist before central systems exist — before thoughts, beliefs, hypotheses, justifications, notions of truth.
Obviously enough, action is not all that is required for thought.
We need input systems.
In other words, the representations which exist before cognitive ‘representations’(in the ‘representational theory of mind’ sense) are of the input system variety.
That is to say, the infant must convert stimulation from light rays, sound waves, from the speech stream into the appropriate representational grist if it is to get the kind of information that it requires from the world; but this gleaning of information does not constitute thought.
The next claim which constructivism makes is that centralsystem thinking emerges out of the organism's interaction with the environment, an interaction that is initially a literal inter- action but which is later carried out internally, at least in the  human case.
Thoughts are — as the slogan has it —‘internalized actions’.
Before passing on, I will introduce a piece of terminology of my own and call central-system thinking ‘cognisance’, a term chosen so as to give the flavour of knowledge, rationality, and accessibility to consciousness.
Thoughts will be referred to as ‘cognisant acts’.
The simplest and most fundamental aspect of cognisance (fundamental philosophically and developmentally) is what is usually referred to as ‘self-world dualism’: the knowledge that there is a physical world out there of which I am an experiencer and that is distinct from me.
Mental development, on the constructivist view, consists in the elaboration of this knowledge; so that if there is one central difference between the mental processes of the baby, the child, and of the adult it is in terms of how self-world dualism is manifest in (and to) the subject.
The representational theory of mind treats the explanation of mental life as a kind of engineering problem; it starts from the inside , from the representational state, and asks how mental states interact with one another to produce something that we would call ‘knowledge’; the representational theorist proceeds like a sceptical philosopher who thinks that what figures in our mental life is not reality but our mental representations of it (recall my saying the Fodor described his position as ‘methodological solipsism’).
The constructivist starting-point could not be more different, and might be said to be ‘biological’ where the representational theory is ‘engineering’— or ‘machinological’.
Constructivists do not admit such scepticism: the existence of an external world is one of the factors which make cognisance possible.
With its existence thus assumed it is knowledge of the external world which has to be explained.
In constructivism we view the organism-environment dyad from the outside and ask how it might be possible that an organism which has input systems and which is active could ever come to know that the environment exists.
Consider then, an organism in a world of inanimate objects.
(There is a lot to be said about the role of other persons too, but I am leaving that out for the time being.)
There are three crucial differences between the organism and the objects.
(1) It can move itself and has biological needs (not just for food and warmth and the like, but the need to use its faculties —Functionlust as it was once called by a German psychologist).
(2) It has input systems.
(3) It is designed so that the interaction between (1) and (2) and other objects in the world will result in cognisance.
To put it epigramatically, the bridge between information pick-up and knowledge is action.
And  this means that the task of a constructivist developmental psychology of cognisance is to describe how this bridge comes to be built.
When introducing the notion of mental holism earlier, I said that thoughts must have reference and I implied that only holistic systems could achieve this reference.
Constructivism is designed to deal with reference and holism.
First, we assume that the neonate's input systems deliver up more-or-less true information about the external world, telling a six-week-old, say, that although the ‘retinal’ image of a square piece of cardboard changes to a trapezium when it or the baby moves sideways, the shape really remains square, and enabling it to discriminate between changes in angle and changes in orientation.
These systems also enable neonates to discriminate between different facial expressions of emotion (for example, smiling versus frowning) and, sometimes, to imitate these expressions as well as non-emotional ones (for example , mouth-widening, tongue protrusion).
The reader only has to glance at a good modern textbook of infant development (say, Bremner's Infancy ) to get the main message: very young humans are prodigiously skilled at picking up geometric and social information, and this can be seen both informally (a neonate turning to a voice) and in the laboratory.
None of this implies of course that babies know anything about the external world at all.
It is a matter of their input systems being tuned to the contours of this physical and this social reality.
Now it is frequently said that the development of skilled movement ‘lags’ a long way behind that of skilled perception, and in one sense this is certainly true: young babies have excellent visual acuity as revealed by their behavioural discrimination of, and neural responsivity, to gratings and chequerboards — but we don't see them playing darts!
The presence of movement is one of our main criteria for being alive, and yet infant movements appear at least to be random, reflexive and undirected.
Moreover, we know that people who are born with severe motor impairments develop normal and sometimes supra-normal intelligence.
They may indeed, as in the case of Christy Nolan, win the Whitbread Prize for literature.
So why not say, then, that in development perception ‘teaches’ action, that as the information delivered up by the input systems becomes progressively ‘richer’the infant becomes better able to direct his own movements, rather than saying that cognisance develops out of action?
My answer to this point will be more philosophical than empirical.
It will rely upon an argument from Kant.
In the Critique of Pure Reason , Kant's aim was to show how objective experience is possible, to set out the conditions necessary for this; whilst Piaget's aim was to show, given certain Kantian assumptions, how objective experience  actually develops.
One of the conditions for ascribing to oneself experiences of a mind-independent reality, Kant argued, was that we should be capable of distinguishing between those sequences of perceptions (if you like, ‘representations delivered up by the input systems’) which are determined by the movement of objects and those which are determined by our own movements.
In the former category we have, to take Kant's example, watching a ship sailing upstream: here an object moves against a more-or-less stable background from (say) left to right.
We have no option but to see it as movement from left to right.
To describe self-governed perceptual sequences, Kant gave the example of scanning the front elevation of a building; in doing which we determine what we see and the order in which we see it — roof, front-door, top-left-hand window, and so forth.
Obviously, each kind of experience necessarily contains elements of the other.
Thus, there is some degree of selfdetermination in the ship case because we are free to shut our eyes, to cross the river and see it move from right to left, free to jump into the water and watch it coming towards us, free to determine the speed with which it passes across our visual field by moving our eyes with or against its movement.
In the house example, we can choose the order in which we see the parts of the building but we surely cannot see occluded portions, and we surely cannot look up to see a thatched roof — because that's the kind of roof we want to see — when the roof is tiled.
In fact, in every microsecond of perceptual experience there is a tension between the real as refractory, as something we cannot choose or will, and the subjective as chosen and willed.
This may sound a somewhat highfalutin' way of making an obvious point; but the obvious points are often the important ones: in this tension we find the limits of experience, beyond which we locate an objective universe and within which we locate subjectivity.
(One caveat: I am not saying that this is the only necessary experiential condition for objectivity: it is, though, the one which highlights the importance of action most clearly in differentiating the objective from the subjective within the stream of experience.)
Without the possibility, then, of altering one's perceptual inputs at will it is difficult to see how the information provided by the input systems could ever be centered upon a self, a self that is not just a repository of information, but something which addresses itself to reality and for whom reality is centred upon itself.
I will give just one reason for this.
If there were no refractoriness (no failures to experience X when trying to have an X-experience) there could be no basis on which to draw a distinction between appearance and reality, and without this distinction there can be no possibility  of thinking about reality.
There would be no distinction between the thinker and the reality he was thinking about.
You may say, against this, that there can surely be some form of appearance/reality distinction so long as the input systems can deliver up information about such objective facts as occlusion .
In this case, the reality of (say) of an orange being behind the breadboard is different from the appearance — which is that of a breadboard leaning against the kitchen wall.
And what of the unseen portions of the wall behind the board?
The ‘appearance’ is of the wall stopping just as it reaches the board; but do not the input systems deliver up the information that the wall continues behind the occluder?
Indeed, as I mentioned above, there is plenty of evidence from research with the very young infants that their input systems allow them to make appearancereality distinctions (for example, apparent versus real shape) at so young an age that the possibility that they have to rely upon records of their actions to do this is just not worth considering.
I think that this kind of objection rests upon a false way of thinking about the information that the input system provides.
I shall have more to say about occlusion a little later, but for now: grasping the fact of occlusion in the sense of grasping the fact that if something were removed then something behind it would be perceived because the something behind was there all along is an achievement of the central systems.
It means that we can think about things that are not present.
Sure enough, we would expect the input systems to ensure that the right kinds of distinctions are drawn — between contour changes that define occlusion and those which define disappearance, for example— but this surely does not mean that the possessor of these input systems is capable of thinking about unperceived entities.
What this adds up to, then, is the claim that if there existed an organism which either could not act or whose actions made no difference to its perceptions then not only would that organism not be cognisant, it could never become cognisant.
(It is not clear to me whether this is some kind of philosophical claim or an hypothesis.
You may say that it is refutable and so it is empirical; but then — see below — our criteria for cognisance are so much bound up with what the subject can do that it is difficult to see how we could assess the cognisance of a totally passive creature.)
Perhaps the reader is now in a position to understand what Piaget intended when he said that infants ‘construct’ reality through action.
They surely do not ‘construct’ it in the sense of making it up!
They construct it in the sense of developing a conception of the real as being the refractory limit of their own actions.
But does this not leave  babies with an awful lot to do for themselves ?
And does it not have the ludicrous implication that a two-month-old only knows more than the two-week-old because he is more active?
What is more, we still have to answer the objection that intellectual development can be normal in people with very severe motor impairments.
If we find cognisance flourishing where there is a set of actions as restricted as those of Christy Nolan's, then how can reality be something that we posit as the limits of action: in this case a poor actor should have a correspondingly poor grasp of the real.
The answer is that by ‘action’ the constructivist intends something much broader than ‘motor behaviour’.
The term is supposed to encompass any intentional change in the perceptual input .
There need be no movement.
Thus,attention — listening to one voice rather than another for example— is non-overt action.
Obviously, if the infant were deaf, blind, without tactile sensations, and totally immobile then the prospects for cognisance would not be very rosy; but in this case the input systems would fail to function as well, so both constructivists and nativists (those who believe in innate mental structures) would predict failure.
(Even the radical nativist has to admit that information has to impinge upon the organism.)
Indeed action would seem to be necessary for the input systems to function properly: the role of eye-movements in vision being the most obvious case.
So far we have been discussing the role of activity in the development of referential thinking, the development of the knowledge that ‘there is a world out there’.
What of the claim that I made earlier that no such conception could ever exist without the mental system being holistic?
How does the necessity for action relate to the necessity for mental holism?
According to the kind of constructivism that I am espousing, the holism of the mental is logically and developmentally dependent upon the holism of directed action.
That is to say, a system could not be cognisant unless it appreciated how intentional changes in its perceptions were constrained by reality.
Among other things, this means that we should look for the origins of cognisance, as did Piaget, in infancy (babyhood).
Initially, the infant perceives and the infant acts, but nothing suggests that the infant understands the relation between these perceptions and these actions.
Take the example of following an object by eye-movements (so-called ‘tracking’).
As Piaget observed, very young infants will do this, but that if the object (mother, say) leaves the visual field it will not be followed.
Why not?
Because there exists no distinction between causing the experience by acting and the maintenance of the experience requiring action, and so no conception of acting in order to experience a something in the external world.
How could infants develop towards such a conception?
Not, the constructivist argues, by the enrichment of perceptual input (in any case the evidence tells us that this is already rich): only through action itself.
Specifically, in Piaget's theory the infant's central systems develop by ‘assimilating’ perceptual data (data implying ‘graspable’/‘suckable’/‘trackable’/whatever) to actions whilst ‘accommodating’(that is changing in a goal-driven way) the actions taken in terms of the outcome (changing the grasp, the suck, or the head movement in terms of the size, contour, or the trajectory of the datum).
So the basic assumption is that the developmental process is failure-driven: actions are continually failing to fulfil the assimilatory intention (recall the term Functionlust that I used earlier) and must therefore be modified.
The infant's brain records the results of this modification and gradually ‘constructs’ a model of reality on that basis.
It must be said, however, that despite the beautiful detail of Piaget's behavioural descriptions, his picture of the mental reorganizations underlying behavioural change was painted with a very broad brush (by present-day standards); and indeed the assimilation-accommodation model is little more than a description of what has to be explained, awaiting, what we now call, a ‘computational model’.
My own view is that connectionism (see Chapter 7) is well placed to provide such a computational account of sensorimotor development; but that is not the issue here.
Here is Piaget's most well-known demonstration of the infant's failure to relate actions to experiences.
At about seven months of age the average baby is quite skilled at removing obstacles to prehension; is well able, for example, to pull a cushion away to reach a rattle behind it.
However, if the rattle slips down so far that it is no longer visible, the infant will at once lose interest and behave as if the rattle had also slipped out of existence.
By about eight months of age most infants are capable of retrieving completely hidden objects; but between eight and twelve months they show another intriguing pattern of errors.
There are now two occluders, A and B, side-by-side before the infant.
The infant retrieves, or witnesses the retrieval of an object from behind A (say) three times, after which he watches as the experimenter moves it to place B. On seeing it vanish at B he will go straight back to A. Although the back-to-A error is more likely to be made the longer the delay between hiding at B and allowing search, this is not a memory problem in any simple sense because the infant will return to A even if the object remains visible at B. We find a particularly clear demonstration of this kind  of ‘perseveration’ in an experiment by Paul Harris in which there were two transparent, lockable boxes as the A and the B location.
After the object (a toy car) had been put at B, the boxes were locked; with the result that most of the infants went straight to B, could not get in, and returned to A and tried to gain entry to a box which they could see (whatever ‘see’ means here exactly) was empty.
A minority of them never went to B at all, but went straight to A and searched, like the others, at a visibly empty space.
Until about eighteen months or so they will typically be unable to search for objects which have been displaced invisibly (by transposing containers, for example).
We need fine-grain theories of why the performance breaks down, theories about memory development (a sophisticated memory-failure account is still in the running), about the ability to inhibit actions, about the development of the frontal cortex.
But from the perspective of constructivism — which is a general theory of how cognisance is possible and how it develops — the immediate ‘information-processing’ shortcomings that lead to the failure to relate one's actions to objects is not relevant.
That infants fail to search in these situations — although they clearly have the motor skills to do so — is one of the empirical bolsters to the view that what develops is the ability to relate actions to experiences ‘of’ them (again: whatever ‘of’means in this context!).
As Piaget said himself when reporting his original data, it is just not possible to explain the seven-month-old's failure to search in terms of memory failure (that is the baby knows that objects exist unperceived but keeps forgetting that this object went behind there) because if an organism had a memory this bad it would ipso facto lack object permanence.
Moreover, we know that infant memory is remarkably good in other contexts.
In fact, cognitive psychologists are nowadays more sympathetic to the Piagetian view that memory is the result of cognitive activity, not a passive receptacle in the mind which grows, rather as the body grows.
(Note how in-house debates in experimental psychology criss-cross with epistemological issues in this area.)
Before passing on I want to raise a problem with all this.
It may have occurred to some readers already.
Isn't there something suspicious about making the performance of intentional actions the acid test of objective knowledge when it is quite possible that young babies have a very rich knowledge about the unseen existence of objects but that they lack the capacity to co-ordinate this knowledge with their motor skills at object removal?
Constructivism seems to make this a logical impossibility, which of course means that no data could ever disprove the constructivist claims about what develops in  infancy: any evidence that object knowledge (the ‘object concept’ or ‘object permanence’) exists without reaching behaviour will not be judged to be evidence for object permanence — as a point of logic.
I will say two things about this issue.
First, we have evidence from Renée Baillargeon (see the Bremner volume referred to above) that babies as young as three or four months are able to ‘represent’, in some sense, the continuing existence of an invisible object behind a screen because they show ‘surprise’ when this out-of-sight object does not resist the backwards movement of the screen.
They do not show surprise when the fall of the screen is resisted by the out-of-sight object.
Now such infants are too young even to organize a so-called visually-guided reach (that is, reaching for what they can see).
The constructivist answer might be that this is behaviour guided by the input systems, with the added assumption that the behavioural expectation of resistance does not entail knowledge of continuing existence — of a continuing object of thought.
Second point:is the constructivist's fundamental assumption not justified if knowledge is our subject of study rather than successful behaviour?
What sense does it make to say that somebody knows that there is, for example, a beer in the fridge,wants a beer, is able to open the fridge door but doesn't open it?
Something has got to give: all these italicized attributions cannot be true of the same person at once.
In our ‘folk psychology’ of knowledge, the relation between action and knowledge is that secure.
Surprise (in the sense studied in Baillargeon's experiment — passive capture of visual attention) is not an action so it cannot tell us about central system function.
(Recall Fodor's example of blinking when a good friend goes to poke us in the eye.)
If surprise were a central system function then we would not , indeed, blink because the blink would be controlled by our knowledge of a friend's good nature.
Thus: surprise cannot tell us about the development of the central systems.
Needless to say, this is not going to be the last word in the debate between the constructivists and the nativists.
Cognisance after infancy
Piaget's claim that thinking is a kind of internalized action, exemplified in the assimilation-accommodation theory of infant learning mentioned above, is really a global assumption in search of some refined, detailed and testable expression.
One way of stating this global assumption is this: what the child has to acquire is the  ability to direct, inhibit, and co-ordinate his thoughts, as he earlier had to direct, inhibit and co-ordinate his actions .
This is, I would argue, a powerful idea which makes the phenomena of mental development more intelligible to us.
What I shall do now is try to back up this last statement by sketching some of the characteristics of childish thought, showing how they can be explained in constructivist terms.
They all concern, in different ways, the appearance-reality distinction, because cognisance must be understood in terms of our drawing this distinction in every area of our mental life.
An infant at eight months who retrieves a completely-occluded object has made a major advance in understanding the appearance-reality distinction, at least on the plane of action, because he now knows that, although the perceptual input at one time tells him that there is no rattle in his reachable space, really there is.
This also means that the infant can now understand a kind of ambiguity: the rattle is both ‘absent’ and ‘present’at the same time.
Piaget's claim is that the cognitive difficulties which infants come to resolve ‘on the plane of action’ in infancy reappear, in childhood, ‘on the plane of [verbal]concepts’and have to receive the same kind of solution — by way of the direction, inhibition and co-ordination of cognitive acts.
John Flavell (see Cognitive Development ) did the following experiment with pre-school children.
In one condition he showed them a series of objects which had been bought from a joke shop: a piece of rubber cheese, a chicken's egg made of stone, and so forth.
Even the youngest children, who were three years old, were well aware of the fact that appearance and reality were conflicting, but how did this knowledge reveal itself in their judgements about the distinction?
To put it another way: how did they think they could share their thoughts about the trick objects with another person?
When they were asked what the (say)‘egg’ was ‘really, really ’the three-year-olds answered correctly that it was a stone, but when asked what the object ‘looks like to your eyes ’they also said ‘stone’.
(There are a number of control questions that I am omitting here.)
This tendency to give a realist answer when we request a phenomenalist (appearance-based) answer -which Piaget called ‘intellectual realism’— is also very easy to see in children's drawings.
That is to say, young children frequently draw not how a scene looks from their point of view but a good, revealing representation of it — something which further experiments have shown is not explicable by simple graphic incompetence.
This does not mean, however, that young children are realists ‘across the board’.
Consider another of Flavell's conditions.
He also showed the children other kinds of illusion in which object's  perceptual properties were altered: a white index card behind a blue light-filter for example.
When three-year-olds were asked what colour the card was really they typically said ‘blue’.
Flavell accounts for this paradox in terms of, what he calls,cognitive salience , which amounts to the claim that the thought of the three-year-old is determined by whatever is ‘up front in consciousness’ at any given moment.
So when they see an apparent egg that is really a stone, the fact of its being a stone (not that they have found a stone on the beach, say, which happens to look just like an egg) swamps their judgement; similarly when they see a white card changing colour — the blueness is salient not the fact that it started white.
And so one may say, in more directly Piagetian terms, that the child's thinking fails, by our lights, in so far as one thought is not balanced (‘in equilibrium with’ in Piaget's jargon) by another.
The child's cognisant acts have the character of perceptions: if an act is done it cannot be undone (‘reversed’ in the jargon) and so there is no going back and taking another perspective on the question or practical problem.
So children are not little realists or little phenomenalists, nor does it really make sense to say that they ‘waver’ between the two.
We should say that their thoughts are captured by salient information where they should be centrally directed, inhibited and co-ordinated.
In a somewhat more subtle form, these tendencies continue into later childhood.
Martin Braine found that if children between five and six years of age are shown a standard visual illusion — such as a stick in water appearing to be broken, by light refraction — they will distinguish correctly between ‘looks?’ and ‘really?’questions, but that if they are asked the neutral question ‘Is the stick straight or broken?’they will say that it is broken.
The neutral question is interpreted phenomenally, where an older child (around seven years) interprets it in a realist fashion.
Maybe the reader's first thought an experiment of my own showed that this is not misinterpretation in any simple sense.
We tested children in pairs so that each child in the pair observed visual illusions from different angles such that one child saw one kind of illusory view and the partner saw an opposite but equally conflicting view.
For example both children knew that bricks A and B were the same size, but, when viewed through portholes in a box, A looked bigger to one child and B looked bigger to the partner.
They were free to look over the top of the box to see what size the bricks really were, and they were quite aware that their own view was distorted because one of the portholes contained a magnifying lens.
The instructions were to agree one answer to this question ‘Are these two bricks the same size, or is one of them bigger  than the other?’
We also gave them colour, length, and brightness illusions.
In another experiment one of the pair had a non-illusory view; for example he or she had portholes of plane glass.
In control conditions children worked alone, either seeing one view only or walking round the table with the experimenter to see both.
The point of the experiments was this: strong social pressure was being put on these children to agree to a realist answer (they were not allowed out of the room until they had an answer!) and if their usual tendency to interpret questions phenomenally is a trivial and weak effect then this social pressure should obliterate it.
The result was that the social pressure had no effect at all.
In children between four and eight years of age there was absolutely no difference between the number of realist answers produced by the pairs and by the control, solo children.
They knew the realist option but did not take it as a way out of a social impasse, because, I would argue, the phenomenalist tendency of thought is too strong.
What dominated their judgements was the salience of the illusion —that was ‘most up front in consciousness’.
Many readers who know nothing else about Piaget's work will know of his experiments on ‘conservation’.
These simple but extremely robust observations concern children's knowledge that although a substance or display is changed perceptually — in other words, that the appearance of an object may change — properties such as length, area, volume, weight, number do not change.
Here is perhaps the simplest and most dramatic example: the non-conservation of length by children below about seven years of age.
We give the child two pencils of equal length side-by-side, and he correctly judges them to be the ‘same size’.
We then move one of the pencils upwards on the table, by about an inch or so, and ask again about the relative length of the pencils.
It's safe to say that every child in every culture will go through a period of saying that the pencil which has been moved up is now longer or bigger or big now.
Why is it longer: ‘because it's higher up’.
It is pretty certain that, in term of what adults mean by ‘longer’ the children do not really think that the pencil is longer; but why do they say this?
They are, in one sense, interpreting the question differently from the way we do; but why do they do it?
As Piaget said when he reported the original finding, trying to explain the children's behaviour away by saying that they ‘misinterpret the question’ is circular:of course they are misinterpreting the question and the next question is about cognitive determinants of this misinterpretation — this ‘non-conservation’.
Although it is tempting to do so, non-conservation cannot be assimilated to the phenomenalist tendency shown up in Martin  Braine's experiment.
For a start, the higher pencil does not look longer.
Moreover, we showed, in a small study, that non-conservers of length will say that a one-inch and a ten-inch stick are the same length so long as their tips are on a level.
Clearly, they do not look the same length; and clearly the child's thought is focused on the tips (‘centrated on’ in the jargon).
Viewed in constructivist terms, the non-conserver is failing to exert central control (lack of ‘direction, inhibition, and co-ordination’) over his cognisant acts.
The tips of the pencils are ‘cognitively salient’, and what is seen of their relation determines the child's communicated beliefs about length.
What if we simply draw their attention to the trailing ends?
I have tested literally hundreds of children on conservation tasks over a period of twenty years and have confirmed (to my own satisfaction at least) that fundamentally — in terms of the central systems — one does not succeed in drawing their attention to non-salient features.
The child sees them and talks about them; but this does not affect his beliefs.
The judgement of basic physical and geometric phenomena have then — descending still further into metaphor — a perceptually-determined, evoked character, rather like the actions of younger infants.
I will turn finally to experiments on what is now called the ‘child's developing theory of mind’(see Astington, Harris and Olson, 1988).
By this is meant young children's explicit knowledge that they and others have mental states which are only ‘in the running for truth’, that beliefs held by people can be false and yet these false beliefs can determine their thought and behaviour.
The phenomena studied in theory-of-mind research, I will argue, fill out the Piaget-Flavell picture of the child as a victim of cognitive salience.
Here is one of the standard procedures that is used to test whether a child has an adult-like appreciation of false belief.
John and Mary (the two experimenters) show a child of three years of age a red box and a blue box and a pound coin.
John gives Mary the coin, she hides it in the red box for safe-keeping and departs.
Meanwhile John tells the child that he is going to play a trick on Mary and transfers the coin into the blue box.
Where will Mary look for the coin when she comes back in?
And once Mary has returned, where will she ‘think’ the coin is?
Typically, three-year-olds, but not four-year-olds, say that Mary will look for the coin where it really is — in the blue box.
Does the child regard mind and reality as existing in a state of perfect correspondence?
That's surely putting it too high.
But there is a salience problem here.
Recall that it was three-year-olds who had difficulty with Flavell's appearance-versus-reality problems; and indeed further experiments have shown that there is a strong  statistical correlation between performance on the appearance-reality and on the false belief task.
Where is the salience effect?
I would say that the child is capable — more or less — of recognizing that other people have mental states different to his own.
Indeed it would be difficult to imagine how children were able to use language to communicate if no such conception were present.
Moreover in other kinds of false belief experiment (by Henry Wellman) where three-year-olds watch a puppet make a mistake in searching, the children are quite capable of explaining the failure in terms of what the puppet is wrongly thinking.
But competing with the conception of the other person's thoughts is the child's own knowledge of the location of the coin.
This is ‘up front in consciousness’ and it is this which determines his answer, in the absence of central control.
We recently did a simple experiment which happens to illustrate how children's knowledge of where an object is determines their behaviour.
It shows quite dramatically how difficult young children find the inhibition of reference to a salient object.
Children played a game against a second experimenter for chocolate.
For fifteen trials, two closed boxes were placed between child and experimenter.
We told the child that there was a chocolate in one of the boxes and that he had to point to one of them — guessing of course— to tell the experimenter where to look for the chocolate.
If the experimenter found it then he kept it, and if he did not find it the child got the chocolate.
In this way the child learnt that it was in his own interest for the experimenter to go to the empty box.
Then the boxes were changed.
This time there were windows facing the child (invisible to the competitor) so the child could see where the chocolate was on each trial.
Where will the child now point?
If he points to the empty box then it is probably fair to regard this as deliberate misinforming, as the ‘implanting’ of a false belief in another's mind.
In fact we did find a clear difference between the three- and the four-year-olds: the younger ones typically pointed to the box with the chocolate and the older children to the empty box.
But what was striking about the three-year-old's behaviour here was that they did this for twenty trials .
They could see that the competitor's pile of chocolate growing ever higher and that they were winning nothing, and yet they were powerless to do anything about it!
If we told them to point to the empty box they would do so; but would revert to pointing to the baited box again on the next trial.
I did not mention before that theory-of-mind tasks are also typically failed by autistic children who are otherwise quite able.
That is to say, they behave like three-year-olds on false belief tasks even if their mental ages are, by other criteria, well above three years.
This is not  the case in non-autistic mentally handicapped children, who do well on false belief tasks so long as their mental age, by other criteria, is above three years.
We also tested a sample of autistic children in the chocolate-finding task and found that they were again behaving just like the three-year-olds: going to the baited box for twenty trials, despite wanting to win chocolates and occasionally trying to filch them from the experimenter's bag.
This suggests the hypothesis that one of the features of autism is a lack of central control of thinking similar to that found in very young normal children.
Their input systems function adequately, but their thinking lacks the full, holistic character of normal thought.
Uta Frith, in her recent book Autism , argues something similar.
(Non-autistic mentally-retarded children would appear to have a different kind of problem.)
Autism is a very profound cognitive deficit indeed, and everything that I have said up to now entails that a person whose thinking significantly lacks an holistic character, and lacks the related qualities of directedness, inhibition and co-ordination, will be profoundly affected.
Coda
We have covered a lot of ground, and maybe the path through the undergrowth of arguments and data is not a very straight or a very clear one.
I certainly would not want to attempt a summary of the route we have taken all the way from the mind-body problem to children trying to win chocolates; but I do need to make some concluding comments to justify the bold claim in the first paragraph that constructivism makes the mind-body problem less intractable.
I argued that the representational theory of mind, with its assumption that thinking is the possession of determinate ‘mental states’ which are in some sense encodings (pictorial, syntactic) of actual or possible states of affairs, contributes to the difficulty of the mind-body problem.
We have mainly been concerned with the modern ‘computational’ version of the representational theory of mind; but, as I shall mention again later, the more traditional views of mental life are no less representational — phenomenology, for example, is a representational theory of mind.
I How might such states be both mental and physical at the same time?
We do not want to say that one kind of state causes the other kind, but neither does it make much sense to say that they are ‘parallel’ or ‘identical’.
There are arguments for all possible positions, but none of them convinces us for long(see chapters 1 and 5).
Recall that constructivism refers only to mental representations at  the level of the input systems, as entities which can be translated, more or less directly, into the language of neuropsychology.
(It refuses to take seriously the claim that central-system processes -thinking — are explicable in terms of the causal interplay of representations.)
Thinking — cognisance — is, however, not a matter of being in one mental state or another, or of flashing through a sequence of mental states: it is having conception of oneself as an experiencer of an external world, an experiencer who has the freedom to perform cognisant acts.
Thinking is a capacity to refer at will, whose nature is made more mysterious if we try to chop it up into mental episodes with particular epistemic content or causal power.
Inadequate thinking, as I hope to have shown in my section on mental development, can be regarded as the inadequate control of mental attention, and, like inadequate action, fails through misdirection, disinhibition, and unco-ordination.
An adequate thought is an achievement made possible through the co-operation of the whole cognitive system: it's not a well-formed encoding of something else.
As I said, it is not only the modern, computational form of representational theory which is, from the point of view of constructivism, mistaken.
Throughout the philosophy of mind and certainly amongst both lay and professional psychologists there is the view that basically two kinds of fact exist: physical facts about the brain and the external world, on the one hand, and facts ‘about how it is with us’, on the other.
This may seem harmless enough, but problems arise once we try to describe the latter kind of fact.
When trying to describe these facts, we find ourselves being sucked into the language of phenomenology with its core assumption that our experience consists of shifting mosaics of raw experiential data -colours, feelings of pain, desires, glimpsed movements…
These experiences are at once ineffable and a psychological bedrock beneath which we cannot penetrate.
And this conception leads inexorably to the view that experience is like a kind of screen, something which could perhaps be painted if only we had the skill and reflective capacity, or something which could be captured by language or music.
Or we might talk in terms of an ‘inner world’, the world of mental tableaux accessible only to ourselves.
How could this phenomenal screen or these phenomenal tableaux also be brain activity?
A constructivist would deny the existence of anything that corresponds to this conception of a phenomenal screen.
To think there is such an entity is to confuse two kinds of process, processes that correspond roughly to the input and the central systems.
(I admit  I am suggesting that we replace one kind of dualism with another!)
In accordance with this latter kind of dualism, we have on the one hand our computational successes in recording (the psychologist James Gibson used the useful phrase ‘resonating to…’) information in the external world.
On the other hand, we have mental activity which enables us, second-by-second, to conceive of ourselves as mental entities.
Without cognisant acts there can be no beliefs about phenomenology: no phenomenology without self-ascription, and no self-ascription without mental actions.
Does this conception make the mind-body problem easier for us?
Perhaps it does in the following modest sense.
At the first, input-process level, we do not encounter philosophical problems in the classic sense: these are problems of mental engineering, of ‘cognitive science’— in the current jargon.
However, the problem at the cognisance level is to describe how a history of activity (that is, intentional changes in informational content) results in the conceptions which we have about our mental life.
It hardly needs saying that how this story is told will depend upon philosophical argument.
But surely, you may say, consciousness does consist of determinate mental episodes.
I think of eating an omelette or walking by the sea and these thoughts have a determinate ‘qualitative’ or ‘phenomenal’content.
And is not the thought of, say, blue different from the thought of green in some way which we may one day be in a position to describe, just as we are now able to describe the causal conditions for the experience green which is different from the experience of blue?
Why do we have to say that these thoughts are like mental actions?
Surely the determinate content of thoughts is not captured by constructivism.
At best constructivism is a developmental theory about what kinds of organism-environment interaction are necessary for certain kind of understanding.
That is quite a lot; but why be more ambitious and say that it makes the place of mind in Nature more intelligible to us?
Answer: nobody is denying that thoughts have qualitative content.
(And why shouldn't the kind of holism that I am espousing not help to make processes such as mental imagery more intelligible to us — Piaget published a number of experiments on the development of imagery.)
What is being attacked by constructivism is the assumption that these mental contents are , in some way, ‘consciousness’, ‘mental life’-whatever term we wish to use.
It was primarily David Hume who highlighted the problem of understanding how a coherent, ego-based mental life could emerge from bundles of ‘impressions’ and ‘ideas’.
It cannot, and that is the reason, above all others, that classical ‘associationism’ failed.
Paradoxically, associationism is anathema  to representational theorists like Fodor; and Fodor criticizes connectionism (see Chapter 7) for inheriting all the problems of associationism.
But a picture of the mind as consisting of atomic mental states causally interacting is not a million miles from the Humean view — a view of which Hume himself was the most insightful critic.
On a more phenomenological level, if we wanted some visual analogue to the associationist view of mental life we could not do much better than think of one of those ‘psychedelic’ slide-shows popular in the late 1960s, in which lights were projected through oil, producing coloured globs which met, merged and repelled in a series of kaleidoscopic patterns.
Every emerging pattern was explicable in terms of principles of local association.
From the standpoint of constructivism, the reason why associationist-representational theories so spectacularly fail to capture the essence of thought is that they ignore the fact that every thought, like every action, has, at some level, a purpose.
The fact that we often feel that our thoughts come unheralded by ‘intentions’, that the content of our mental life is unwilled, just demonstrates how thin is the layer of consciousness.
This is a familiar point to those who know anything of Freudian theory.
But there is, perhaps, one crucial objection to the constructivist's claim that moving the focus away from mental representations and towards mental actions will make the mind-body problem appear to us as less of a problem.
It is this: saying that the character of ‘mental representations’(beliefs and imaginings, for example) can be understood only in terms of a history of activity, or that it is the subject's conception of himself as active in relation to the world which gives these ‘representations’ their ‘content’or ‘semantics’(I hope to have shown something like this) is simply irrelevant to the mind-body problem.
This is the problem of how mentality — call it ‘mental representations’ or ‘cognisant acts’— relates to its physical realization in the brain.
The constructivist thesis, it is argued, is not relevant because mental representations have not been defined away and replaced by talk of actions: we still have to say how mental life as we know it to be, with the representational character that we naturally give to it, relates to neuronal life.
The only interesting claim that the constructivist can make here, the objection runs, is that there is a prospect of translating all representational language into action language — with a host of adverbs, perhaps?
If that is what is intended, the objector would say, then constructivism is nothing more than a kind of behaviourism (another attempt to replace the mental by the behavioural); or perhaps we might lump it together with Marxist attempts to ‘resolve’ the mind-body problem in terms of‘praxis’.
That is hardly a solution: it merely changes the subject from the mental/physical relationship to the behavioural/physical relationship.
What can I say in answer to this charge of irrelevance?
I will take the example of an experience about whose veridicality a subject is undecided.
I do this simply to bracket off questions about how experiences relate to the world and thus to concentrate on the question of subjectivity.
Here is the example.
Having just been reading a bright-red leaflet we glance up to a plain, white wall — at which instant we see a green patch.
For a second or so we are undecided about whether the patch is an after-image or a spot of mildew on the wall.
What we do know, however, is that we are seeing a green patch, and our experience has a particular, qualitative — indeed paintable — character.
How is a ‘cognisant episode’ such as this going to be analysed away into the language of activity?
Well clearly it is not going to yield to any such analysis, and to believe that it will is to deny the reality of subjective life and to side with the behaviourists.
What I can say, however, is that the constructivist position allows a distinctive analysis of the ‘mental’ when we speak of a ‘mental representation of a green patch’: it helps us to understand the difference between mental representations and the non-mental variety (a photograph for example).
At the time of looking up we ascribe an experience of greenness to ourselves; we consider the experience as something being undergone by us before any decision is taken about its veridicality.
Such an ascription is a cognisant act involving, at the very least, a conception of a one's self, a conception of experience, and a conception of veridicality.
As I argued, given the holism of the mental, we are not going to succeed in analysing these conceptions in terms of some complex causal interplay between determinate representations.
We can, however, make some attempt at understanding the cognisant act on the model of a physical act.
And that is — I am afraid -as far as it goes.
The constructivist says that we should regard the problem of how it is possible to act at will as the best philosophical and psychological road to the problem of mentality.
This problem is difficult enough; but starting from the nature of mental representations, considered as entities poised somewhere between subject and object, guarantees failure.
I admit that this constructivist way of thinking hardly ‘solves’ the mind-body problem.
But I doubt that it is irrelevant to it.
Notes
1.
Stephen Stich (1983) presents a case for a syntactic theory of mind which is more radical than Fodor's.
He argues that the language of folk psychology (talk about ‘beliefs’, ‘desires’ and the like) may float free of the kind of mental states that actually do the computational work: these are defined solely by their syntax and causal role, not by their reference.
He spends a lot of time saying why this way of regarding syntactic mental states does not encounter the problem of the holism of the mental.
2.
This means the process of assigning syntactic roles to elements of a sentence: noun phrase, prepositional phrase, adverb, etc.
In the dedication of his book, Fodor says that the following remark by the psycholinguist Merrill Garrett had a strong influence on his thesis: ‘
What you have to remember about parsing is that basically it's a reflex’.
3.
The more precise terms that he uses are ‘isotropic’ and ‘Quinean’(after the philosopher W. V. O. Quine).
The former means that anything in the domain of belief is potentially relevant to what is being considered; the latter means that the falsification or verification of propositions is done relative to their status in a scientific theory (and, by extension, in a belief system).
4.
The main influence on thinking in this area is the work of the late David Marr (e.g. in Vision ).
He described three levels of representation in the process of vision and three levels of explanation.
5.
Perhaps the best place to begin reading Piaget in the original is Piaget and Inhelder,The Psychology of the Child .
Piaget's The Child's Construction of Reality (1955) is probably the best source of the constructivist thesis.
Boden has written an excellent shod introduction to the theory.
Piaget is not the only constructivist.
The philosopher Mark Johnson has recently produced what can only be called a constructivist account of linguistic meaning and reasoning.
6.
This presents the problem for the constructivist of how to regard beliefs .
To be consistent with holism the constructivist has to say that individual ‘beliefs’— mental states that are only in the running for truth — do not correspond to anything in the mind.
This is then, in Fodor's (1987) terms, not a ‘realist’ theory of belief.
Paradoxically, constructivism would side with Stich (see note 1) about the unreality of belief.
7.
The principal technique for testing babies' perceptual and cognitive capacities is the ‘habituation-dishabituation’ technique.
(This does not, unlike the Piagetian methods, rely on the baby doing anything intentionally — such as reaching.
It allows the psychologist to determine whether the subject has detected a change in a stimulus or can discriminate between two stimuli.)
Initially the subject will attend to a new stimulus but will then gradually lose interest and start to look away (habituation); if the stimulus is then changed in some way and if this causes a re-awakening of interest (dishabituation) then we can assume that the baby has detected the change.
Another technique is ‘preferential looking’.
If the subject prefers to look at one stimulus rather than another we can assume that he has detected a difference between them.
8.
This idea had a great influence upon the thinking of Schopenhauer who followed up its implications more thoroughly than did Kant. 9.
The term ‘refractory’ is taken from the theorist James Mark Baldwin.
He had a considerable influence upon the thinking of  Piaget.
See Russell,The Acquisition of knowledge , for a comparison of the two.
10.
Baillargeon used the habituation-dishabituation technique — see note 7. 11.
Phenomenology is the method of enquiry developed by the philosophers Brentano and, later, Husserl.
In this, all assumptions about external reality are suspended (‘bracketed’) and the theorist focuses entirely upon his field of immediate experience.
It is not a million miles away from Fodor's ‘methodological solipsism’— though phenomenologists have little interest in the causal interplay between the mental states thus identified.
The Mind in the Laboratory
Richard Latto
We have the technology
The increasing power and sophistication of computers is advancing the brain sciences in two ways.
It has improved our ability to model cognitive processes, both as a spin-off from the computations necessary to create artificial intelligences and through the computing metaphors used in cognitive psychology.
(See the discussions of these developments elsewhere in this book, particularly Chapters 4 and 7.)
And it has led to the introduction of new technologies for the direct investigation of the relationships between brain, behaviour and external events, the subject of the present chapter.
Most current procedures for recording the electrical activity of the brain, or producing radiographic images of the living human brain, or investigating the accuracy and timing of behaviour are dependent on computing capacity which was not available twenty years ago.
But many of the techniques which computers are enabling us to exploit are not new.
By 1875, the Liverpool physiologist Richard Caton had detected tiny fluctuations in voltages present on the surface of the brains or scalps of monkeys, cats and rabbits.
More significantly, he also realized that this electrical activity was affected by external stimuli falling on the sense organs.
Fifty-five years later, Hans Berger, a psychiatrist working in Jena, reported similar fluctuations in humans and discovered that, in a resting subject, this electroencephalogram (EEG) oscillated at a regular eight cycles a second, a pattern he called the alpha rhythm.
This disappeared if the subject was alerted by a noise or touch.
Edgar Adrian, in Cambridge, subsequently demonstrated the importance of the visual cortex at the back of the brain in generating alpha waves and the particular effectiveness of visual stimuli in blocking them.
In one especially striking experiment, the alpha waves disappeared when the subject imagined a visual scene.
It began to seem a possibility that an external observer would be able to predict whether or not an apparently relaxed subject was forming visual images.
Another exciting window on the mind seemed to open up in Chicago in the 1950s when Nathaniel Kleitman and Bill Dement  began using the techniques of electroencephalography to investigate sleep.
Sleep could be divided into a number of different phases which recurred at regular intervals throughout the night.
One of these phases was known as paradoxical or rapid eye-movement (REM) sleep.
It was paradoxical because although the subject was very deeply asleep, being completely relaxed and more difficult to wake than at any other time during the night, the EEG pattern was that of alert wakefulness.
At the same time there were bursts of rapid eye-movements and muscular twitches in other parts of the body.
Dement's discovery was that when subjects were woken during REM sleep they nearly always reported that they were dreaming.
Later research has shown that dreaming is not unique to this phase of sleep, but REM dreams are typically much more colourful and rich in imagery than non-REM dreams.
So again, laboratory techniques were affording scientists a glimpse of their subjects' mental lives.
The brain is not only an electrical machine, it also has a physical and chemical structure and these too are now being monitored in the living brain.
By using computers to integrate the information from a large number of different viewpoints round the skull, it is possible to visualize the appearance of a slice through the brain and build up a full three-dimensional image.
The viewing medium can be X-rays, as in computerized tomographic (CT) scans; magnetic resonance of atomic nuclei, as in nuclear magnetic resonance (NMR) scans; or emission from radioactively labelled substances incorporated into the structure of nerve cells as in positron emission tomographic (PET) scans.
These obviously have considerable clinical value for localizing and identifying areas of brain abnormality, but they also enable areas of activity in the normally functioning brain to be pictured.
The resolution of these pictures is still relatively coarse and they produce only a stationary image at a single moment in time.
Nevertheless, they have demonstrated activity in the visual areas during an imaging task, in the language areas during a verbal task and even, on one -occasion, in the higher visual areas of a schizophrenic patient who subsequently reported that he had been hallucinating.
Remarkable as these observations are, they are currently only confirming what was known already about localization within the brain.
All these EEG and scanning techniques are, so far, giving us only very rough correlations between brain structure and function and mental processes.
More important, the mental processes being studied are still only crudely defined.
A different and apparently much more specific line of research, however, developed from another of Adrian's electrophysiological experiments.
While studying the relationship between visual stimuli and the EEG, Adrian found  that if a regular series of bright flashes was presented to the subject's eyes there was an equally regular series of blips in the EEG recorded from electrodes on the scalp over the visual areas at the back of the skull.
These little potential shifts, known as either evoked potentials (EPs) or event related potentials (ERPs), are normally buried in the random background activity of the EEG.
They can be reliably dug out again only by averaging over many presentations so that the random background fluctuations cancel each other out, leaving just the potential shifts that are linked in time to the triggering event.
Averaging of this kind was first done at the National Hospital in London in the 1940s by George Dawson, initially using a technique of photographic superimposition and then later a system of addition using banks of condensers, but it was the electronic processing and computing power of the 1960s and 1970s which made the accurate timing of these averaged potentials possible, resulting in a rapid expansion in ERP research.
Since then, correlations have been reported between potential shifts and a wide variety of different events, ranging from simple and complex sensory stimuli to whole sequences of behaviour or even internally generated mental events.
It is now being claimed that the ERP allows the objective monitoring of well specified mental activities.
As Fergus Campbell has suggested, if the ERP can tell us whether or not the subject has seen a light, it takes the psycho out of psychophysics.
It enables the scientist to say something about the internal experiences of others without the tedium of having to ask the subjects themselves.
The central consideration of this chapter is the validity of these claims and their significance for our understanding of the mind-body relationship.
We know what you're thinking
Are you ready?
Benjamin Libet of the University of California at San Francisco has been responsible for two sets of experiments which are often cited as crucial evidence in the debate about the relationship between brain and mind.
In 1979 he published a paper showing that the perception evoked by stimulating the skin or the neural pathway between the skin and the cortex was reported by the subject as occurring a few hundred milliseconds before the cortical ERP was sufficiently complete to generate that perception.
In earlier work, he and others had established that the cortical-evoked potential, and also direct cortical stimulation, had to persist for several hundred milliseconds  before subjects reported feeling anything.
Then in the 1979 paper he found that subjects placed the time of occurrence of this sensation only a few milliseconds after the peripheral stimulus which evoked it.
So although the ERP had to persist for several hundred milliseconds before the subject felt anything, they nevertheless reported that the sensation had occurred at the moment when the ERP was beginning.
Libet concluded from this that the subjective experience was occurring before the neural events which bought it about.
This apparently backward causality, if true, would cause problems for identity theories of mind and has been used by dualists like John Eccles to support their position, with the backward step in time made by a non-physical mind.
Libet's second set of experiments, described in 1985, is even more striking.
About a second before a subject moves a part of his body, a slow negative shift in the electrical potential generated by the brain begins.
This effect, which is strongest over the frontal lobes, was first observed in 1964 by Grey Walter, who called it the Contingent Negative Variation.
More recently, and perhaps begging the question of its mental significance, it has come to be known as the Readiness Potential (RP).
In Libet's experiment, subjects were asked to move their hands at random times of their own choosing.
Averaging the EEG over forty such self-initiated movements, Libet found that there was indeed a time-locked negative shift beginning about 550 msec before the movement.
Whatever the particular significance of these RPs in terms of information processing, it is reasonable to conclude with Libet that 550 msec is the minimum interval by which neural activity precedes a self-initiated, and therefore presumably voluntary, movement.
At the same time, Libet set up a procedure for allowing subjects to report the time at which they first experienced the conscious intention to act.
This was done by asking them to report the position of a dot moving round an oscilloscope screen at the moment of the experience.
Knowing the time the dot was in any particular position, Libet was able to calculate that on average the experience of the conscious intention to act was reported as beginning about 200 msec before the movement began.
Subtracting these 200 msec from the 550 msec by which the RP preceded the movement, Libet concluded that the neural activity associated with an apparently voluntary act began some 350 msec before the first moment at which the subject was aware of his intention to act.
So, he argued, the ‘cerebral initiation of a spontaneous voluntary act begins unconsciously’(Libet, 1985).
If accepted, this somewhat paradoxical suggestion leaves the problem of finding a role for consciousness in voluntary acts.
Libet speculates that it may ‘function in a permissive  fashion, either to permit or prevent the motor implementation of the intention to act that arises unconsciously.’
The marginalization of consciousness in this way would certainly make life simpler for those attempting to understand our cognitive processes, but unfortunately Libet's conclusions do not follow from his data.
The problem with the conclusions in both sets of experiments is that they are based on the assumption that we can infer when an experience occurs from a subject's verbal report.
In each case, the subject was reporting which other event a particular experience was synchronous with.
But, and this is Libet's error, what the subject was actually comparing was the time at which two experiences were occurring.
We have no way of knowing exactly when these experiences took place.
All we can reasonably conclude is that they happened at the same time.
A much more likely explanation of Libet's findings is simply that all experiences are delayed relative to the stimulus causing them, so that synchronous external events produce synchronous experiences.
(Another useful illusion is that of the instantaneity of experience.
We have to view a stimulus for a finite time before it generates a perception, but that perception appears to us to occur instantaneously rather than fading into view like the Cheshire cat.)
But there is no way we can test for this hypothetical delay.
Subjects are always limited to making judgements about experiences; experimenters are stuck with observing physical events like evoked potentials, verbal reports and button presses.
There is no way in which the time of occurrence of an experience can be related to the time of occurrence of a physical event without assuming answers to the questions Libet is asking.
(One, untestable, assumption which most reductionists would make is that conscious experiences cannot precede the neural events underlying them.)
So Libet's experiments tell us something interesting about the information processing going on in the subject's brain but they tell us nothing about the temporal relationship between physical events — either inside or outside the brain — and conscious experiences.
There is another, apparently much more fundamental although philosophically less interesting, criticism of Libet's work.
Perhaps the particular potentials he is recording are not causally linked with the conscious experiences he is investigating?
Given that there are good correlations between the two, this would imply that they are both being caused by a third, unidentified event.
This event would presumably precede the potentials being recorded and it could provide an explanation for the apparent referral back in time in the first set of experiments, although it does seem electrophysiologically unlikely that there could be a neural change  happening sufficiently early after the triggering stimulus.
But in the second set of experiments, a neural event preceding the RP would only serve to make the effect Libet is claiming even more striking and alternative explanations still need to be sought.
Get set
Libet was investigating the processes underlying a decision to move; that is, the ERP that precedes a movement.
But most human electrophysiological work has been concerned with the processing of incoming events, that is the ERP that follows the presentation of a stimulus.
When, for example, a subject fitted with scalp electrodes over the auditory cortex is played a series of brief clicks through headphones and the EEG following each click is averaged so that random fluctuations cancel each other out, what is left is a systematic but complex pattern of electrical waves which is caused by the click in the same way that the waves on the surface of a pond are caused by dropping a pebble into it.
The first fifty or so milliseconds of these waves are the most consistent for any particular stimulus and it is thought that they are almost entirely generated by the incoming stimulus, irrespective of any mental activity on the part of the subject.
These early components of the ERP are therefore usually called exogenous.
After fifty milliseconds the waves are more labile.
Some of them are still exogenous and can be modified only by varying the stimulus, but some of them now seem to depend mainly on the way the subject is processing the stimulus.
It is these internally generated or endogenous components, lasting sometimes as long as a second after the triggering stimulus, which offer the most potential for investigating mental activities.
ERPs are very slippery customers.
Even those who most strongly advocate their use as research tools would admit that we do not know exactly what neural processes generate them and that any particular fluctuation will be the result of a multiplicity of different kinds of changes occurring in several different and possibly independent systems.
Some of these changes will be related to neural processes that have little psychological relevance.
Nor is there any reason to suppose that the peaks and valleys of the fluctuations have greater neural or psychological significance than any other intermediate point.
So sorting out what is going on in an ERP is like untangling a complex bundle of many different strands of similar wool with one hand tied behind the back.
Given this, the progress that has been made is remarkable, particularly in relating components of the ERP to attentional processes.
Whether or not we perceive an event in the world around us  depends on three things.
First, it has to fall within our viewing window: we have to have the right apparatus to receive and process the information signalling the event.
Thus, we can perceive the sound emitted by a piccolo but not that from a dog whistle.
Second, we have to be sufficiently alert: the apparatus has to be switched on.
If we are drowsy we may not hear either the piccolo or the dog whistle.
Third, in certain circumstances, we have to be attending to the stimulus: the apparatus has to be tuned in correctly.
In a complex orchestral passage, we shall probably not be aware of the piccolo unless we are specifically listening out for it.
This facility for selective attention increases the processing power of our brains enormously by enabling us to direct our limited processing capacity where it is most needed.
It is clearly under voluntary control: we can decide who to listen to in a crowded room and who to shut out.
And it is extremely sophisticated: we can pick out our chosen voice from an overlapping background of very similar sounds.
From William James at the end of the last century to the present day, psychologists have speculated and experimented to discover how this is done.
A stimulus will generate an ERP only if it falls within our sensory window and the size and form of that ERP will vary according to our general state of alertness, of which alpha blocking is one important indicator.
Even more strikingly, the ERP will vary according to whether or not we are selectively attending to it.
As early as 1957, Michel Jouvet in Lyons had reported that the size of the ERP generated by a visual stimulus from the occipital cortex at the back of the brain, a primarily visual area, decreased when the subject was asked to attend to an auditory stimulus.
Working with Raúl Hemández-Peón, he also showed that the auditory ERPs generated in the neurons in the cat's ear almost disappeared when a salient visual stimulus, for example a mouse, was brought into the cat's field of view.
So this damping down of the sensory input when attention moves elsewhere can occur very early in the pathway from the sense organ to the brain.
These early experiments were sometimes difficult to interpret, but the general finding that the form of the ERP is affected by shifts in attention has proved very reliable.
Recent experiments on the psychophysiology of selective attention by, for example, Steven Hillyard at San Diego and Emanuel Donchin at Illinois have successfully related different endogenous components in the ERP to different stages in the process of selective attention.
Suppose a subject is listening to different sequences of sounds played independently to each ear through a pair of headphones in order to pick out and respond to a particular target sound.
If the subject is instructed to attend to one ear and ignore the sounds coming into  the other ear, all the sounds in the attended ear will produce an enhanced N100 component in the ERP.
(The name N100 indicates a systematically occurring negative shift in the ERP which peaks about 100 msec after the stimulus.)
This enhancement is thought to be associated with the extraction of additional information about the stimuli in the attended ear.
A more subtle distinction affects a later component, the P300 (a positive shift peaking 300 msec after the stimulus).
For while all stimuli in the attended ear give an enhanced N 100, only those sounds which the subject, correctly or incorrectly, identifies as the target stimulus will result in an enhanced P300.
So the P300 is thought to be associated with the completion of stimulus identification and classification in preparation for a cognitive or motor response.
Late waves like the P300 and the more recently identified N400 are by far the most cognitively interesting of the ERP components.
The P300 was first described in 1965 by Sutton.
It is generally elicited only by stimuli that are both infrequent (or improbable) and significant in the sense that they require some kind of response by the subject.
Its purely endogenous nature is well illustrated by the facts that it can be evoked by the absence of a stimulus such as a gap in a long sequence of evenly spaced tones and that the actual probability and significance of the stimulus is less important in determining whether or not the P300 will occur than the subject's perception of its probability and significance.
The most cognitively complex association with an ERP was found in 1980 by Kutas and Hillyard for the N400 wave.
This is elicited, after the very long delay of 400 msec, by the visual presentation of a semantically improbable word (for example, the word ‘socks’ in ‘He spread the warm bread with socks’).
Meaning seems to be the crucial factor, since the presentation of a grammatically inappropriate word or an appropriate word in a new and unexpected typeface does not evoke an N400 wave.
And the finding that it takes 400 msec to generate the electrical activity associated with the meaning of visually presented words suggests that this is one of the most complex activities our perceptual systems are asked to perform.
These experiments tell us a great deal about certain aspects of cognitive processes, particularly their relative timing or sequencing.
They also provide circumstantial evidence for a close relationship between mind and brain.
They have shown that mental processes can be correlated with specific neural changes.
This is a necessary condition for a reductionist view of the mind but, particularly given the absence of any effective demonstration of a causal connection between the mental and the neural, it is certainly not a  sufficient condition.
(The many demonstrations, in neuropsychological experiments of the kind discussed in Chapter 4, of the loss of mental processes caused by the loss of neural processes are more powerful here.)
But the electrophysiological examples I have described go some way to countering Wittgenstein's negative assertion: ‘No supposition seems to me more natural than that there is no process in the brain correlated with associating or with thinking; so that it would be impossible to read off thought-processes from brain-processes’(Zettel, paragraph 608, Anscombe's translation, 1967).
There may of course be some mental processes for which no neural activity exists, but such an awe-inspiring negative could not be proved until we knew the place and function of every least sub-atomic particle in the human brain.
And the more links that are discovered between mental and neural processes, the smaller the dualist gap becomes.
What have we found?
It is an act of faith of most brain scientists, including, as must be obvious by now, this one, that an understanding of the brain will lead to an understanding of behaviour and of the processes that control and underpin behaviour, some of which are conscious and some unconscious, but which taken together correspond to the folk-psychological term ‘mind’.
Indeed brain-mind identity is more than a belief, it is a hypothesis which seems to be the simplest explanation of the mind-brain problem, if it is a problem, and therefore one which parsimony requires us to accept.
Further, although this hypothesis has not yet resulted in an account incorporating consciousness, it has been remarkably successful in explaining many other mental phenomena which earlier generations saw as necessarily mysterious and as evidence for some kind of duality.
Joan of Arc's hallucinations were not so much the voice of God as the voice of some aberrant neurons in her temporal lobes.
Electrophysiology allows us to correlate one set of observable physical events (electrical activity in the brain) with another (the behaviour, including the behaviour of reporting experiences, of the subject being recorded from).
It is important to remember that the linguistic utterances of others are just as much externally observed behaviour as walking down stairs or pressing a button in a psychophysics laboratory although, because of the high information content of linguistic behaviour, we are prone to endow it with some mystical quality which opens a special window on to the mind of the person generating it.
We must approach observations of linguistic  behaviour with the same careful attitude as we approach other kinds of behaviour or indeed as we approach our electrophysiological observations.
It is also worth noting that correlations between ERPs and behaviour are never perfect, perhaps because of masking of some of the ERPs by random fluctuations of the background EEG.
An individual event which normally gives a particular ERP may sometimes yield nothing and the ERP may sometimes occur in the absence of the evoking event.
It is always the case that averaging over tens of trials is necessary to give consistent results, particularly with endogenous ERPs.
So it is not yet possible to say with absolute certainty, using evoked potentials that are correlated with reports of conscious mental events, whether or not an individual external event has resulted in a particular mental event.
Further, the need for averaging obviously favours repetitive responses to repetitive stimuli and neural events that do not correlate in a consistent time-locked way with external stimuli will necessarily be overlooked.
This weakness must become more severe as we move from investigating relatively simple sensory and motor processes to the study of high level cognitive processes.
All of these observations of correlations between ERPs and different kinds of behaviour, including phenomenological reports, may tell us something about mental representations and the cognitive processes generating them, but they can tell us nothing about whether these representations and processes are conscious or unconscious.
It is the essential but usually overlooked fact that in any psychophysical experiment when, for example, subjects are asked whether or not they perceive a stimulus, their responses, verbal or otherwise, cannot be relied on as accurate accounts of their conscious experiences.
So, in a near-threshold task the subject may be accurately identifying the presence of a stimulus which tells the experimenter that there is some kind of mental representation of the stimulus, but there is no way the experimenter can decide whether or not the subject is consciously aware of the stimulus.
Indeed, it is a common observation in experiments of this kind that subjects themselves often express confusion about what they are conscious of.
The problem arises whenever we try to use conscious awareness as a dependent variable: for example, when we want to decide whether or not a particular external event leads to a phenomenal event.
This is an area of some controversy at the moment in psychology, where one of the holy grails is the attempt to provide empirical evidence for the intuitively reasonable idea that there can be a dissociation of behaviour from consciousness.
This is a phenomenon which most  of us experience from time to time, particularly when performing a highly practised task like driving a car or using a keyboard, and which the clinician often feels presents in exaggerated form in certain neurological conditions.
The term ‘blindsight’ was coined by Larry Weiskrantz at Oxford to describe perhaps the best known example of this dissociation, in which patients with damage to the visual areas of the cortex deny being able to see a visual stimulus while behaving in some respects as if they are processing it, for instance by moving their eyes in its direction.
The difficulty here is the same as the one already encountered with the attempt to relate evoked potentials to conscious events.
We only have the subjects' external behavioural indicators (verbal or non-verbal) of their experiences and we have no way of validating these indicators.
So we end up dissociating one piece of behaviour from another: in ‘blindsight’, the verbal response ‘No, I did not see the light’ is dissociated from the ability to move the eyes towards the light.
This, I would argue, though not all would agree, may tell us something interesting about the way the brain compartmentalizes different aspects of visual processing and it may tell us that subjects are more conservative about admitting to seeing a very degraded image than about trying to move their eyes to it, but it sheds little light on the actual experiences the patients are having when we show them a light.
There is an elegant circularity in trying to prove that behaviour can be dissociated from conscious awareness by using behaviour to indicate the absence of awareness.
I am not suggesting that we should be completely sceptical about the value of introspection.
There are some circumstances in which accounts of conscious experiences may be very useful in suggesting hypotheses about the nature of cognitive processes.
The still influential contribution of Köhler and the other Gestalt psychologists to elucidating the rules underlying pattern perception is a major example.
But when we talk about our conscious experiences we are providing our listener with only a very crude approximation to the actual phenomenal content of experience.
(Interestingly, one of the functions of art is the attempt to refine this process of communicating mental states and the accounts of the artist can sometimes be a more useful guide to the nature of cognitive processes than naïve introspection.)
What I am suggesting is that introspective reports, while often providing helpful qualitative information, can never be reliable enough to use as quantitative data defining the presence or absence of conscious awareness.
Returning to the central theme of the present chapter, electrical activity can be correlated with behaviour and this helps us towards an understanding of the neural mechanisms and cognitive processes  underlying behaviour.
It does not enable us to say anything directly about the nature of consciousness.
But then an understanding of consciousness, for all its fascination, is not necessary to the production of an adequate model of cognitive behaviour.
While consciousness may be central to an understanding of one's self, it is marginal to an understanding of other people.
Consciousness in other people is a hypothesis for which there is circumstantial evidence in their verbal reports which match, by-and-large, our verbal reports of our own experiences.
(This implies of course that consciousness in animals is a hypothesis for which there can be no evidence at all unless we resort to anthropomorphism, which we usually do.)
Most psychologists accept that cognitive processes, and therefore ‘mind’— although this is a term not widely used in the brain sciences -encompass both conscious and unconscious activities.
Clearly, conscious processes are central to an individual's own experience, but most of us remain neutral as to whether they are central to cognitive processes given that many, if not most, of these are not conscious.
It also follows from this that understanding consciousness would not be sufficient for understanding mental processes.
So current cognitive models of language, memory, perception and so forth are also basically neutral to the question of consciousness.
They discuss how information is processed to achieve a particular end (storage and retrieval in memory, for example), but they say nothing about the borderline to be drawn between the conscious and unconscious parts of these procedures.
What remains uncertain is whether consciousness is a separate phenomenon which needs explaining, like language or vision, or whether it is simply an attribute of certain neural processes in the same way as high reflectance is an attribute of the piece of paper you are looking at while you read this, something which is simply part of the physical characteristics of the brain or the paper.
Indeed, the evidence we have from cognitive psychology of the overwhelming predominance of the unconscious over the conscious parts of mental processes suggests that consciousness may be as peripheral to the central information processing activities of the brain as the whiteness of this paper is marginal to the semantic content of the words printed on it, which are telling you what I think about the mind.
Cognitive Neuropsychology and the Philosophy of Mind
J. Richard Hanley
Introduction
Clinical neuropsychology involves the study of the effects of brain injury on human behaviour.
What neuropsychologists are trying to do is to come to some understanding of the way in which damage to the brain impairs abilities such as memory, perception and the use of language.
Within the last two decades, a new approach to this subject has assumed great influence.
This new approach is known as cognitive neuropsychology , and it attempts to explain the impairments which neuropsychological patients unfortunately experience within the vocabulary of cognitive psychology.
One of my main goals in this chapter is to describe the nature of cognitive neuropsychology, and to account for its pre-eminence.
However, this is a book about the philosophy of mind rather than experimental psychology, and the main point that I want to make is rather more philosophical than psychological.
Consequently, I am going to start off by outlining some of the philosophical beliefs about the nature of mind which underpin contemporary research in the cognitive sciences, including cognitive neuropsychology.
This will involve a brief discussion of the approach known in contemporary philosophy as functionalism .
The basic theme of this chapter will be that the success of cognitive neuropsychology provides strong grounds for believing that functionalism, or something very close to it, is actually true.
Functionalism as a Philosophy of Mind
The functionalist approach to the study of mind characterizes much of the work currently being done in cognitive psychology, artificial intelligence and linguistics.
Unlike classical behaviourists, functionalists believe that is not possible to explain intelligent behaviour unless we make reference to processes that are taking place inside a person's head.
Now, of course, nobody denies that  certain processes (blood flow, neural transmission etcetera) occur in the brain and that behaviour would be impossible without them.
What is controversial about functionalism is its claim that we are going to be able to make significant generalizations about behaviour only if we think about what is going on in the brain at a particular level of description.
If we confine ourselves to explanations couched in the vocabulary of physics or neurochemistry, then we are going to lose, or fail to formulate, a vitally important set of generalizations about human behaviour, and science will never be able to explain or predict behaviour in a satisfactory way.
According to functionalism, it turns out that the appropriate level of description is the same as that which characterizes folk psychology , the psychological theory that ordinary people use when predicting and explaining the behaviour of their fellow human beings in the course of their everyday lives.
Functionalists, therefore, attempt to explain behaviour in terms of mental concepts such as beliefs, thoughts, desires and memories.
Behaviour comes about as a result of the interaction of these mental processes with each other and with the environmental stimuli that are constantly impinging upon our sensory systems.
This is not to say that folk psychology already has adequate theories of perception, language, memory or any other cognitive process.
Indeed, the data from patients with brain injury that I will be discussing in the final two sections are very puzzling indeed from the standpoint of folk psychology.
The point is simply that the account of mental processes which folk psychology provides, constitutes an explanation at an appropriate level of abstraction for the purposes of explaining behaviour scientifically.
It should be emphasized that this level of explanation does not commit the functionalist to a belief in any non-physical substances or processes.
Most, perhaps all, functionalists are thorough-going materialists who believe that mental phenomena are genuine physical phenomena seen at a particular level of abstraction.
This commitment to materialism means that a couple of standard dualist objections must be faced.
First, there is the dualist's argument that mental processes cannot be physical processes because physical entities — such as neurons -lack certain qualities — such as intentionality or consciousness — that characterize the mental.
The response to this is that intentionality and consciousness are emergent properties of physical systems.
Neurons do not individually have the property of consciousness, consciousness emerges when a large number of neurons are interacting in the right kind of way; just as speed is a property not of any single component of a car, but an emergent property of the whole system  when it is operating in an appropriate way.
Of course, nobody as yet knows how intentionality — the property that mental phenomena have of being about something other than themselves — or consciousness emerge from the operations of the brain.
From the perspective of functionalism (and from the perspective of other materialist theories also), however, this is a question for science rather than an imponderable problem of metaphysics.
Searle (1984, pp. 18–21) strongly supports the view that intentionality and consciousness are emergent properties, but there is at least one important difference between Searle's account of emergent properties and the one I am advocating here.
I have no quarrel with Searle's claim that ‘mental phenomena are caused by processes going on in the brain’.
When he states subsequently that ‘mental phenomena just are features of the brain’, thus tying mental phenomena very rigidly to the brain itself, then I dissent.
The functionalist view I advocate is that mental phenomena emerge as a result of the way that the neurons etcetera are functionally organized in the brain, not as a result of the physical properties of neurons per se .
As Churchland (1988, p. 37) has put it, ‘what is important for mentality is not the matter of which the creature is made, but the structure of the internal activities which that matter contains’.
Consequently, mental phenomena could emerge from a physical system which does not contain neurons at all, if its physical components were arranged together in a particular way.
Most important, there may be no interesting similarity whatsoever that could be formulated in the vocabulary of physics between such a system and the brain.
This might even include the nature of the emergence of the mental from the physical itself.
Only at the functional level would the two types of system be equivalent.
The second question which an opponent of dualism such as a functionalist must face, concerns the alleged privacy of the mental.
It is true that we cannot observe or measure directly mental processes taking place in the brain in the way that we can measure, say, blood flow via a brain scanner.
This does not mean however that mental processes are in some way divorced from the physical world, nor does it mean that they should be excluded from the subject matter of natural science.
From a functionalist perspective, mental processes are inferred processes — they gain their status in our theoretical base not as a result of being directly observed or experienced, but from the way in which they enable us to understand and explain human behaviour.
They exist, theorists believe, because they help us to see the world as it really is.
Their ontological status is therefore every bit as secure as the status of unobserved  theoretical entities in other sciences (for example quarks in subatomic physics).
What this means, of course, is that functionalists do not see consciousness as a defining feature of the mental.
Since the time of Freud, it has been acceptable to many theorists that the way in which we behave may be powerfully influenced by mental processes to which we have no conscious access.
This is not to say that functionalists would be in sympathy with Freud's belief that certain unconscious mental processes are so anxiety-provoking that they must not be allowed to enter awareness.
They simply share the belief that it is not going to be possible to explain behaviour adequately if mental processes are identified with the contents of conscious awareness.
Let me emphasize here that functionalists are happy to accept that many of our mental states are associated with conscious awareness.
They are also happy to accept that it is only because we have these mental states that we behave as we do.
Behaviour is genuinely caused by the interaction of such mental states.
Such views are very different from those that would be associated with behaviourism or epiphenomenalism, neither of which allows mental states any causal role in the production of behaviour.
Furthermore, the work of Young and his colleagues, which I shall be discussing later in the chapter, shows that being aware of the operations of, say, one's face processing system has vitally important functional consequences.
However, the functionalist view is that it would be quite misguided to attempt to explain behaviour by making direct reference to the subjective or phenomenal qualities (technically known as qualia ) of these mental states.
If it is really necessary to think of mental states as having qualitative content (and see Dennett, 1988, for some powerful arguments that it is not), then it follows from functionalism that such qualia do not have causal interactions with other mental states or behaviour and are mere epiphenomena.
Successful Science
The sceptic might, at this point, complain that while I may have sketched out the functionalist position, I have not provided any convincing arguments as to why one should believe it.
What I now want to suggest is that there is a lot of very successful science currently being conducted which literally depends on functionalism being true.
If functionalism is false, then the success of the cognitive sciences is a massive scientific fluke.
My argument for functionalism  is therefore critically dependent on whether or not I can convince you that progress in one of these areas — cognitive neuropsychology — is unlikely to be simply an illusion.
In this section, I will set out what I believe to be the basic characteristics of a flourishing, as well as an unsuccessful, approach to science.
I will then attempt to evaluate cognitive neuropsychology in terms of these criteria.
Science exists so that we can improve our understanding of naturally occurring phenomena.
Understanding in this sense means being able to perceive structure amongst a set of observations that were at first sight perplexing and confusing.
When we identify such a structure, then it means that we can successfully explain our observations in terms of concepts that we genuinely understand already.
What are the signs that tell us whether or not we are making genuine progress in a particular area of study?
First, we should be able to explain a relatively large set of observations in terms of a much smaller set of more general theoretical principles.
Second, these principles should then lead us on a successful search for phenomena that we had not observed previously.
Then, as we encounter fewer phenomena that genuinely puzzle us, so our faith in the explanatory adequacy of our theoretical base increases.
Why might an attempt to explain a particular set of phenomena flounder?
Perhaps the most obvious cause of failure is an inability to perceive the pattern that exists in nature.
There would appear to be at least two different reasons why this might be so.
First, it may be that no one(as yet ) has made the critical observations which would allow the pattern to become evident.
In this situation, ‘further research is necessary’ and, when controversy arises, it is likely to occur between those who actually share a large number of fundamental theoretical assumptions.
Secondly, a failure to perceive the pattern may also occur because we lack within our theoretical base the conceptual framework that would enable us to grasp the structure that is potentially available, given the observations that we have made already.
For example, we apparently only came to some understanding of how the heart worked when we had within our conceptual framework the notion of a pump .
In such a situation, further collection of data may be pointless in the absence of any fresh conceptual insight.
There is, however, a more fundamental reason why an attempt to perceive a structure within a given set of phenomena may fail; it may be that there actually is no structure there to be perceived in the first place.
Plato said that we should attempt ‘to carve nature at its joints’.
The implication, contrary to relativism, is that certain things (referred to in the contemporary literature as ‘natural kinds’) simply belong together.
If we attempt to put the wrong type of things together, or attempt separate explanations of things which are part of the same natural kind, then we are going to struggle to produce successful science.
We won't produce any interesting generalizations, we won't succeed in predicting new phenomena, and the world will remain every bit as confusing as it was previously.
Cognitive Neuropsychology
Case Studies and Group Studies
Cognitive neuropsychology is the attempt to draw parallels between models of cognitive function and the patterns of performance observed in patients who have suffered Brain injury.
There are two basic questions.
First, can we explain the impaired performance that these patients produce in terms of our functional models?
Second, can we learn anything new about the nature of the underlying cognitive processes from studying these unfortunate individuals?
Cognitive neuropsychology is largely a European rather than a North American phenomenon.
The vast bulk of the neuropsychological work performed in the United States to investigate cognitive processes uses group studies as in, for example, the investigation of human amnesia (severe loss of long-term memory function as a result of brain damage).
A set of amnesics is first assembled on the basis of their low scores on a clinical memory test.
Their performance on some task is then evaluated by comparing their average score with the average score of a group of matched control subjects.
The purpose is to test an hypothesis about what the ‘cause’ of amnesia might be.
This approach to amnesia has had some success.
In particular there is the intriguing finding that some amnesics can learn certain new skills as quickly as normal subjects, even though they are often unable to remember the circumstances in which they learnt them.
Unfortunately, though, we are not very much closer to a genuine explanation of amnesia in functional terms that we were twenty years ago.
The problem is that it is highly improbable that a group of patients with brain injury constitute a natural kind, even when they display similar symptoms on some test or other.
This is because no two patients are likely to have identical injuries, and large groups of patients are even less likely to be homogenous.
In fact, if you probe deeper, vitally important functional differences between patients will emerge.
In amnesia, as in many other  so called neuropsychological syndromes (developmental dyslexia, schizophrenia, Wemicke's aphasia etcetera) there is probably no uniform pattern in nature waiting to reveal itself.
What you have are groups of people who display superficially similar symptoms for a variety of different reasons.
Where cognitive neuropsychology has had its greatest success is in areas where a detailed model of cognitive function is used to explain the pattern of performance produced by individual patients.
Let me illustrate this via an examination of the cognitive neuropsychology of reading.
Models of Reading
According to one influential cognitive model (Coltheart, 1985; see Figure 1), there are two distinct reading routes that might come into operation when one is reading aloud.
Following the terminology of Patterson (1982), these two systems are said to involve either ‘assembled’ or ‘addressed’phonology.
A pronunciation of a word is said to be assembled when it is built up piecemeal from its component letters.
The letters are first ‘parsed’ into their appropriate graphemic units.
A grapheme is here defined as the way in which a phoneme is represented in print.
Graphemic parsing is necessary because a phoneme is often represented in English by more than one letter (for example, PH represents one phoneme in ‘graph’, OO represents one phoneme in ‘boot’).
Each grapheme is then translated into a corresponding phonemic representation on the basis of pre-established conversion rules (each grapheme would become associated with a particular phoneme as one's reading skills develop).
Finally, the phonemes are blended together to produce the spoken response.
The alternative pronunciation route, which involves ‘addressed’ phonology, employs the lexical system.
Initially, an entry in a reading lexicon which matches the sequence of letters that one has detected is located.
The reading lexicon (or ‘visual input lexicon’ as it is sometimes known) contains our knowledge of written English word forms.
It is built up as a result of encountering these words in print as one is learning to read, though of course new word forms will be added throughout adult life as they are encountered.
This whole-word visual representation is then used to address and so locate its associated pronunciation in a lexicon of spoken word forms known as the speech output lexicon.
It is known as a speech output system because there is evidence that a quite separate lexicon is involved in speech perception.
A pronunciation is addressed either with or without the mediation of the semantic system — our store of word meanings.
The fundamental difference between the two  routes, then, is that a pronunciation is either built up from sublexical components (‘assembled’ phonology) or looked up as a whole (‘addressed’phonology).
This model has been extremely successful in enabling us to understand acquired dyslexia.
Acquired dyslexia involves a loss of reading ability as a result of brain injury.
This contrasts with developmental dyslexia which is an impairment, possibly congenital, in learning to read in the first place.
The model can explain a pattern of acquired dyslexia known as surface dyslexia which is   characterized by poor reading of irregularly spelled words such as‘yacht’ or ‘colonel’.
These words tend to be read as if they were regular.
So ‘colonel’ might be read COLL-OH-NELL.
In one memorable instance, a patient pronounced ‘LISTEN’ as ‘LISTON’and responded ‘that's the famous boxer’(Marshall and Newcombe, 1973).
Despite their problems with irregular words, however, these patients can produce a plausible pronunciation of unfamiliar non-words (‘blasp’, for example).
What might be responsible for such an unusual pattern of performance?
This impairment can be explained in a straightforward manner if one assumes that damage has occurred to the part of the reading system that involves addressed phonology.
This would mean that the patient is heavily reliant on assembled phonology .
This allows them to generate a plausible pronunciation for a non-word like ‘blasp’, but means that they cannot pronounce many irregular words correctly.
Consequently, words like ‘colonel’ or ‘yacht’are pronounced as if they were non-words.
The success of the model does not end there.
Following the discovery of surface dyslexia, it became clear that there should also exist another form of acquired dyslexia in which the ability to use assembled phonology was lost, while the ability to read a word via addressed phonology was intact.
This pattern had never been noticed before, but as soon as researchers started looking for it, several case studies of what is now known as phonological dyslexia were reported in rapid succession in the early 1980s.
In cases of phonological dyslexia, the patient finds it almost impossible to read any word with which he or she was unfamiliar prior to brain injury.
However they can still read a very high percentage of pre-morbidly familiar words accurately, regardless of their spelling.
This pattern of performance suggests that these patients find it difficult to assemble a pronunciation, but they can continue to read familiar words because the lexical system, utilizing addressed phonology, is still working effectively.
This means that they are able to retrieve the appropriate pronunciation of a word as a whole from the speech output lexicon.
The dual-route model of reading is thus able not only to explain an existing set of data within a simple theoretical model, it also successfully pinpointed the existence of an entirely new type of acquired dyslexia.
Moreover, a closer look at individual patients provides support for what was said about the heterogeneity of groups at the start of this section.
So, the more that surface dyslexics are studied, the more it becomes obvious that the condition fractionates; there are important differences between individual surface dyslexics.
These differences can also be accommodated by the dual route model.
For example, one surface dyslexic can accurately define the irregular words that he regularizes in pronunciation tasks (for instance , pronouncing ‘colonel’ as ‘COL-OH-NELL’).
His problem is therefore at the level of the speech output lexicon.
Another, who has problems in understanding speech as well as problems in understanding print, has an impairment at the semantic level.
Yet another patient's problems are at the level of the visual input lexicon itself.
A different patient correctly reads irregular words aloud but fails to retrieve their meaning, responding for example to a word on a card with: ‘HYENA, what the heck is that?’
(Schwartz, Saffran and Marin, 1980).
This patient has lost the semantic representations for many words (the brain's store of meanings), but retains the link between the visual input and speech output lexicons.
In addition, Coltheart (1985) argues that other patients have impairments to the assembled phonology system.
One patient pronounces every letter in a word separately, which suggests a problem of graphemic parsing.
Another patient could name letters but could not sound them out, suggesting a problem at the level of grapheme to phoneme assignment.
I have gone into such detail about individual patients to try to convince you first, that it can be misleading to categorize patients too narrowly into groups, and second, that the dual-route model I described can accommodate a wide variety of data from different individual cases.
There is an equally important additional point that I want to make.
Since brain damage can produce these very precise differences between patients, it is difficult to avoid the conclusion that there is one part of the brain that has the precise function of carrying out each piece of information processing that is specified within the cognitive model.
It seems to me to be perverse in the extreme to attempt to resist the claim that the brain is literally carrying out these functions.
Cognitive neuropsychology thus provides powerful evidence that the level of analysis which functionalists use to describe brain processes is the correct one.
Models of face processing
Finally, I want to move from cognitive models of word recognition to cognitive models of face recognition.
This is because I believe that one of the basic assumptions of functionalism can be successfully illustrated, and alternatives to functionalism can be successfully confronted, by a careful examination of the effects of brain injury on face processing tasks.
According to functionalism, it is useful to categorize environmental stimuli on the basis of what they mean to a subject rather than on the  basis of their gross physical characteristics.
In other words, when it comes to an attempt to understand how someone is likely to respond to a stimulus, a description of the stimulus in terms of its simple physical dimensions is not going to be of any value.
No laws of behaviour are going to be formulated which are in any way dependent on the basic physical characteristics of a stimulus.
One might think that radical behaviourists such as Skinner would advocate the classification of stimuli along purely physical dimensions.
However Skinner (1957) writes of verbal behaviour as being ‘under the control of extremely subtle properties’ of a stimulus, but never clarifies what this might mean.
This is one of the reasons why Chomsky (1959) was able to launch such a devastating attack on radical behaviourism.
The inadequacy of conceptualizing stimuli in purely physical terms is neatly illustrated in a study by Campbell, Landis and Regard (1986).
They compared the performance of two patients on a lip-reading task and on a task which required analysis of facial expression.
One of the patients could not categorize the expression on faces that she was shown in photographs in terms of whether the expression was one of happiness, anger, surprise and so on.
However, she was able to judge the sounds that were being mouthed by faces in photographs, and showed other evidence of normal lip-reading abilities.
By contrast, the other patient (known as ‘T’), was able to judge facial expression normally but had lost the ability to lip-read.
At first sight, the reader might doubt whether even people without brain injury usually possess significant lip-reading skills.
In fact, though, McGurk and MacDonald (1976) have shown the extent to which we use information about the position of a speaker's lips to help us recognise spoken words.
They showed, for instance, that if you look at someone saying ‘ga’ on a piece of film with the sound being removed and replaced by the sound ‘ba’, then subjects will actually report hearing the sound ‘da’.
Patient ‘T’ was not susceptible to the McGurk effect.
It is important to remember just how similar the physical features are that one must respond to in facial speech and facial expression judgements.
In both cases it is the position of the lips that conveys much of the vital information.
If it is the simple physical characteristics of a stimulus that play the key role in generalizations about behaviour, then we might expect to find patients who have lost the ability to lip-read and lost the ability to judge expression, but not patients who have lost only one of these two abilities while retaining the other.
According to the functionalist, of course, facial expression and lip-reading are likely to be dealt with by distinct parts of the information-processing system because the nature of  the information that they convey is so different.
Therefore the dissociation which Campbell and her colleagues have demonstrated between lip-reading and expression analysis makes perfect sense from a functionalist perspective.
Phenomenology
I now turn to a consideration of some implications of the cognitive neuropsychology of face recognition for phenomenology — an approach to the mind and mental phenomena that gives prominence to introspectible ‘phenomena’ understood as acts of consciousness and their immediate objects.
Phenomenologists such as Dreyfus (1972) argue that the level of explanation utilized in cognitive science does not truly exist.
The physical brain and the world of introspectible phenomenal experience are all that there really is: ‘no cognitive psychologist has succeeded in defining another sort of input between these two which would provide the ultimate bits of information to which rules are applied’(p. 199).
My favourite phenomenological quote, however, comes from Jennings (1986):
…social psychologists spent years conducting experiments to specify the exact parameters of a hypothetical motivational state called ‘cognitive dissonance’…
Certainly, an enormous amount of unproductive work could have been saved if phenomenological analyses were first performed to ‘see’ if this supposed psychological state actually existed…(p. 1236).
One of the most remarkable findings to have emerged from contemporary cognitive neuropsychology is the demonstration that patients can show evidence of covert recognition of faces that were known pre-morbidly, in the absence of any conscious awareness that the face is familiar.
For instance, the patient PH (Young and De Haan, 1988) shows no overt recognition of faces.
When he is shown a pair of faces and has to decide which of the two is a celebrity, he performs at chance level, even though he performs almost as well as normal subjects on this task when the faces are replaced by their names.
In other situations, however, PH's pattern of responding makes it clear that he is recognizing familiar faces at an unconscious level.
The clearest example of this is PH's performance in priming tasks (Young, Hellawell and De Haan, 1988).
Associative priming is a well known phenomenon in cognitive psychology.
If one has to identify a stimulus — for instance a word -then one can accomplish this more quickly if presentation of the word is immediately preceded by an associated word or picture.
For instance, when subjects have to decide whether certain names are familiar or not (say, Oliver Hardy) they respond more quickly if they are shown, a few tenths of seconds earlier, a picture of a person who is associated with the target name (Stan Laurel).
Now, the remarkable finding is that PH shows exactly the same pattern.
He can identify a familiar name more quickly if it is preceded by an associated face, even though he does not report finding any face familiar.
What is more, he shows every bit as much priming from these unrecognized faces as he does from names (which, of course, he can recognize overtly).
These data are of great theoretical significance within cognitive neuropsychology.
For instance the strength of the priming effect suggests that covert recognition reflects the otherwise intact operation of the normal face recognition system when it is cut off from some centre of consciousness (Young and De Haan, 1988) rather than the operation of a separate, subsidiary face recognition system.
This in turn opens up some fascinating questions about the role of consciousness itself in memory and perception.
What I want to emphasize here is the impact of these findings for a phenomenologist.
If all that exists in reality are low-level physical processes in the brain on the one hand, and the high-level products of phenomenological awareness on the other, then how is PH's covert recognition of faces to be conceptualized?
You could ask PH to introspect into the contents of his phenomenological awareness when he is looking at faces for as long as you liked, but there would be no insight that any recognition is occurring.
That PH is genuinely recognizing faces, however, cannot be seriously questioned.
This pattern of findings would appear to be impossible to accommodate from the viewpoint of phenomenology.
As Bauer put it in a recent BBC television discussion of covert recognition, ‘Our normal experience of perception, of seeing objects or faces as an all or none process, is a trick that the brain plays on us’.
It is a trick that should no longer fool anyone except phenomenologists.
Finally, as in the discussion of reading, I could point to other patients who have a wide variety of different face processing problems.
For example, some have difficulties in retrieving semantic information about people (for example their occupation), some have difficulties specific to the retrieval of people's names, and some can remember old faces but cannot learn new ones.
The problems which these and other patients suffer can mostly be explained in terms of detailed functional models of face processing such as that proposed by Bruce and Young (1986), in the same way that patients' different reading problems could be explained by Coltheart (1985).
Bearing all this in mind, what are we to make of Searle's (1984) claim that the brain does not identify faces via information processing of the kind described in cognitive models and that, as far as the cognitive sciences are concerned, there may simply be no story to tell?
His suggestion is that ‘facial recognition may be as simple and as automatic as making footprints in the sand’.
If this were true, then it is hard to see how impairments in face processing could be explained so economically in terms of the cognitive modules that functional models contain.
If these information-processing modules exist only in the minds of cognitive scientists, rather than in the minds of the subjects they study, then breakdowns in face recognition or word recognition should either be all-or-none, or else they should be extremely difficult to conceptualize within the vocabulary of cognitive psychology.
In fact, the striking dissociations that one can observe in neuropsychological patients show us instead that skills which seem so simple and automatic in the course of everyday life are in fact comprised of a large number of functional sub-components, any of which may be impaired by brain injury.
Work such as that of Young et al(1988) has even shown us how something that was traditionally assumed to be as intangible and subjective as the nature of conscious awareness itself can be disrupted by physical damage to the brain and can be successfully studied by the observational techniques of cognitive psychology.
The fact is that cognitive neuropsychologists have significantly increased our understanding of the effects of brain injury on behaviour by conceptualizing mental processes in purely functional terms without regard to their subjective qualities or to physiology.
This seems to me to represent good grounds for believing that functionalism itself may well be true.
It is time for certain philosophers to come and take a hard look at the data which we have collected before they dismiss our models and our philosophical assumptions so glibly.
Suggested Reading
Although neither have been cited directly in the text, the philosophical ideas in this chapter have been heavily influenced by the work of Jerry Fodor and Zenon Pylyshyn.
Fodor (1981) provides a very clear description of functionalism, and his book The Modularity of Mind discusses some of the philosophical issues surrounding cognitive neuropsychology.
Pylyshyn (1984) contains an important account of the relationship between cognitive psychology and artificial intelligence, and Pylyshyn (1973) contains an interesting discussion of the differences between cognitive science and phenomenology.
A very clear introduction to current work in cognitive neuropsychology is provided by Ellis and Young (1988).
Churchland's Matter and Consciousness is an equally lucid introduction to the philosophy of mind.
A Critique of Neuromythology
Raymond Tallis
Introduction
One of man's great intellectual adventures — the exploration and understanding of his own nervous system — is progressing at a rate undreamed of only a few decades ago.
There are many reasons for this.
First of all, there have been important advances in experimental methods: single cell recordings with exquisitely fine electrodes; novel methods of imaging the internal structure of neurons and the connections between them; cell culture techniques permitting the growth and development of nervous systems to be studied in great detail; and sophisticated computational and statistical analysis of data permitting better mathematical modelling of large and small scale events in the nervous system and its functional connections.
Secondly, there have been important conceptual advances.
Since Hubel and Wiesel began publishing their work in the late 1950s, there has been an increasing appreciation of the way in which nervous systems are so structured as to ensure that certain events of special importance to the organism have an increased likelihood of triggering activity in the relevant places.
Alongside this, there has been growing awareness of the plasticity of the nervous system and of the extent to which the ‘hard-wiring’ of the wetware of the brain is itself modulated by the brain's own experience.
At a microscopic level, the range of factors and substances behaved to influence the interactions between neurones has been greatly widened.
And there has been a remarkable interchange of ideas between computational theorists and neuroscientists, in which attempts to create computer models of neural function have not only generated powerful new tools for the interpreting of the brain but have also fed back into computer theory and practice.
At every level — from the simple oligosynaptic circuits involved in the tropisms of primitive organisms to the complex neural activity implicit in human perception — computational models dominate scientific thought.
The converging conceptual worlds of computational theory and neuroscience are expressed in the huge and powerful ‘neural nets’ of parallel distributed processors and in the emergent science of cognitive neurobiology in which the brain  is approached as an immensely complex information processor (see Chapter 7).
A third reason for the accelerating rate of advance in neuroscience is that there are simply larger numbers of better funded people engaged in research in this field today than ever before.
And they come from diverse backgrounds: not only physiologists but also physicists, molecular biologists and mathematicians are attracted into neuroscience which threatens to displace physics and even molecular biology as the queen of the sciences.
It would be perverse, then, to deny that very exciting things have been happening and it is no business of this chapter to disparage these remarkable advances in understanding of the brain.
My concern here is with the mythology that has accompanied these advances; the metaphysical claims implicit — and not infrequently explicit — in the way they have been described.
I am concerned, that is to say, with neuromythology.
The founding myth of neuromythology is that our more detailed knowledge of the nervous system has resulted — or very soon will result — in an increased understanding of the mind, indeed of the very nature of understanding itself.
If we do not yet have the solution to the problem of consciousness, we are at least working towards it within the right framework.
Any delay in arriving at a solution will be due not to our being on the wrong track but simply to the enormous complexity of the problem.
(We are frequently reminded that the brain has many millions of neurones and that these have many billions of connections).
When we have a complete account of the brain, we are assured, consciousness will be intellectually transparent and the mind will assume its rightful place as just another part of (physical) nature, obedient to the laws that hold sway elsewhere in the material universe.
This is the myth that I want to examine here.
Although the majority of scientists tend to be a little coy about metaphysical matters in their professional publications, they are often less so outside when writing elsewhere, being prone to describe the framework of presuppositions about perception within which they conduct their investigations as if it were a discovery in its own right and that ‘discovery’ an explanation of perception.
And although the majority of materialist philosophers base their belief in the neurophysiological theory of perception on arguments rather than observations, they are, nevertheless, greatly influenced by the apparent successes of neurophysiology.
The Materialist Theory of Perception
We may think of consciousness as having two components: sensation and perception on the one hand and willing or agency on the other; or input and output.
For the purposes of the present discussion I  am going to confine myself to sensation and perception and ignore behaviour.
I do this not only because the issues are easier to grasp in the case of perception than in the case of voluntary movement, but also because neurophysiologists of movement are less prone to wild claims than neurophysiologists of perception: most of the former would admit that we do not yet have the faintest idea how voluntary activity is able to utilize or over-ride reflex pathways; how we mobilize so-called ‘motor programmes’ when we need them; or even where in the nervous system voluntary movement is initiated.
The metaphysical framework for the neurophysiology of perception is provided by the Causal Theory of Perception (henceforth referred to as the CTP).
This goes back at least as far as Aristotle.
According to Aristotle, perceiving an object is the result of being acted upon by it: objects of perception, acting via a medium of perception, causally affect the perceiver's sensory apparatus.
As a result, the apparatus ‘receives the form of the object without its matter’; the change in the apparatus is perception.
The CTP is susceptible of a materialist interpretation and this, in its neurophysiological version, is what I am going to focus on.
This explicitly materialist framework of contemporary neurophysiology originated much later than Aristotle.
One of its earliest expressions is to be found in Thomas Hobbes's Leviathan , published in 1651:
The cause of sense is the external body, or object, which presseth the organ proper to each sense, either immediately, as in taste or touch; or, mediately, as in seeing, hearing or smelling.
The external object
worketh on the eyes, ears and other parts of a man's body; and by diversity of working produceth diversity of experience.
We experience the world in virtue of the fact that the contents of the world impinge on us.
Our bodies and the world bump into one another and there is an exchange of energy between them.
This exchange of energy explains how we perceive the world.
This is now so widely accepted that it seems less like a theory, or even a theoretical framework, than a piece of common sense; and in one form or another it encompasses the views of the majority of Anglo-American philosophers and neuroscientists about the basis of consciousness or, at the very least, of perception.
Although some philosophers and psychologists would emphasize the role of action in controlling perception (see chapter 2) and some talk of ‘top down’ constraints on the interpretation of the perceived, the causal role of incident energy remains fundamental and the materialist version of the CTP essentially unchallenged.
The neurophysiological version of the CTP, with which we are concerned here, holds that perception is the result of the constant interaction between the material world and the nervous system.
In particular, perceptual awareness, and so consciousness itself, is identified with certain events taking place in the higher reaches of the central nervous system where a chain of events, collectively described as sensory processing, and originating from the object that is perceived, reaches a terminus.
For example, I perceive this flower in front of me because light which has been reflected from it impinges on my retina and causes trains of nerve impulses to travel along the visual pathways to the visual cortex.
The events in the visual cortex correspond in some way (see later) to perception of the flower.
It is out of such events that the visual field, indeed the visual world, is composed.
And these, along with other cortical events relating to other sensory pathways, are the basis of consciousness and of our state of being ‘worlded’.
In other words, according to the neurophysiological CTP, sensation, perception, experience, consciousness, are intimately related to, or even boil down to, large numbers of trains or patterns of nerve impulses.
We perceive what is ‘out there’ or what is ‘around us’as a result of the transfer of energy from objects or events to specialized parts of the body known collectively as ‘the sensory system’.
I shall argue that this framework is explanatorily inadequate and that the inadequacy is inherited by theories developed within it.
Such theories contribute nothing to explaining the mystery of perception.
At best they re-describe perception in a manner that actually generates more problems than it solves.
Neuroscience, which depends upon a materialist CTP for the explanatory force of its explanations of the mind, cannot, therefore, sustain any claim to be explaining or advancing our understanding of the basis of perception, or of the mind.
The Neurophysiology of Perception: Exposition
The main task of sensory neurophysiology has been to establish in more precise detail how ‘the diversity of working produceth diversity of experience’— the modern term for which is ‘coding of sensory information’.
The framework for the investigation of ‘sensory coding’ was established in the nineteenth and early twentieth centuries, when  the business of explaining perception was transformed into the more specific project of correlating the physical properties of perceived objects and events with patterns of activity in the nervous system and the latter with the subjective properties of the experience:
It was early appreciated that, apart from, say, minor variations in the speed of conduction, the impulses in all nerve fibres have essentially identical characteristics.
This was explicitly recognized by the early twentieth century physiologists who saw their fundamental task as that of discovering how the infinite variety of the perceived world could be reflected in, or reconstructed in, the rather monotonous nervous system.
With the advent of digital computers and the development of information theory in the 1940s and 1950s, this job was interpreted as being that of finding out how the nervous system ‘encoded’ reality in a digital form.
The task of the nervous system was seen to be a computational one.
It would not be appropriate here to attempt the impossible task of summarizing modern sensory physiology but it is necessary to discuss a few basic principles and laws.
We can think of experience as being differentiated both qualitatively and quantitatively .
For neurophysiologists and neuropsychologists, the way forward in understanding perception has been to correlate these dimensions of experience with, firstly, the material properties of the experienced object or event (usually regarded as the ‘stimulus’) and, secondly, the patterns of discharges in the sensory system.
Qualitative Aspects of Experience
The quality — or modality — of the experience depends less upon the quality of energy reaching the nervous system than upon which parts of the sensory system are activated: stimulation of the retinal receptors causes an experience of light; stimulation of the receptors in the inner ear gives rise to the experience of sound; and so on.
Muller's nineteenth-century ‘doctrine of specific energies ’ formalized the ordinary observation that different sense organs are sensitive to different physical properties of the world and that when they are stimulated, sensations specific to those organs are experienced.
It was proposed that there are endings (or receptors) within the nervous system which are attuned to specific types of energy, For example, retinal receptors in the eye respond to light energy, cochlear endings in the ear to vibrations in the air, and so on .
Of course, high  energy stimulation even of the wrong kind may stimulate a sensory ending; for example , excessive pressure on the eyeball will produce a sensation of light.
Contrariwise, over-intense stimulation of the appropriate kind will evoke pain.
These are, however, abnormal situations; for ordinary perception, the doctrine of specific energies holds.
This early framework for sensory physiology — of a piece with the Hobbesian idea of ‘the organ proper to each sense’— has undergone a good deal of refinement.
Within the cochlea, for example, it has been shown that there are endings that respond preferentially to sounds of high rather than low pitch.
More centrally, in the cerebral cortex the afferent fibres from groups of receptors are ‘wired together’ so that more complexly patterned stimuli — such as edges or lines of a certain inclination — may preferentially elicit neural activity and the corresponding subjective experience.
The work of Hubel and Wiesel, in particular, put the conception of neurones as ‘feature detectors’, rather than simply energy detectors, on the map, supporting the idea that for each cell in the cortex there was a specific pattern of excitation that would reliably excite it.
Each cell had its own stimulus requirements and when it became active this said something about the nature of the event or object in its own part of the visual field.
It would not be too great a distortion of the facts to say that the main thrust of twentieth century sensory physiology has been to move the application of the doctrine of specific energies inwards from the sensory ending towards and into the cortex.
Quantitative Aspects of Experience
There are three fundamental dimensions of quantity in experience:(a) intensity;(b)(spatial) extensity; and (c) duration.
At a neurophysiological level, the intensity of an experience is typically reflected in the number of neurones activated (the phenomenon of ‘recruitment’) and, more specifically, in the firing frequency of the relevant neurones.
Extensity (for example the size of a patch of light) usually correlates with the number and spatial distribution of receptors activated.
Finally, duration is correlated with the period of time for which the relevant neurones are active.
(I am leaving aside phenomena such as accommodation, whereby a constant stimulus when sustained may activate the nervous system progressively less intensively, with a corresponding reduction in the perceived intensity of the stimulus.
These, and other features of ‘adaptation’, do not invalidate the underlying conceptual framework.)
The earliest psychophysical observations demonstrated a correlation between the intensity of the physical stimulus and  subjective reports of the intensity of the resultant experience.
These were eventually formalized in the Weber-Fechner law which reported a quantitative relationship between stimulus and subjective experience, the sensation increasing in proportion to the logarithm of the magnitude of the physical stimulus.
A quantitative correlation between the objective intensity of stimulus and the pattern of neural activity was subsequently demonstrated by physiologists recording from individual fibres.
Since the work of S. S. Stevens in the 1930s and later, it has been recognized that, although the Weber-Fechner Law holds for many sorts of sensory experience, the exponent varies widely; nevertheless, the principle of a quantitative correlation between external stimulus, neural activity and experienced sensation remains intact and now appears to be well-established.
So much for the basic laws.
The repeated confirmation of the correlation between the physical characteristics of the stimulus and the characteristics of the neural activity it triggers, and between the characteristics of the stimulus and that of the subjective sensation, has encouraged the belief that our sensations are in some sense to be understood in terms of a set of stimulation levels (spiking frequencies) in the appropriate sensory pathways.
And it would seem that physiologists — working within the common-sense assumptions that we experience the world because it impinges upon our bodies and that what we experience is what, directly or indirectly, impinges on our bodies in the form of transferred energy — have made considerable progress in explaining how ‘the diversity of working produceth the diversity of experience’.
Or have they?
In the discussion that follows, I shall question whether:
(a) scientific, and in particular physiological, observations have provided any additional, independent evidence in support of the impingement theory of perception/experience;
(b) the impingement theory, with its physiological embellishments, goes any way towards explaining perception.
One might expect, a priori, that no empirical (that is perception-based) observations could provide evidence in support of a metaphysical theory of perception; that perceptions would not enable us to get to the root of perception.
By unmasking the circularity of physiological explanations of perception that have been developed within the framework of the idea of the ‘impingement’, I shall show that the a priori principle is upheld.
The Neurophysiology of Perception: Critique
The Psychophysical Laws
According to the Muller doctrine, sensory endings are particularly sensitive to certain types of energy — light energy in the case of retinal endings, sound energy in the case of cochlear endings, and so on-and that when they, or their central connections, are stimulated a specific modality of sensation is experienced.
According to the Weber-Fechner law, there is a correlation between the intensity of the energy incident on the sense ending and the magnitude of the corresponding subjective experience.
These laws seem a) to provide empirical support for the neurophysiological account of perception and b) to contribute to its explanatory force.
I will argue, however, that a) and b) are apparent rather than real.
a) Do the laws provide empirical support for the neurophysiological account of perception?
Both laws are derived from observations and there can be no doubt about their empirical credentials.
Are those empirical credentials sufficient, however, to sustain the metaphysical implications it is thought that the laws have?
Empirical observations may generate laws that correlate one type of experience with another; but can they take us ‘beneath’ experience to its basis?
It seems unlikely that experience can take us outside of the closed circle of experience to reveal that upon which experience — experience in general, rather than particular experience — is based.
Yet some writers seem to think that the laws do just that; and that the quantitative observations encompassed in the laws take us beyond (subjective) experience because they are based upon objective measures of physical energy, utilizing scientific instruments.
The objectivity of the psychophysical laws — and the escape from the closed circle of experience — is more apparent than real.
For the scales on the ‘objective’ measuring devices used to derive the data upon which the laws are founded are not validated independently of subjective experience.
In the final analysis, the scientific estimate of the intensity of light, for example, is rooted in subjective experience of brightness.
Our objective measures of light intensity would be discarded if they universally gave answers that contradicted our subjective experiences.
Scientific measurements may ‘correct’, ‘reform’ or at least question individual unaided observations but there cannot be a systematic, universal discrepancy.
The cash value of scientific observations in this context must therefore be based upon subjective experience and cannot be greater than the cash value of the  latter; for it is subjective experience that, ultimately, validates our objective scales of energy intensity.
We may use physical methods of measuring light intensity that are apparently independent of our subjective experience — for instance photosensitive cells — but these are accepted because they correlate to a greater or lesser degree, under normal circumstances, with subjective experiences of brightness.
If there were simply no correlation whatsoever between the electrical output of a photo-electric cell and some other measure of light intensity directly or indirectly related to experience, it would not have been accepted as a way of measuring light intensity.
However indirectly related to sensory experience a laboratory quantification of a particular form of energy may be, in the end the rate of exchange between one form of energy and another — the way in which we compare the quantity of one with the quantity of another -reposes upon the gold standard of subjectivity.
The observation that a sensory system has a relatively low threshold for the form of energy which it transforms into experience is not only a pre-scientific empirical observation but also one that science could not reform — if reform were necessary — nor independently validate.
It would seem therefore that the contingent or empirical links uncovered by experimental science between the nature of the stimulus and the intensity and distribution of neural activity on the one hand and between the properties of the stimulus and those of the evoked sensation on the other are not based on discoveries that go beyond, or arise outside of, ordinary experience.
Ultimately, the two variables of impinging stimulus and evoked sensation are internally rather than externally related; for our estimate of the properties of the impinging stimulus — and the decision as to whether or not those properties ‘justify’ the sensation they give rise to — is based upon the norms of, necessarily subjective, experience.
The psychophysical laws relate sets of experiences, rather than relating experiences to something external to experience.
Interestingly, the psychophysical laws may be even more entrained in subjectivity than I have suggested.
Recent work has confined that it is not possible to measure intensity of subjective sensation in a way that is distinct from and independent of measurement of the physical stimulus from which it is derived; that Fechner's logarithmic transform exists only as a mathematical construction to link reports of sensations with measurements of stimuli; and an experimental subject's conformity to Stevens' power law depends on his getting the experiment ‘right’.
Even if the laws of psychophysics are empirical laws in the sense of correlating one type of observation or experience with another, they are not laws about the relationship between experience and that which lies outside of experience and is its trigger or basis —‘pure’, objective, material energy.
Psychophysical laws, in other words, provide no independent evidence for a physical basis of perception.
To assert this is merely to reiterate a point that should be obvious: that science, however sophisticated its instrumentation, cannot generate observations that somehow enable us to look at the relationship between experience and the world as it were from outside of experience.
(b) The lack of explanatory force of the laws
The lack of explanatory force of neurophysiological and psychophysical observations is explicitly admitted by some scientists.
It has been well expressed by the biologist Richard Dawkins:
The sensation of seeing is for us very different from the sensation of hearing, but this cannot be directly due to the physical differences between light and sound.
Both light and sound are, after all, translated…by the respective sense organs into the same kind of nerve impulse.
It is impossible to tell, from the physical attributes of a nerve impulse, whether it is conveying information about light, about sound or about smell.
A similar point was made by the seventeenth-century philosopher John Locke, who saw it as an insoluble mystery.
Dawkins, however, feels he has an answer.
He asserts, rather cryptically, that
It is because we internally use our visual information and our sound information in different ways and for different purposes that the sensations of seeing and hearing are so different.
It is not directly because of the physical differences between light and sound
This is not a very convincing escape from the circularity of the psychophysical laws.
On the contrary, it exposes the explanatory weakness of the Muller Doctrine, if it is offered as an advance in our understanding of the origin of different modalities of sensation, of why the world feels as it does; and, even more, if it is offered as an account of our being able to feel the world at all.
The Doctrine is at best a circular re-statement of the obvious: Why did I experience those vibrations in the air as sounds?
Because they stimulated my auditory, rather than my visual, system.
But why do those particular nerve endings count as part of the auditory system?
Because they are connected with the area of the cortex that  is designated the auditory cortex.
But why is that particular area of the cortex designated the auditory cortex?
Because it is concerned with the reception of sound.
But what evidence is there that this bit of the cortex is concerned with the reception of sound?
Well, there is the fact that it is connected to sensory endings that are designed specifically to respond to vibrations in the air.
And so we are back to the beginning…
The circularity is obvious: the destination of the particular sensory pathway defines/explains the starting point, the starting point defines/explains the destination.
Metaphysical Problems
We are now close to the fundamental inadequacies of the neurophysiological explanation of perception.
Consider the physiologist's intuition that an increased neuronal firing frequency explains increased intensity of experience.
This depends for its prima facie plausibility upon the assumption that there can, should or must be a correlation between the quantity of energy incident on nervous tissue and the intensity of experience.
But to begin with this assumption is to by-pass, rather than explain, the mystery of perception as it presents itself to us if we assume that perception occurs because the perceived object impinges directly or indirectly upon the nervous system.
The mystery that it by-passes is that of how energy is transformed into sensation, experience, information or whatever.
Only when that has been explained might the Weber-Fechner Law and the Muller doctrine — connecting the quantity and modality of energy with the quantity and modality of sensation — have any explanatory value.
The specific observations of neurophysiologists, correlating stimulus properties, neural activities and the characteristics of subjective reports of sensation, contribute to explaining how ‘the diversity of working produceth a diversity of experience’only if we have already explained how ‘working’ produceth ‘experience’at all .
Or how energy impinging on the nervous system is transformed into information in, or addressed to, the nervous system.
I would argue that physiologists of perception, working within the framework created by the Muller Doctrine and the Weber-Fechner Law are in a position of dotting the i's and crossing the t's in a text that has not yet been written.
This is only the beginning of the neurophysiologist's metaphysical problems.
For the materialist version of the CTP is beset with many difficulties that ultimately make its claim to have explanatory force somewhat vacuous.
I should like to deal briefly with the most important of these.
a) How do the neural events in the brain actually relate to perceptions?
There are several rival accounts of this, some of them not compatible with materialism.
For example,substance and bundle (or event ) dualism assert that the neural events cause the perceptual events.
In other words, the perception is a mental effect that is at one step in the causal chain beyond the physical events.
Since the causal chain passes through perception and on to the rest of the nervous system, perhaps triggering action, it must become physical again.
So one is left with the impossible task of explaining why a perfectly respectable causal chain should ‘go mental’ for a while and then, recovering its non-senses, should return to being purely physical.
Substance and bundle dualism for this and other reasons are rather unpopular.
Property dualism holds that the perception and the neural events which are its physical basis are simply different aspects, properties or attributes of the same (physical) events: what the physiologist observes on examining the brain and what the owner of the examined brain feels are two aspects of the same event.
This interpretation in no way diminishes the enigma of the relationship between electrochemical events in the nervous system and conscious experiences.
For the idea of an object or an event with two metaphysically different aspects — with, as it were, an unextended mental front end and an extended physical rear end -is deeply puzzling.
Moreover, rather as substance dualism tends to do, it seems to undermine the causal role of consciousness in, for example, bringing about or influencing actions.
For the causal relations of events would be just the same irrespective of whether or not the causal chain temporarily took on a mental aspect (as in property dualism) or (as in substance dualism)‘went mental’ for a while.
A further telling argument against the dual aspect theory -and one that has been rarely noticed — is that ‘aspects’ are relative to viewpoints; in other words, they emerge posterior to perceptions.
They cannot, therefore, be invoked to explain perceptions, even less the manner in which perception is related to matter.
Most scientists implicitly, and the many philosophers explicitly, prefer identity theories.
These assert that perceptions are strictly identical with certain events in the nervous system.
Such theories have to face the obvious objection that brain processes and mental phenomena seem utterly unalike.
For example, one can say of a brain process that it occupies a particular point in space or that it can be displayed on an oscilloscope screen; whereas neither of these things could be said of, for example , the subjective sensation of the colour blue or of the thought that I hate Monday mornings.
It is difficult  to comprehend an object that is utterly unlike itself.
This, in fact insuperable, difficulty is said to be overcome by proposing that mental phenomena and brain processes are the same stuff viewed within different theoretical frameworks.
But this apparent escape is only another version of the dual aspect theory and inherits the latter's problems.
b) How/why does the causal chain linking object and perception have a beginning and an end?
The materialist versions of the CTP assume that there is a causal chain that begins with the perceived object and ends with the perception.
The perception then ‘reaches back’ to the perceived object.
Since this causal chain is but part of a boundless nexus of causal chains that originate before and outside the perceived object and end beyond the perceiving body, it is not very clear why the former should count as an ‘origin’.
Why, in other words, should perception be of the perceived object rather than any other object in the causal chain further back in the causal chain; why every perception should not be of the Big Bang that started off the Universe.
Nor is it clear why the events in the cerebral cortex should count as a terminus; why they — rather than other events up- or down-stream — should constitute the perception.
The CTP proclaims that the link between the perceived object and the perception is just an ordinary bit of the great causal nexus of nature (it needs to believe this, as we shall see presently) and yet it is prepared to accept that this segment of the chain has a rather privileged status; at the very least, that it has a beginning and an end.
c) How does the nervous system construct stable objects out of transient events?
The neurophysiological CTP asserts that perception consists of neural events triggered by events in the perceived object.
The perceived world, however, seems to consist of stable objects as well as events occurring in them.
The CTP requires, therefore, that transient events triggering transient events should give rise the idea of (permanent) objects as well as that of transient events within them.
There is as yet no way of explaining how objects are constructed out of events; even less how the contrast between objects and events — one of the most pervasive features of everyday experience — is perceived.
d) The monotonous nervous system and the infinitely varied perceived world
As Dawkins pointed out in the passage quoted earlier, nerve impulses look pretty much the same whatever ‘information’ they are carrying.
There is a sharp contrast between the monotony and similarity of the event in the nervous system and the variety of the perceived world.
The perceived world is infinitely various, within and across modalities of sensation.
Moreover, there is a clear distinction between present and past perception (memory); between memory and thought; between passive and active states of mind (daydreaming versus active recall, association of ideas versus directed meditation); and between the content and the level of consciousness.
For causal theorists there are only nerve impulses, all of which are essentially the same.
Perception, that is to say, boils down to the passage of sodium, potassium and other ions across semi-permeable membranes.
It is legitimate, therefore, to ask what it is that is special about flea-bitten membranes that they should open up one object (the body) to all others, to a world.
That they should make of one body a site where the variousness of all other bodies is in some way received.
There are several responses to this puzzle.
They all involve the use of terms, or an appeal to concepts, that are illegitimate within the physicalist terms of reference of the neurophysiological CTP.
Yes, it will be conceded, there is an apparent discrepancy between the rather simple nerve impulses nervous system and the complex representations of the world they afford us.
This discrepancy, however, disappears when we recognize that it is not in individual nerve impulses that we must seek our representations of the world, but in their patterns .
We must think of the nervous system encoding the perceived world; and in trying to understand this process we should consider not individual spikes but their potentially infinite combinations.
The monotony of the individual neurones is irrelevant; what matters is the infinite variety of their combinations, of their patterns, which will become evident when we look at the nervous system at the right level.
I shall deal with the language of neurophysiological description shortly.
However, it is necessary to say a word or two here to refute this seemingly compelling argument.
We are so used to hearing talk about the nervous system ‘encoding’ the outside world that it is easy to forget that this is a metaphor and it is one that has no place in serious philosophical discussion of the mind-body problem or the philosophy of perception.
The reason the coding metaphor has such currency in contemporary talk about perception is that it seems to suggest a way in which very simple and apparently homogenous  elements such as nerve impulses can generate the richness and variety of consciousness.
Consider morse code.
Using this very simple code, constructed out of dots and dashes, it is possible to encode a text of any degree of richness — even, for example, the works of Shakespeare.
We may imagine therefore that neural dots and dashes — trains of impulses — can encode the variousness of experience.
The analogy is attractive, but illegitimate.
For the richness of morse code is a borrowed richness.
First, it is parasitic, as all codes are, upon a primary, natural language.
The meanings of morse are borrowed from the meanings of, say, English and messages encoded in it are meaningful only when they are interpreted, that is, decoded.
Where is the decoder in the nervous system?
In so far as it ‘translates’ at all, the nervous system ‘translates’only from nerve impulses into nerve impulses, from sodium fluxes into sodium fluxes.
This would not count as decoding unless muscular activity and other outputs were regarded as translations out of‘impulses’ into an interpreted language.
But to interpret decoding in this way would be to espouse behaviourism and to by-pass consciousness altogether.
There is a second, yet more damaging, objection to the coding metaphor.
Even translation from morse into natural language does not take us all the way to consciousness; for, in the absence of consciousness, language is merely variegated sound, rather than the rich varieties of meaning that are embodied in, for example, Shakespeare's texts.
No one outside of the wilder sects of the artificial intelligence fraternity would suggest that a device that translated morse into natural language characters on the screen of a computer was releasing the consciousness implicit in morse.
Natural languages such as English in turn owe their meanings to the conscious experiences of language users.
Codes, in short, owe their meanings -and the variety that is constructed out of their monotonous elements -to consciousness.
If the nervous system, therefore, owes the richness of the experiences which its activity embodies to the complexity of its codes, it must, ultimately owe its consciousness — to consciousness; for this will be required ultimately to turn its codes into complex experienced meanings, into experiences.
e) The unities of consciousness
Neurophysiological accounts of consciousness fail to address the problem of the unities of human consciousness.
These unities are evident at different levels.
There is the unity of the moment: different tactile and proprioceptive sensations amount to a coherent body image; different visual sensations cohere to a visual field; and  sensations from different modalities converge to a general sensory field, an organized moment-by-moment presence of a world, so that the feeling in my hand as I hold a stone, the sight of the sea and the sound of the seagull behind me are all not merely present but co-present.
Beyond this, current sensations converge with knowledge and memory and desire to make sense of the experience of the present: I not only experience this object but I recognize it — as something of a certain kind; as yours, as mine, as something I have seen before; and it means something to me in terms of my appetites and needs and ambitions.
Beyond the unities of the present moment, there are unities over time.
There is a self that coheres over time, so that a person p 2 at time t 2 is in some sense identical to the person p 1 at time t 1 .
This identity operates at a much higher level than mere identity of the body or continuity of habits.
It is an explicit sense of continuing self which includes a sense of responsibility over time (‘1 did that’) and, beneath this, a deep sense of psychological continuity (‘I remember having that experience’, ‘I was there then’).
Sensations and memories converge to create a continuing, if interrupted, sense of a coherent self.
This sense of self is quite robust: when we wake up, we not only remember what we know, but also who we are.
We are able to resume ourselves after sleep, after an alcoholic stupor, after an epileptic fit, after prolonged coma.
In the light of these unities, it seems necessary to postulate a systematic set of relationships between the patterns of memory and the sense of ‘1’, the qualitative interior of mental experience.
The basis of these unities does not seem to lie within the nervous system as it is currently conceived.
Since Sherrington's classic The Integrative Action of the Nervous System , there has been much talk of ‘the integrative activity of the nervous system’, based upon the convergence of nervous pathways.
But the scattered activity of different parts of the nervous system seems to converge only at the cost of merging, and so losing, the components that come together in the process of convergence, rather in the manner of snowflakes joining a drift.
There is no neurophysiological model of the kind of convergence that would seem to be necessary for the many different sensations of the moment to be brought into synthetic unity, without loss of their individual distinctiveness and specificity, into the instantaneous sense of ‘being here’; or of the manner in which experience of many different moments can be synthesized into a sense of continuing self without those moments losing their separateness in memory.
As for the recovery of consciousness, or wakefulness, there is no imaginable physiology of this ‘light dawning over the whole’.
Neural activity, triggered by a thousand  scattered occasions, temporally and spatially dispersed, has nothing within itself to create the basis of these fundamental unities of consciousness.
f) Intentionality
The final and the greatest problem of the neurophysiological version of the CTP (or, indeed, any version of the CTP), is that it cannot explain the intentionality or ‘aboutness’that connects the neural events with the object they are supposed to be perceptions of.
The causal theory of perception relates the object and contents of perception in two directions: there is an afferent limb connecting the object with the nervous system in which perception is generated; and an efferent limb in virtue of which the neural events ‘reach out to’ or ‘are about or of’the object.
The efferent limb carries the intentionality or aboutness that is fundamental to perception:
It is clear that the inwardly-directed causal, connection does not explain the outwardly-directed intentional relation.
Intentionality is usually overlooked by causal theorists who tend to see their job as being to sort out the afferent limb.
It is therefore especially ironical that the neurophysiological CTP, which locates the basis of perception literally in the head, at a particular place away from the perceived object, actually sharpens the mystery of intentionality.
For nature, after all, offers no other examples of causal chains in which events causally downstream refer back to the objects that are involved in producing their causal ancestors.
The intentionality of perceptions — and indeed of other mental phenomena — makes them non-analogous to material phenomena outside of the nervous system.
And nothing that takes place within the nervous system can explain why this property of intentionality should emerge there.
The Attractions of the Materialist Causal Theory of Perception
If, as I have argued, neurophysiological explanations of mind explain nothing and if physiological observations give us no purchase on the essentially metaphysical question of the nature of mind, how has the myth become so powerful that many people within and outside the scientific community do believe that neurophysiology has advanced (or will advance) our understanding of mind and the mind-body relationship?
The CTP itself is attractive for many reasons.
For a start, it promises to biologize consciousness; to make it part of the natural world.
This, in turn, opens up the possibility of a unified account of the world that encompasses not only physical but also mental events.
The causal thread that reaches from the perceived object to the perception and on from that to the overt activity of the perceiver symbolizes the ontological homogeneity of the world.
The CTP, or something like it, is thus crucial to the over-riding scientific project of describing the whole of reality in terms of a single set of (physical) mechanisms.
Secondly, the neurophysiological CTP is consistent with scientific and everyday observations about the interdependence of mind and brain.
Ordinary experience seems to indicate that brain position determines experience content: where my head is (in space and in time) is the most important determinant of the content of my consciousness.
Moreover, the state of my sense endings — whether they are covered or uncovered, damaged or undamaged, pointed in one direction or another — also influences experience content.
Changes in electrical activity of the brain are associated with changes in the level and content of consciousness: you can tell whether someone is asleep or awake by looking at his electro-encephalogram.
And we have already discussed the correlations described by the Weber-Fechner law between impinging energy and sensation.
The most striking demonstration of the interdependency of brain and mind are observations, ranging from the most crude to the most refined, that brain dysfunction leads to abnormalities of or absence of perception.
Decapitation, with associated brain removal, leads to a perceptible decline in I.Q. in most instances.
Indeed, brain removal leads to mind removal.
Brain injury, due for example to trauma or to stroke, or to experimental lesions, seriously interferes with perception and may remove perception completely, either temporarily or permanently.
There are rough correlations between the kinds of brain injury and the kinds of deficits observed in consciousness, as are described in a vast neuropsychological literature.
Brain dysfunction -due to uncontrolled electrical discharges as in epilepsy or due to the effects of drugs or toxins damping down electrical activity — will lead to disturbance or loss of consciousness.
Contrariwise, pseudoperceptions, ranging from crude, unformed noises and flashes of light through to complex scenes with accompanying meanings and emotions, can be generated by spontaneous discharges of the brain or in the laboratory by stimulating electrodes.
All of these observations seem to fit with, and to give support to, the idea that perception is the result of the impact of the perceived objects on an appropriately tuned nervous system.
It would be perverse to deny this.
But it has to be reiterated that the CTP does not explain these observations: it does not explain how the impinging events give rise to awareness of those events.
At best, the CTP is a vacuous summary of these observations, a framework within which they can be gathered together.
Conformity with observations about the interdependence between mind function and brain function does not support the claim of the neurophysiological CTP to explain mind or point the way to such an explanation.
A parallel attraction of the theory is that it seems to constrain perception to be true — to be only about things that impinge on the nervous system; that are, in other words, ‘really there’.
This is important for the biologizing of consciousness: consciousness will evolve only if it improves the survival chances of creatures endowed with it; and it will have survival value only if it accurately reports what is actually ‘there’.
If perception has to be triggered off by what is actually there, then it is constrained to be true.
False perception can arise only if the nervous system has spontaneous activity independently of any causative external object.
Unfortunately this evolutionary attraction of the causal theory is also illusory, for reasons that similar to those that established the circular nature of the Weber-Fechner and other psychophysical laws.
The constraint that we shall perceive only that which is ‘really there’ is a true constraint only if ‘really there’can be defined independently of the usual constraints of perception.
Unfortunately, as I have demonstrated elsewhere (see Chapter 3 of my Explicit Animal ), it cannot.
So the constraint boils down to: we can perceive only that which we usually perceive.
This, of course, is no real constraint at all .
Moreover, what we perceive far exceeds what actually interacts with our nervous system; for what interacts with our nervous systems is occurrent energy and what we perceive are continuant objects (see earlier, p. 98).
Since the CTP is so flawed as an explanation of the mind and since its apparent attractions are apparent rather than real, how does the claim of that science to advance our understanding of the mind  command such a following?
To answer this question, we need to understand the language of neuromythology.
